{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from textwrap import wrap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataAndLabels(cases):\n",
    "    labels_string = cases.cancer_type\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    labels = le.fit_transform(labels_string)\n",
    "\n",
    "    # Get rid of the cancer type and patient_id columns \n",
    "    data = cases[cases.columns[3:]]\n",
    "    return {'data': data, 'labels': labels }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading case data ...')\n",
    "cases_200 = pd.read_csv(\"pancancer_case_features_200.csv\")\n",
    "cases_500 = pd.read_csv(\"pancancer_case_features_500.csv\")\n",
    "cases_800 = pd.read_csv(\"pancancer_case_features_800.csv\")\n",
    "all_data = {\n",
    "    '200': getDataAndLabels(cases_200),\n",
    "    '500': getDataAndLabels(cases_500),\n",
    "    '800': getDataAndLabels(cases_800)\n",
    "}\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foldData(data, labels):\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    folds = []\n",
    "    for train_index, dev_index in skf.split(data, labels):\n",
    "        train_data, dev_data     = data.values[train_index], data.values[dev_index]\n",
    "        train_labels, dev_labels = labels[train_index], labels[dev_index]        \n",
    "        folds.append( {'train_data': train_data, 'train_labels': train_labels, \n",
    "                        'dev_data':   dev_data,   'dev_labels': dev_labels })\n",
    "    return folds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(data, labels):\n",
    "    train_data_all, test_data, train_labels_all, test_labels = train_test_split(data, labels,\n",
    "                                                               stratify=labels, \n",
    "                                                               test_size=0.25)\n",
    "\n",
    "    train_data, dev_data, train_labels, dev_labels = train_test_split(train_data_all, train_labels_all,\n",
    "                                                                     stratify=train_labels_all, \n",
    "                                                                     test_size=0.20)\n",
    "\n",
    "    print(\"training data:\", train_data.shape)\n",
    "    print(\"dev data     :\", dev_data.shape)\n",
    "    print(\"test data    :\",  test_data.shape)\n",
    "    return {'train_data': train_data, 'train_labels': train_labels, \n",
    "            'dev_data':   dev_data,   'dev_labels': dev_labels,\n",
    "            'test_data':  test_data,  'test_labels': test_labels}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestParams(train_data, train_labels):\n",
    "    #\n",
    "    # Logistic Regression\n",
    "    #\n",
    "    lr = LogisticRegression(penalty='l2', multi_class = 'ovr', solver='liblinear', max_iter=150)\n",
    "    params = {'C': [0.001, 0.01, 0.1, 0.5, 1, 10]}\n",
    "    logit = GridSearchCV(lr, params, cv=5,\n",
    "                         scoring='accuracy', return_train_score=True)\n",
    "\n",
    "    # Fit  training data\n",
    "    logit.fit(train_data, train_labels)  \n",
    "    # Show the best C parameter to use and the expected accuracy\n",
    "    print('\\nLogistic Regression Classifier, L2 regularization')\n",
    "    print(' Best param:', logit.best_params_)\n",
    "    print(' Accuracy:  ', np.round(logit.best_score_, 4) )\n",
    "    \n",
    "    return logit.best_params_\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMetrics(precision_l1, recall_l1, precision_l2, recall_l2):\n",
    "    labels = [ '\\n'.join(wrap(l, 8)) for l in feature_size ]        \n",
    "    plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "    plt.plot(labels, precision_l1, color='mediumblue',\n",
    "             linewidth=3, label='L1 precision at different C values', marker='o' )\n",
    "    plt.plot(labels, recall_l1, color='mediumblue', linestyle='dashed',\n",
    "             linewidth=3, label='L1 at different C values', marker='o' )\n",
    "\n",
    "    plt.plot(labels, precision_l2, color='darkorange', \n",
    "             linewidth=3, label='L2 precision with reduced number of features', marker='o' )\n",
    "    plt.plot(labels, recall_l2, color='darkorange', linestyle='dashed',\n",
    "             linewidth=3, label='L2 recall with reduced number of features', marker='o' )\n",
    "\n",
    "    plt.yticks(np.arange(.34, .7, .01))\n",
    "    plt.ylabel('Precision, Recall', fontsize=20)\n",
    "    plt.xlabel('Feature size with L1 regularization at different C parameters', fontsize=20, labelpad=20)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runLogitL1(train_data, train_labels, dev_data, dev_labels, c_param):\n",
    "    l1 = LogisticRegression(penalty='l1', tol=.01, \n",
    "                            solver=\"liblinear\", multi_class=\"ovr\",\n",
    "                            max_iter=500, C=c_param)\n",
    "    # Fit model\n",
    "    l1.fit(train_data, train_labels) \n",
    "    # Predict\n",
    "    predict = l1.predict(dev_data)\n",
    "    # Get precision, recall, f1 scores\n",
    "    scores = precision_recall_fscore_support(dev_labels, predict, average='weighted', labels=np.unique(predict))  \n",
    "    \n",
    "    # Get the features with non-zero coefficients.  We will use\n",
    "    # this list to reduce the features for the\n",
    "    # following logistic regression with L2 regularization\n",
    "    non_zero_sums = np.where(np.sum(l1.coef_, axis=0) != 0)\n",
    "    names = np.array(list(train_data.columns))\n",
    "    non_zero_names = names[non_zero_sums] \n",
    "    \n",
    "    return {'scores': scores, 'non_zero_genes': non_zero_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminateFeatures(train_data, train_labels, dev_data, dev_labels, logit_best_params):\n",
    "\n",
    "    params = {'C':  [1000, 100, 10, 1, .5, .3, .1, .05]}\n",
    "\n",
    "\n",
    "    # Now perform logistic regression on this training set with reduced features\n",
    "    # as well as the orginal non-reduced training set.  Run over different\n",
    "    # C values to plot differences in accuracy\n",
    "    precision_l1        = []\n",
    "    recall_l1           = []\n",
    "    precision_l2      = []\n",
    "    recall_l2           = []\n",
    "    feature_size        = []\n",
    "\n",
    "\n",
    "    for c_param in reversed(params['C']):\n",
    "        # Keep this random seed here to make comparison easier.\n",
    "        np.random.seed(0)\n",
    "\n",
    "        #\n",
    "        # Perform Logistic Regression on different C values\n",
    "        # using L1 regularization\n",
    "        #\n",
    "        l1_info = runLogitL1(train_data, train_labels, dev_data, dev_labels, c_param)    \n",
    "        non_zero_genes = l1_info['non_zero_genes']\n",
    "        feature_size.append(str(len(non_zero_genes)) + ' (C=' + str(c_param) + \")\")\n",
    "        precision_l1.append(l1_info['scores'][0])\n",
    "        recall_l1.append(l1_info['scores'][1])\n",
    "\n",
    "\n",
    "        #\n",
    "        # Reduce feature size, only keeping features with non-zero weights \n",
    "        # found using l1 regularization\n",
    "        #\n",
    "        min_train_data = train_data[non_zero_genes]\n",
    "        min_dev_data   = dev_data[non_zero_genes]\n",
    "\n",
    "\n",
    "        # Run logistic regression with L2 regularization on reduced\n",
    "        # feature set\n",
    "        lr = LogisticRegression(penalty='l2', tol=.01, max_iter=150, \n",
    "                                C=logit_best_params['C'], solver=\"liblinear\", multi_class=\"ovr\")\n",
    "        lr.fit(min_train_data, train_labels) \n",
    "\n",
    "        predict = lr.predict(min_dev_data)\n",
    "\n",
    "        # Get precision, recall, f1 scores\n",
    "        scores = precision_recall_fscore_support(dev_labels, predict, average='weighted', labels=np.unique(predict))  \n",
    "        precision_l2.append(scores[0])\n",
    "        recall_l2.append(scores[1])\n",
    "        \n",
    "    plotMetrics(precision_l1, recall_l1, precision_l2, recall_l2)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data   = all_data['200']['data']\n",
    "labels = all_data['200']['labels']\n",
    "splits = splitData(data, labels)\n",
    "logit_best_params = getBestParams(splits['train_data'], splits['train_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for top_n_genes, data_object in all_data.items():\n",
    "    data   = data_object['data']\n",
    "    labels = data_object['labels']\n",
    "    splits = splitData(data, labels)\n",
    "    eliminateFeatures(splits['train_data'], splits['train_labels'],\n",
    "                      splits['dev_data'], splits['dev_labels'], logit_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
