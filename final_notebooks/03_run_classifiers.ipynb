{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dRLi1FBsby4R"
   },
   "source": [
    "# W207.6 Final Project - Predicting Cancer Type from Tumor Mutations\n",
    "### Tony Di Sera, Vijay Singh, Rajiv Nair, Jeremy Fraenkel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6NrLTq1-bVmt"
   },
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u1NF-T6Jby4U"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "from textwrap import wrap\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import time\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "from tensorflow.keras.layers import Dense as Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "# Establish the colors for each cancer type\n",
    "label_colors = []\n",
    "cm = plt.get_cmap('tab20b')\n",
    "for i in range(20):\n",
    "    label_colors.append(cm(i))\n",
    "cm = plt.get_cmap('tab20c')\n",
    "for i in range(13):\n",
    "    label_colors.append(cm(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "NVVoSJj8by4i",
    "outputId": "78557bfc-1622-4c33-96e3-36e17e0d1a0e"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "BLpMLAMqby4l",
    "outputId": "56444f10-50f0-4c22-dbfc-252569929c4e"
   },
   "outputs": [],
   "source": [
    "#cd /content/drive/My Drive/berkeley/W207 machine learning/Final Project/w207_6_sum19_g5_final_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "cruqTsRrby4e",
    "outputId": "85cfe90d-4189-4801-d5df-84b5ccbc85c2"
   },
   "outputs": [],
   "source": [
    "#if tf.test.gpu_device_name() != '/device:GPU:0':\n",
    "#  print('WARNING: GPU device not found.')\n",
    "#else:\n",
    "#  print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O-7lMnfrby4y"
   },
   "outputs": [],
   "source": [
    "# create the directory where the downloaded directory is stored\n",
    "data_dir = \"./data\"\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    \n",
    "# create the directory where the metrics are stored\n",
    "metrics_dir = \"./metrics\"\n",
    "if not os.path.isdir(metrics_dir):\n",
    "    os.makedirs(metrics_dir)\n",
    "    \n",
    "# create the raw where the source data is stored\n",
    "raw_dir = \"./raw\"\n",
    "if not os.path.isdir(raw_dir):\n",
    "    os.makedirs(raw_dir)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OUYcwsHcIelo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping download, as file ./raw/tcga_dictionaries.txt is present\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "# This downloads a dictionary file\n",
    "dictionary_filename = \"./raw/tcga_dictionaries.txt\"\n",
    "if os.path.isfile(dictionary_filename):\n",
    "    print(\"Skipping download, as file %s is present\" %(dictionary_filename))\n",
    "else:\n",
    "    print('Downloading dictionary file...')\n",
    "    url = 'https://w207-final-project.s3.amazonaws.com/raw/tcga_dictionaries.txt'  \n",
    "    urllib.request.urlretrieve(url, dictionary_filename)  \n",
    "print(\"done.\")\n",
    "\n",
    "\n",
    "# This loads the data dictionary to will convert\n",
    "# the tumor_sample_barcode into a cancer_type\n",
    "# and provide full names for the cancer types\n",
    "tcga_dict = open(\"./raw/tcga_dictionaries.txt\",\"r\")\n",
    "dict_name_index = 0 #Set dictionary index counter to 0\n",
    "for line in tcga_dict:\n",
    "    if line.startswith(\"#\"): #If line starts with #, the next line will be a known dictionary\n",
    "        dict_name_index += 1\n",
    "    elif dict_name_index == 4:\n",
    "        tissue_source_site = eval(line)            \n",
    "    elif dict_name_index == 5:\n",
    "        code_to_disease = eval(line)\n",
    "    elif dict_name_index == 6:\n",
    "        disease_to_code = eval(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1jJefDaHby7m"
   },
   "source": [
    "# Run the Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k8UQU7csby7n"
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zK-UScuMa25r"
   },
   "source": [
    "### The data dictionary\n",
    "All data source files are downloaded above.  This dataset, is a data dictionary\n",
    "that will allow us to translate cancer type codes to cancer type names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yf_agA3Ba88f"
   },
   "outputs": [],
   "source": [
    "# This loads the data dictionary to will convert\n",
    "# the tumor_sample_barcode into a cancer_type\n",
    "# and provide full names for the cancer types\n",
    "tcga_dict = open(\"./raw/tcga_dictionaries.txt\",\"r\")\n",
    "dict_name_index = 0 #Set dictionary index counter to 0\n",
    "for line in tcga_dict:\n",
    "    if line.startswith(\"#\"): #If line starts with #, the next line will be a known dictionary\n",
    "        dict_name_index += 1\n",
    "    elif dict_name_index == 4:\n",
    "        tissue_source_site = eval(line)            \n",
    "    elif dict_name_index == 5:\n",
    "        code_to_disease = eval(line)\n",
    "    elif dict_name_index == 6:\n",
    "        disease_to_code = eval(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tvpezaGsby7o"
   },
   "outputs": [],
   "source": [
    "def getDataAndLabels(name, features, label_encoder):\n",
    "    labels_string = features.cancer_type\n",
    "   \n",
    "    labels        = label_encoder.fit_transform(labels_string)\n",
    "\n",
    "    # Get rid of the cancer type and patient_barcode columns \n",
    "    data = features[features.columns[3:]]\n",
    "\n",
    "    return {'name': name, 'feature_size': data.shape[1],\n",
    "            'data': data, 'labels': labels , 'label_encoder': label_encoder }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "u2kc_vGOby7r",
    "outputId": "8fa86854-348d-463d-97e7-e4fed4ae3811"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data ...\n",
      "  after_pca\n",
      "  after_rf\n",
      "  all\n",
      "  all_patient\n",
      "  bestfit_100\n",
      "  bestfit_4000\n",
      "  bestfit_800\n",
      "  bestfit_8000\n",
      "  l1reg_c0.025\n",
      "  l1reg_c0.05\n",
      "  l1reg_c0.1\n",
      "  l1reg_c0.25\n",
      "  l1reg_c0.5\n",
      "  l1reg_c1\n",
      "  l1reg_c10\n",
      "  l1reg_c100\n",
      "  rfe_8000\n",
      "  top_100_genes\n",
      "done.\n",
      "Loading test data ...\n",
      "  after_pca\n",
      "  after_rf\n",
      "  all\n",
      "  all_patient\n",
      "  bestfit_100\n",
      "  bestfit_4000\n",
      "  bestfit_800\n",
      "  bestfit_8000\n",
      "  l1reg_c0.025\n",
      "  l1reg_c0.05\n",
      "  l1reg_c0.1\n",
      "  l1reg_c0.25\n",
      "  l1reg_c0.5\n",
      "  l1reg_c1\n",
      "  l1reg_c10\n",
      "  l1reg_c100\n",
      "  rfe_8000\n",
      "  top_100_genes\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "print('Loading training data ...')\n",
    "\n",
    "filepath = \"./data/features_*\"\n",
    "\n",
    "# label encoder\n",
    "label_encoder   = preprocessing.LabelEncoder()\n",
    "\n",
    "# get all file names for the feature datasets\n",
    "train_files = glob.glob(filepath + \".train.csv\")\n",
    "all_train_data = {}\n",
    "\n",
    "# load all of the files\n",
    "for filename in train_files:\n",
    "    \n",
    "    name = filename[16:-10]\n",
    "    print(\" \", name)\n",
    "    train_features = pd.read_csv(filename)\n",
    "    all_train_data[name] = getDataAndLabels(name, train_features, label_encoder)\n",
    "\n",
    "print(\"done.\")\n",
    "\n",
    "\n",
    "print('Loading test data ...')\n",
    "\n",
    "test_files = glob.glob(filepath + \".test.csv\")\n",
    "all_test_data = {}\n",
    "for filename in test_files:\n",
    "    \n",
    "    name = filename[16:-9]\n",
    "    print(\" \", name)\n",
    "    test_features = pd.read_csv(filename)\n",
    "    all_test_data[name] = getDataAndLabels(name, test_features, label_encoder)\n",
    "\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y_50vHGONZwI"
   },
   "source": [
    "## Functions for tracking metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KZsxQONYby8K"
   },
   "outputs": [],
   "source": [
    "def get_saved_metrics():\n",
    "    metrics_filename = \"./metrics/metrics.csv\"\n",
    "    if os.path.isfile(metrics_filename):\n",
    "        metrics_df = pd.read_csv(metrics_filename)\n",
    "        metrics =  [row for row in metrics_df.T.to_dict().values()]\n",
    "        return metrics\n",
    "    else:\n",
    "        return []\n",
    "      \n",
    "def get_saved_metrics_dataframe():\n",
    "    metrics_filename = \"./metrics/metrics.csv\"\n",
    "    if os.path.isfile(metrics_filename):\n",
    "        metrics_df = pd.read_csv(metrics_filename)\n",
    "        return metrics_df\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def save_metrics(name, classifier, metrics, prf_by_label, confusion_mx):\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics, columns=['name', 'classifier', 'feature_size', \n",
    "                                                'accuracy', 'precision', 'recall', 'f1', \n",
    "                                                'time'])\n",
    "    \n",
    "    # Write out scores as csv files\n",
    "    metrics_df.to_csv(\"./metrics/metrics.csv\")\n",
    "    \n",
    "    # Write out confusion matrix to csv file    \n",
    "    confusion_mx_df = pd.DataFrame.from_dict(confusion_mx)\n",
    "    filename = \"./metrics/confusion_\" + name + \"_\" + classifier + \".csv\"\n",
    "    confusion_mx_df.to_csv(filename)\n",
    "    \n",
    "    # Write out precision, recall, f1 by class to csv file\n",
    "    prf_by_label_list = []\n",
    "    for row in prf_by_label:\n",
    "      prf_by_label_list.append(list(row))\n",
    "    prf_by_label_df = pd.DataFrame(prf_by_label_list)\n",
    "    filename = \"./metrics/prf_by_class_\" + name + \"_\" + classifier + \".csv\"\n",
    "    prf_by_label_df.to_csv(filename)\n",
    "    \n",
    "def get_prf_by_label(name, classifier):\n",
    "    filename = \"./metrics/prf_by_class_\" + name + \"_\" + classifier + \".csv\"\n",
    "    if os.path.isfile(filename):\n",
    "        prf_by_label_df = pd.read_csv(filename)\n",
    "        return prf_by_label_df[prf_by_label_df.columns[1:]]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_confusion_matrix(name, classifier):\n",
    "    filename = \"./metrics/confusion_\" + name + \"_\" + classifier + \".csv\"\n",
    "    if os.path.isfile(filename):\n",
    "        confusion_df = pd.read_csv(filename)\n",
    "        return confusion_df[confusion_df.columns[1:]]\n",
    "    else:\n",
    "        return None\n",
    "      \n",
    "def calculate_metrics(name, classifier, feature_size, predict, test_labels, \n",
    "                      elapsed_time, metrics, ROC = False):\n",
    "    # Get precision, recall, f1 scores\n",
    "    prf_scores          = precision_recall_fscore_support(test_labels, predict, \n",
    "                                                          average='weighted')\n",
    "    acc_score           = accuracy_score(test_labels, predict)\n",
    "    prf_by_label        = precision_recall_fscore_support(test_labels, predict, \n",
    "                                                          average=None)\n",
    "    classification_rpt  = classification_report(test_labels, predict)\n",
    "\n",
    "    # Get confusion matrix\n",
    "    conf_mx             = confusion_matrix(test_labels, predict)\n",
    "\n",
    "    metrics.append({\n",
    "     'name':               name,\n",
    "     'classifier':         classifier,\n",
    "     'feature_size':       feature_size,\n",
    "     'accuracy':           acc_score,\n",
    "     'precision':          prf_scores[0],\n",
    "     'recall':             prf_scores[1],\n",
    "     'f1':                 prf_scores[2],\n",
    "     'time':               elapsed_time \n",
    "    })\n",
    "    save_metrics(name, classifier, metrics, prf_by_label, conf_mx)\n",
    "    \n",
    "    # Get ROC curve and score\n",
    "    if ROC == True:\n",
    "        roc_score(test_labels, predict, classifier, name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC score and plot ROC curve\n",
    "def roc_score(y_label, y_pred, classifier, name):\n",
    "    #Binaryize Labels\n",
    "    y = label_binarize(y_label, classes=list(range(len(np.unique(y_label)))))\n",
    "    # Binarize Predictions\n",
    "    y_score = label_binarize(y_pred, classes=list(range(len(np.unique(y_label)))))\n",
    "    n_classes = y.shape[1]\n",
    "    # Empty initialized dict\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    # Loop over classes\n",
    "    for i in range(n_classes):\n",
    "        # Compute ROC curve for each class\n",
    "        fpr[i], tpr[i], _ = roc_curve(y[:, i], y_score[:, i])\n",
    "        # Compute ROC area for each class\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i]) \n",
    "    # Compute macro-average ROC curve and ROC area\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for j in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[j], tpr[j])\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "    # Plot ROC curve\n",
    "    plt.plot(np.append([0],fpr[\"macro\"]), np.append([0],tpr[\"macro\"]),label='macro-average ROC curve (area = {0:0.2f})'.format(roc_auc[\"macro\"]))\n",
    "    # Dashed diagonal\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    # Axes\n",
    "    plt.xlim([-0.01, 1.0])\n",
    "    plt.ylim([0.0, 1.01])\n",
    "    # Label of graph\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate (Recall)')\n",
    "    # Title of graph\n",
    "    plt.title('ROC curve for {0} ({1})'.format(classifier, name))\n",
    "    # Legend\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BcMd3vhdby7z"
   },
   "source": [
    "## Functions for running different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gOquprmrby75"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Logistic regression\n",
    "# \n",
    "def getBestParamsLogit(train_data, train_labels):\n",
    "    #\n",
    "    # Logistic Regression\n",
    "    #\n",
    "    lr = LogisticRegression(penalty='l2', multi_class = 'ovr', solver='liblinear', max_iter=150)\n",
    "    params = {'C': [0.1, 0.25,  0.5]}\n",
    "    logit = GridSearchCV(lr, params, cv=5,\n",
    "                         scoring='accuracy', return_train_score=True)\n",
    "\n",
    "    # Fit  training data\n",
    "    logit.fit(train_data, train_labels)  \n",
    "    # Show the best C parameter to use and the expected accuracy\n",
    "    print(' Best param:', logit.best_params_)\n",
    "    print(' Accuracy:  ', np.round(logit.best_score_, 4) )\n",
    "    \n",
    "    return logit.best_params_\n",
    "\n",
    "def run_logistic_regression(train_data, train_labels, test_data, test_labels, \n",
    "                            name, hyper_params, metrics, forcerun=False):\n",
    "  \n",
    "    existing = [record for record in metrics if record['name'] == name and record['classifier'] == 'lr']\n",
    "    if (not(forcerun) and len(existing) > 0):\n",
    "      print(\"\\nLogistic Regression (skipping)\")\n",
    "      return\n",
    "    \n",
    "    print(\"\\nLogistic Regression\", name)\n",
    "\n",
    "    start = time.process_time()\n",
    "    if name in hyper_params and 'lr' in hyper_params[name]:\n",
    "        best_params_logit = hyper_params[name]['lr']\n",
    "    else:\n",
    "        print(\"Running grid search on Logistic Regression...\")\n",
    "        best_params_logit = getBestParamsLogit(train_data, train_labels)\n",
    "\n",
    "    # Run logistic regression with L2 regularization on reduced\n",
    "    # feature set\n",
    "    lr = LogisticRegression(penalty='l2', tol=.01, max_iter=150, \n",
    "                          C=best_params_logit['C'], \n",
    "                          solver=\"liblinear\", multi_class=\"ovr\")\n",
    "    lr.fit(train_data, train_labels) \n",
    "    predict = lr.predict(test_data)\n",
    "    elapsed_time = time.process_time() - start\n",
    "\n",
    "\n",
    "    calculate_metrics(name, 'lr', train_data.shape[1], predict, test_labels, \n",
    "                      elapsed_time, metrics, ROC = False)\n",
    "\n",
    "    print(\" done.\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KHfO2X_Vby77"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Linear SVM\n",
    "#\n",
    "\n",
    "def getBestParamsSVM(train_data, train_labels):\n",
    "    #\n",
    "    # SVM\n",
    "    #\n",
    "    classifier = LinearSVC(penalty='l2')\n",
    "\n",
    "    params = {'C': [0.01, 0.1, 0.5]}\n",
    "    svm = GridSearchCV(classifier, params, cv=4, \n",
    "                       scoring='accuracy', return_train_score=True)\n",
    "\n",
    "    # Fit  training data\n",
    "    svm.fit(train_data, train_labels)  \n",
    "    # Show the best C parameter to use and the expected accuracy\n",
    "    print(' Best param:', svm.best_params_)\n",
    "    print(' Accuracy:  ', np.round(svm.best_score_, 4) )\n",
    "    \n",
    "    return svm.best_params_\n",
    "  \n",
    "def run_linear_svm(train_data, train_labels, test_data, test_labels, \n",
    "                   name, hyper_params, metrics, forcerun=False):\n",
    "    \n",
    "    existing = [record for record in metrics if record['name'] == name and record['classifier'] == 'svm']\n",
    "    if (not(forcerun) and len(existing) > 0):\n",
    "      print(\"\\nLinear SVM (skipping)\")\n",
    "      return\n",
    "    \n",
    "    print(\"\\nLinear SVM\", name)\n",
    "    start = time.process_time()\n",
    "    if name in hyper_params and 'svm' in hyper_params[name]:\n",
    "        best_params_svm = hyper_params[name]['svm']\n",
    "    else:\n",
    "        print(\"Running grid search on Linear SVM...\")\n",
    "        best_params_svm = getBestParamsSVM(train_data, train_labels)\n",
    "\n",
    "    svm = LinearSVC(penalty='l2', C=best_params_svm['C'])\n",
    "\n",
    "    svm.fit(train_data, train_labels,) \n",
    "    predict = svm.predict(test_data)\n",
    "    elapsed_time = time.process_time() - start\n",
    "\n",
    "    calculate_metrics(name, 'svm', train_data.shape[1], predict, test_labels, \n",
    "                      elapsed_time, metrics, ROC = False)\n",
    "    \n",
    "    print(\" done.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "muZmidvcby8A"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Decision tree\n",
    "#\n",
    "def run_decision_tree(train_data, train_labels, test_data, test_labels, name, hyper_params, metrics):\n",
    "\n",
    "    existing = [record for record in metrics if record['name'] == name and record['classifier'] == 'dt']\n",
    "    if (len(existing) > 0):\n",
    "      print(\"\\nDecision Tree (skipping)\")\n",
    "      return\n",
    "    \n",
    "    print(\"\\nDecision Tree\", name)\n",
    "    start = time.process_time()\n",
    "    dt = DecisionTreeClassifier()\n",
    "    \n",
    "    dt.fit(train_data, train_labels,) \n",
    "    predict = dt.predict(test_data)\n",
    "    elapsed_time = time.process_time() - start\n",
    "\n",
    "\n",
    "    calculate_metrics(name, 'dt', train_data.shape[1], predict, test_labels, \n",
    "                      elapsed_time, metrics, ROC = False)\n",
    "    \n",
    "    print(\" done.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aK-uq9g0by8C"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Random forest\n",
    "#\n",
    "def run_random_forest(train_data, train_labels, test_data, test_labels, name, hyper_params, metrics):\n",
    "  \n",
    "    existing = [record for record in metrics if record['name'] == name and record['classifier'] == 'rf']\n",
    "    if (len(existing) > 0):\n",
    "      print(\"\\nRandom Forest (skipping)\")\n",
    "      return\n",
    "    \n",
    "    print(\"\\nRandom Forest\", name)\n",
    "    start = time.process_time()\n",
    "    rf = RandomForestClassifier(n_estimators=500)\n",
    "    \n",
    "    rf.fit(train_data, train_labels,) \n",
    "    predict = rf.predict(test_data)\n",
    "    elapsed_time = time.process_time() - start\n",
    "\n",
    "    calculate_metrics(name, 'rf', train_data.shape[1], predict, test_labels, \n",
    "                      elapsed_time, metrics, ROC = False)\n",
    "    \n",
    "    print(\" done.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W7u0wd8oby8F"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Neural Net\n",
    "#\n",
    "def run_neural_net(train_data, train_labels, test_data, test_labels, name, hyper_params, metrics):\n",
    "    existing = [record for record in metrics if record['name'] == name and record['classifier'] == 'nn']\n",
    "    if (len(existing) > 0):\n",
    "      print(\"\\nNeural Net (skipping)\")\n",
    "      return\n",
    "    \n",
    "    print(\"\\nNeural Net\", name)\n",
    "    tr_lab = to_categorical(train_labels)\n",
    "    test_lab = to_categorical(test_labels)\n",
    "    \n",
    "    number_of_classes = len(tr_lab[0])\n",
    "    \n",
    "    start = time.process_time()\n",
    "    model = K.Sequential()\n",
    "    model.add(Dense(2000, input_dim=train_data.shape[1], activation='relu', \n",
    "                    kernel_regularizer=regularizers.l1_l2(l2=0.01,l1=0.01)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(400, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(number_of_classes, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = [\"accuracy\"])\n",
    "    \n",
    "    \n",
    "    #model.fit(train_data, tr_lab, epochs=200, batch_size=100)\n",
    "    if name == 'after_pca':\n",
    "      n_epochs = 10\n",
    "    else:\n",
    "      n_epochs = 140\n",
    "    \n",
    "\n",
    "    hist = model.fit(train_data, tr_lab, epochs=n_epochs, batch_size=100,\n",
    "                     validation_data=(test_data, test_lab))\n",
    "    \n",
    "    \n",
    "    evaluate = model.evaluate(x = test_data, y = test_lab)\n",
    "    predict = model.predict(test_data)    \n",
    "    \n",
    "    elapsed_time = time.process_time() - start\n",
    "\n",
    "    calculate_metrics(name, 'nn', train_data.shape[1],\n",
    "                      np.argmax(predict,1), test_labels, elapsed_time, metrics, ROC = False)\n",
    "\n",
    "    print(\" done.\")\n",
    "    \n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dwdypavvby8K"
   },
   "source": [
    "## Run the different classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MPlio9KCby8R",
    "outputId": "1ffef275-ec68-42ea-bdc5-0679fb395165"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************\n",
      "after_pca\n",
      "************************\n",
      "\n",
      "Logistic Regression after_pca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Linear SVM after_pca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Decision Tree after_pca\n",
      " done.\n",
      "\n",
      "Random Forest after_pca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "************************\n",
      "after_rf\n",
      "************************\n",
      "\n",
      "Logistic Regression after_rf\n",
      "Running grid search on Logistic Regression...\n",
      " Best param: {'C': 0.25}\n",
      " Accuracy:   0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Linear SVM after_rf\n",
      "Running grid search on Linear SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best param: {'C': 0.01}\n",
      " Accuracy:   0.5601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Decision Tree after_rf\n",
      " done.\n",
      "\n",
      "Random Forest after_rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "************************\n",
      "all\n",
      "************************\n",
      "\n",
      "Logistic Regression all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Linear SVM all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Decision Tree all\n",
      " done.\n",
      "\n",
      "Random Forest all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "************************\n",
      "all_patient\n",
      "************************\n",
      "\n",
      "Logistic Regression all_patient\n",
      "Running grid search on Logistic Regression...\n",
      " Best param: {'C': 0.5}\n",
      " Accuracy:   0.5608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Linear SVM all_patient\n",
      "Running grid search on Linear SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best param: {'C': 0.01}\n",
      " Accuracy:   0.5532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Decision Tree all_patient\n",
      " done.\n",
      "\n",
      "Random Forest all_patient\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "************************\n",
      "bestfit_100\n",
      "************************\n",
      "\n",
      "Logistic Regression bestfit_100\n",
      "Running grid search on Logistic Regression...\n",
      " Best param: {'C': 0.25}\n",
      " Accuracy:   0.406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Linear SVM bestfit_100\n",
      "Running grid search on Linear SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best param: {'C': 0.1}\n",
      " Accuracy:   0.3961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Decision Tree bestfit_100\n",
      " done.\n",
      "\n",
      "Random Forest bestfit_100\n",
      " done.\n",
      "************************\n",
      "bestfit_4000\n",
      "************************\n",
      "\n",
      "Logistic Regression bestfit_4000\n",
      "Running grid search on Logistic Regression...\n",
      " Best param: {'C': 0.1}\n",
      " Accuracy:   0.5151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Linear SVM bestfit_4000\n",
      "Running grid search on Linear SVM...\n",
      " Best param: {'C': 0.01}\n",
      " Accuracy:   0.5018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Decision Tree bestfit_4000\n",
      " done.\n",
      "\n",
      "Random Forest bestfit_4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "************************\n",
      "bestfit_800\n",
      "************************\n",
      "\n",
      "Logistic Regression bestfit_800\n",
      "Running grid search on Logistic Regression...\n",
      " Best param: {'C': 0.1}\n",
      " Accuracy:   0.4688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Linear SVM bestfit_800\n",
      "Running grid search on Linear SVM...\n",
      " Best param: {'C': 0.01}\n",
      " Accuracy:   0.4584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Decision Tree bestfit_800\n",
      " done.\n",
      "\n",
      "Random Forest bestfit_800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "************************\n",
      "bestfit_8000\n",
      "************************\n",
      "\n",
      "Logistic Regression bestfit_8000\n",
      "Running grid search on Logistic Regression...\n",
      " Best param: {'C': 0.1}\n",
      " Accuracy:   0.531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Linear SVM bestfit_8000\n",
      "Running grid search on Linear SVM...\n",
      " Best param: {'C': 0.01}\n",
      " Accuracy:   0.5179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Decision Tree bestfit_8000\n",
      " done.\n",
      "\n",
      "Random Forest bestfit_8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "************************\n",
      "l1reg_c0.025\n",
      "************************\n",
      "\n",
      "Logistic Regression l1reg_c0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Linear SVM l1reg_c0.025\n",
      " done.\n",
      "\n",
      "Decision Tree l1reg_c0.025\n",
      " done.\n",
      "\n",
      "Random Forest l1reg_c0.025\n",
      " done.\n",
      "************************\n",
      "l1reg_c0.05\n",
      "************************\n",
      "\n",
      "Logistic Regression l1reg_c0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Linear SVM l1reg_c0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Decision Tree l1reg_c0.05\n",
      " done.\n",
      "\n",
      "Random Forest l1reg_c0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "************************\n",
      "l1reg_c0.1\n",
      "************************\n",
      "\n",
      "Logistic Regression l1reg_c0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Linear SVM l1reg_c0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Decision Tree l1reg_c0.1\n",
      " done.\n",
      "\n",
      "Random Forest l1reg_c0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "************************\n",
      "l1reg_c0.25\n",
      "************************\n",
      "\n",
      "Logistic Regression l1reg_c0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Linear SVM l1reg_c0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Decision Tree l1reg_c0.25\n",
      " done.\n",
      "\n",
      "Random Forest l1reg_c0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "************************\n",
      "l1reg_c0.5\n",
      "************************\n",
      "\n",
      "Logistic Regression l1reg_c0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Linear SVM l1reg_c0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Decision Tree l1reg_c0.5\n",
      " done.\n",
      "\n",
      "Random Forest l1reg_c0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "************************\n",
      "l1reg_c1\n",
      "************************\n",
      "\n",
      "Logistic Regression l1reg_c1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Linear SVM l1reg_c1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Decision Tree l1reg_c1\n",
      " done.\n",
      "\n",
      "Random Forest l1reg_c1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "************************\n",
      "l1reg_c10\n",
      "************************\n",
      "\n",
      "Logistic Regression l1reg_c10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Linear SVM l1reg_c10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Decision Tree l1reg_c10\n",
      " done.\n",
      "\n",
      "Random Forest l1reg_c10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "************************\n",
      "l1reg_c100\n",
      "************************\n",
      "\n",
      "Logistic Regression l1reg_c100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Linear SVM l1reg_c100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Decision Tree l1reg_c100\n",
      " done.\n",
      "\n",
      "Random Forest l1reg_c100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "************************\n",
      "rfe_8000\n",
      "************************\n",
      "\n",
      "Logistic Regression rfe_8000\n",
      "Running grid search on Logistic Regression...\n",
      " Best param: {'C': 0.1}\n",
      " Accuracy:   0.5194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Linear SVM rfe_8000\n",
      "Running grid search on Linear SVM...\n",
      " Best param: {'C': 0.01}\n",
      " Accuracy:   0.5081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Decision Tree rfe_8000\n",
      " done.\n",
      "\n",
      "Random Forest rfe_8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "************************\n",
      "top_100_genes\n",
      "************************\n",
      "\n",
      "Logistic Regression top_100_genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Linear SVM top_100_genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "\n",
      "Decision Tree top_100_genes\n",
      " done.\n",
      "\n",
      "Random Forest top_100_genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyfraenkel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n"
     ]
    }
   ],
   "source": [
    "hyper_params = {\n",
    "    'l1reg_c0.025':         {'lr': {'C': 0.25}, 'svm': {'C': 0.01}}, \n",
    "    'l1reg_c0.05':          {'lr': {'C': 0.25}, 'svm': {'C': 0.01}}, \n",
    "    'l1reg_c0.1':           {'lr': {'C': 0.25}, 'svm': {'C': 0.01}}, \n",
    "    'l1reg_c0.25':           {'lr': {'C': 0.25}, 'svm': {'C': 0.01}}, \n",
    "    'l1reg_c0.5':           {'lr': {'C': 0.25}, 'svm': {'C': 0.01}},\n",
    "    'l1reg_c1':             {'lr': {'C': 0.25}, 'svm': {'C': 0.01}},\n",
    "    'l1reg_c10':            {'lr': {'C': 0.1},  'svm': {'C': 0.01}},\n",
    "    'l1reg_c100':           {'lr': {'C': 0.25}, 'svm': {'C': 0.01}},\n",
    "    \n",
    "    'top_100_genes':        {'lr': {'C': 0.1},  'svm': {'C': 0.01}},\n",
    "\n",
    "    'bestfit_med':          {'lr': {'C': 0.1 }, 'svm': {'C': 0.01}},\n",
    "    'bestfit_large':        {'lr': {'C': 0.1 }, 'svm': {'C': 0.01}},\n",
    "    \n",
    "    'all':                  {'lr': {'C': 0.25}, 'svm': {'C': 0.01}},\n",
    "    'after_pca':            {'lr': {'C': 0.5 }, 'svm': {'C': 0.01}},\n",
    "    \n",
    "    'rfe_svm_100':          {'lr': {'C': 0.5},  'svm': {'C': 0.1}}, \n",
    "    'rfe_lr_100':           {'lr': {'C': 0.5},  'svm': {'C': 0.1}}, \n",
    "\n",
    "    'rfe_svm_800':          {'lr': {'C': 0.5},  'svm': {'C': 0.1}}, \n",
    "    'rfe_lr_800':           {'lr': {'C': 0.1},  'svm': {'C': 0.01}}, \n",
    "    \n",
    "    'rfe_svm_4000':         {'lr': {'C': 0.5},  'svm': {'C': 0.01}}, \n",
    "    'rfe_lr_4000':          {'lr': {'C': 0.1},  'svm': {'C': 0.01}}, \n",
    "    \n",
    "    'rfe_svm_8000':         {'lr': {'C': 0.25}, 'svm': {'C': 0.01}}, \n",
    "    'rfe_lr_8000':          {'lr': {'C': 0.1},  'svm': {'C': 0.01}} \n",
    "}\n",
    "\n",
    "metrics = get_saved_metrics()\n",
    "\n",
    "\n",
    "for name in all_train_data.keys():\n",
    "    print(\"************************\")\n",
    "    print(name)\n",
    "    print(\"************************\")\n",
    "\n",
    "    train      = all_train_data[name]\n",
    "    test       = all_test_data[name]\n",
    "    \n",
    "    \n",
    "\n",
    "    run_logistic_regression(train['data'], train['labels'], test['data'], test['labels'], \n",
    "                            name, hyper_params, metrics, forcerun=False)\n",
    "    \n",
    "    run_linear_svm(train['data'], train['labels'], test['data'], test['labels'], \n",
    "                   name, hyper_params, metrics, forcerun=False)\n",
    "\n",
    "    run_decision_tree(train['data'], train['labels'], test['data'], test['labels'], \n",
    "                   name, hyper_params, metrics)\n",
    "    \n",
    "    run_random_forest(train['data'], train['labels'], test['data'], test['labels'], \n",
    "                   name, hyper_params, metrics)\n",
    "    \n",
    "    #run_neural_net(train['data'], train['labels'], test['data'], test['labels'], \n",
    "    #               name, hyper_params, metrics)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "disera_nair_singh_fraenkel_final_project.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
