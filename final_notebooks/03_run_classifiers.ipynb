{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03_run_classifiers.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dRLi1FBsby4R"},"source":["# W207.6 Final Project - Predicting Cancer Type from Tumor Mutations\n","## Notebook 3 Run Classifiers\n","### Tony Di Sera, Vijay Singh, Rajiv Nair, Jeremey Fraenkel\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6NrLTq1-bVmt"},"source":["## Initialization"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"u1NF-T6Jby4U","colab":{}},"source":["import pandas as pd\n","import urllib.request\n","import numpy as np\n","import glob\n","import os\n","import warnings\n","from textwrap import wrap\n","import matplotlib.pyplot as plt\n","from IPython.display import display\n","import time\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\"\n","\n","from sklearn import preprocessing\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import chi2\n","from sklearn.feature_selection import RFE\n","from sklearn import preprocessing\n","from sklearn import metrics\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import train_test_split\n","from sklearn.decomposition import PCA\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.svm import LinearSVC\n","from sklearn.svm import SVC\n","import tensorflow as tf\n","import tensorflow.keras as K\n","from tensorflow.keras.layers import Dense as Dense\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.callbacks import Callback\n","from sklearn.metrics import roc_curve, auc\n","from scipy import interp\n","from sklearn.preprocessing import label_binarize\n","\n","plt.rcParams.update({'figure.max_open_warning': 0})\n","\n","# Establish the colors for each cancer type\n","label_colors = []\n","cm = plt.get_cmap('tab20b')\n","for i in range(20):\n","    label_colors.append(cm(i))\n","cm = plt.get_cmap('tab20c')\n","for i in range(13):\n","    label_colors.append(cm(i))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"O-7lMnfrby4y","colab":{}},"source":["# create the directory where the metrics are stored\n","metrics_dir = \"./metrics\"\n","if not os.path.isdir(metrics_dir):\n","    os.makedirs(metrics_dir)\n","\n","# create the directory where the metrics are stored\n","metrics_dir = \"./images\"\n","if not os.path.isdir(metrics_dir):\n","    os.makedirs(metrics_dir)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zK-UScuMa25r"},"source":["### The data dictionary\n","All data source files are downloaded above.  This dataset, is a data dictionary\n","that will allow us to translate cancer type codes to cancer type names."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OUYcwsHcIelo","outputId":"047aa8c5-cae9-480e-da6e-a14fc62dc445","executionInfo":{"status":"ok","timestamp":1565287284722,"user_tz":360,"elapsed":1013,"user":{"displayName":"Tonya Di Sera","photoUrl":"https://lh3.googleusercontent.com/-PIQrExnDWnE/AAAAAAAAAAI/AAAAAAAAABk/N0sOhMjcejE/s64/photo.jpg","userId":"15321878092886920267"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["# This downloads a dictionary file\n","dictionary_filename = \"./raw/tcga_dictionaries.txt\"\n","if os.path.isfile(dictionary_filename):\n","    print(\"Skipping download, as file %s is present\" %(dictionary_filename))\n","else:\n","    print('Downloading dictionary file...')\n","    url = 'https://w207-final-project.s3.amazonaws.com/raw/tcga_dictionaries.txt'  \n","    urllib.request.urlretrieve(url, dictionary_filename)  \n","print(\"done.\")\n","\n","\n","# This loads the data dictionary to will convert\n","# the tumor_sample_barcode into a cancer_type\n","# and provide full names for the cancer types\n","tcga_dict = open(\"./raw/tcga_dictionaries.txt\",\"r\")\n","dict_name_index = 0 #Set dictionary index counter to 0\n","for line in tcga_dict:\n","    if line.startswith(\"#\"): #If line starts with #, the next line will be a known dictionary\n","        dict_name_index += 1\n","    elif dict_name_index == 4:\n","        tissue_source_site = eval(line)            \n","    elif dict_name_index == 5:\n","        code_to_disease = eval(line)\n","    elif dict_name_index == 6:\n","        disease_to_code = eval(line)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Skipping download, as file ./raw/tcga_dictionaries.txt is present\n","done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1jJefDaHby7m"},"source":["## Run the Classifiers"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"k8UQU7csby7n"},"source":["###  Load the data"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tvpezaGsby7o","colab":{}},"source":["def getDataAndLabels(name, features, label_encoder):\n","    labels_string = features.cancer_type\n","   \n","    labels        = label_encoder.fit_transform(labels_string)\n","\n","    # Get rid of the cancer type and patient_barcode columns \n","    data = features[features.columns[3:]]\n","\n","    return {'name': name, 'feature_size': data.shape[1],\n","            'data': data, 'labels': labels , 'label_encoder': label_encoder }"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"u2kc_vGOby7r","outputId":"3837a9c5-df00-430c-c667-632a764f8642","executionInfo":{"status":"ok","timestamp":1565280263563,"user_tz":360,"elapsed":48855,"user":{"displayName":"Tonya Di Sera","photoUrl":"https://lh3.googleusercontent.com/-PIQrExnDWnE/AAAAAAAAAAI/AAAAAAAAABk/N0sOhMjcejE/s64/photo.jpg","userId":"15321878092886920267"}},"colab":{"base_uri":"https://localhost:8080/","height":233}},"source":["print('Loading training data ...')\n","\n","filepath = \"./data/features_*\"\n","\n","# label encoder\n","label_encoder   = preprocessing.LabelEncoder()\n","\n","# get all file names for the feature datasets\n","train_files = glob.glob(filepath + \".train.csv\")\n","all_train_data = {}\n","\n","# load all of the files\n","for filename in train_files:\n","    \n","    name = filename[16:-10]\n","    print(\" \", name)\n","    train_features = pd.read_csv(filename)\n","    all_train_data[name] = getDataAndLabels(name, train_features, label_encoder)\n","\n","print(\"done.\")\n","\n","\n","print('Loading test data ...')\n","\n","test_files = glob.glob(filepath + \".test.csv\")\n","all_test_data = {}\n","for filename in test_files:\n","    \n","    name = filename[16:-9]\n","    print(\" \", name)\n","    test_features = pd.read_csv(filename)\n","    all_test_data[name] = getDataAndLabels(name, test_features, label_encoder)\n","\n","print(\"done.\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loading training data ...\n","  bestfit_100\n","  bestfit_800\n","  bestfit_4000\n","  bestfit_8000\n","done.\n","Loading test data ...\n","  bestfit_100\n","  bestfit_800\n","  bestfit_4000\n","  bestfit_8000\n","done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Y_50vHGONZwI"},"source":["### Functions for tracking metrics"]},{"cell_type":"markdown","metadata":{"id":"RELDyc5GopnX","colab_type":"text"},"source":["#### ROC Curve"]},{"cell_type":"code","metadata":{"id":"C0wrUdNtepbe","colab_type":"code","colab":{}},"source":["# Calculate ROC score and plot ROC curve\n","def roc_score(y_label, y_pred, classifier, name):\n","    #Binaryize Labels\n","    y = label_binarize(y_label, classes=list(range(len(np.unique(y_label)))))\n","    # Binarize Predictions\n","    y_score = label_binarize(y_pred, classes=list(range(len(np.unique(y_label)))))\n","    n_classes = y.shape[1]\n","    # Empty initialized dict\n","    fpr = dict()\n","    tpr = dict()\n","    roc_auc = dict()\n","    # Loop over classes\n","    for i in range(n_classes):\n","        # Compute ROC curve for each class\n","        fpr[i], tpr[i], _ = roc_curve(y[:, i], y_score[:, i])\n","        # Compute ROC area for each class\n","        roc_auc[i] = auc(fpr[i], tpr[i]) \n","    # Compute macro-average ROC curve and ROC area\n","    # First aggregate all false positive rates\n","    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n","    # Then interpolate all ROC curves at this points\n","    mean_tpr = np.zeros_like(all_fpr)\n","    for j in range(n_classes):\n","        mean_tpr += interp(all_fpr, fpr[j], tpr[j])\n","    # Finally average it and compute AUC\n","    mean_tpr /= n_classes\n","    fpr[\"macro\"] = all_fpr\n","    tpr[\"macro\"] = mean_tpr\n","    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","    # Plot ROC curve\n","    plt.plot(np.append([0],fpr[\"macro\"]), np.append([0],tpr[\"macro\"]),label='macro-average ROC curve (area = {0:0.2f})'.format(roc_auc[\"macro\"]))\n","    # Dashed diagonal\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    # Axes\n","    plt.xlim([-0.01, 1.0])\n","    plt.ylim([0.0, 1.01])\n","    # Label of graph\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate (Recall)')\n","    # Title of graph\n","    plt.title('ROC curve for {0} ({1})'.format(classifier, name))\n","    # Legend\n","    plt.legend(loc=\"lower right\")\n","    # Save image\n","    plt.savefig(\"./images/\"+str(name)+'_'+str(classifier)+'.png')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KZsxQONYby8K","colab":{}},"source":["def get_saved_metrics():\n","    metrics_filename = \"./metrics/metrics.csv\"\n","    if os.path.isfile(metrics_filename):\n","        metrics_df = pd.read_csv(metrics_filename)\n","        metrics =  [row for row in metrics_df.T.to_dict().values()]\n","        return metrics\n","    else:\n","        return []\n","      \n","def get_saved_metrics_dataframe():\n","    metrics_filename = \"./metrics/metrics.csv\"\n","    if os.path.isfile(metrics_filename):\n","        metrics_df = pd.read_csv(metrics_filename)\n","        return metrics_df\n","    else:\n","        return None\n","\n","def save_metrics(name, classifier, metrics, prf_by_label, confusion_mx):\n","    \n","    metrics_df = pd.DataFrame(metrics, columns=['name', 'classifier', 'feature_size', \n","                                                'accuracy', 'precision', 'recall', 'f1', \n","                                                'time'])\n","    \n","    # Write out scores as csv files\n","    metrics_df.to_csv(\"./metrics/metrics.csv\")\n","    \n","    # Write out confusion matrix to csv file    \n","    confusion_mx_df = pd.DataFrame.from_dict(confusion_mx)\n","    filename = \"./metrics/confusion_\" + name + \"_\" + classifier + \".csv\"\n","    confusion_mx_df.to_csv(filename)\n","    \n","    # Write out precision, recall, f1 by class to csv file\n","    prf_by_label_list = []\n","    for row in prf_by_label:\n","      prf_by_label_list.append(list(row))\n","    prf_by_label_df = pd.DataFrame(prf_by_label_list)\n","    filename = \"./metrics/prf_by_class_\" + name + \"_\" + classifier + \".csv\"\n","    prf_by_label_df.to_csv(filename)\n","    \n","def get_prf_by_label(name, classifier):\n","    filename = \"./metrics/prf_by_class_\" + name + \"_\" + classifier + \".csv\"\n","    if os.path.isfile(filename):\n","        prf_by_label_df = pd.read_csv(filename)\n","        return prf_by_label_df[prf_by_label_df.columns[1:]]\n","    else:\n","        return None\n","    \n","def get_confusion_matrix(name, classifier):\n","    filename = \"./metrics/confusion_\" + name + \"_\" + classifier + \".csv\"\n","    if os.path.isfile(filename):\n","        confusion_df = pd.read_csv(filename)\n","        return confusion_df[confusion_df.columns[1:]]\n","    else:\n","        return None\n","      \n","def calculate_metrics(name, classifier, feature_size, predict, test_labels, \n","                      elapsed_time, metrics, ROC = False):\n","    # Get precision, recall, f1 scores\n","    prf_scores          = precision_recall_fscore_support(test_labels, predict, \n","                                                          average='weighted')\n","    acc_score           = accuracy_score(test_labels, predict)\n","    prf_by_label        = precision_recall_fscore_support(test_labels, predict, \n","                                                          average=None)\n","    classification_rpt  = classification_report(test_labels, predict)\n","\n","    # Get confusion matrix\n","    conf_mx             = confusion_matrix(test_labels, predict)\n","\n","    metrics.append({\n","     'name':               name,\n","     'classifier':         classifier,\n","     'feature_size':       feature_size,\n","     'accuracy':           acc_score,\n","     'precision':          prf_scores[0],\n","     'recall':             prf_scores[1],\n","     'f1':                 prf_scores[2],\n","     'time':               elapsed_time \n","    })\n","    save_metrics(name, classifier, metrics, prf_by_label, conf_mx)\n","    \n","    # Get ROC curve and score\n","    if ROC == True:\n","        roc_score(test_labels, predict, classifier, name)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BcMd3vhdby7z"},"source":["### Functions for running different classifiers"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gOquprmrby75","colab":{}},"source":["#\n","# Logistic regression\n","# \n","def getBestParamsLogit(train_data, train_labels):\n","    #\n","    # Logistic Regression\n","    #\n","    lr = LogisticRegression(penalty='l2', multi_class = 'ovr', solver='liblinear', max_iter=150)\n","    params = {'C': [0.1, 0.25,  0.5]}\n","    logit = GridSearchCV(lr, params, cv=5,\n","                         scoring='accuracy', return_train_score=True)\n","\n","    # Fit  training data\n","    logit.fit(train_data, train_labels)  \n","    # Show the best C parameter to use and the expected accuracy\n","    print(' Best param:', logit.best_params_)\n","    print(' Accuracy:  ', np.round(logit.best_score_, 4) )\n","    \n","    return logit.best_params_\n","\n","def run_logistic_regression(train_data, train_labels, test_data, test_labels, \n","                            name, hyper_params, metrics,  ROC=False):\n","  \n","    existing = [record for record in metrics if record['name'] == name and record['classifier'] == 'lr']\n","    if (len(existing) > 0):\n","      print(\"\\nLogistic Regression (skipping)\")\n","      return\n","    \n","    print(\"\\nLogistic Regression\", name)\n","\n","    start = time.process_time()\n","    if name in hyper_params and 'lr' in hyper_params[name]:\n","        best_params_logit = hyper_params[name]['lr']\n","    else:\n","        print(\"Running grid search on Logistic Regression...\")\n","        best_params_logit = getBestParamsLogit(train_data, train_labels)\n","\n","    # Run logistic regression with L2 regularization on reduced\n","    # feature set\n","    lr = LogisticRegression(penalty='l2', tol=.01, max_iter=150, \n","                          C=best_params_logit['C'], \n","                          solver=\"liblinear\", multi_class=\"ovr\")\n","    lr.fit(train_data, train_labels) \n","    predict = lr.predict(test_data)\n","    elapsed_time = time.process_time() - start\n","\n","\n","    calculate_metrics(name, 'lr', train_data.shape[1], predict, test_labels, \n","                      elapsed_time, metrics, ROC)\n","\n","    print(\" done.\")\n","    \n","    return"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KHfO2X_Vby77","colab":{}},"source":["#\n","# Linear SVM\n","#\n","\n","def getBestParamsSVM(train_data, train_labels):\n","    #\n","    # SVM\n","    #\n","    classifier = LinearSVC(penalty='l2')\n","\n","    params = {'C': [0.01, 0.1, 0.5]}\n","    svm = GridSearchCV(classifier, params, cv=4, \n","                       scoring='accuracy', return_train_score=True)\n","\n","    # Fit  training data\n","    svm.fit(train_data, train_labels)  \n","    # Show the best C parameter to use and the expected accuracy\n","    print(' Best param:', svm.best_params_)\n","    print(' Accuracy:  ', np.round(svm.best_score_, 4) )\n","    \n","    return svm.best_params_\n","  \n","def run_linear_svm(train_data, train_labels, test_data, test_labels, \n","                   name, hyper_params, metrics,  ROC=False):\n","    \n","    existing = [record for record in metrics if record['name'] == name and record['classifier'] == 'svm']\n","    if (len(existing) > 0):\n","      print(\"\\nLinear SVM (skipping)\")\n","      return\n","    \n","    print(\"\\nLinear SVM\", name)\n","    start = time.process_time()\n","    if name in hyper_params and 'svm' in hyper_params[name]:\n","        best_params_svm = hyper_params[name]['svm']\n","    else:\n","        print(\"Running grid search on Linear SVM...\")\n","        best_params_svm = getBestParamsSVM(train_data, train_labels)\n","\n","    svm = LinearSVC(penalty='l2', C=best_params_svm['C'])\n","\n","    svm.fit(train_data, train_labels,) \n","    predict = svm.predict(test_data)\n","    elapsed_time = time.process_time() - start\n","\n","    calculate_metrics(name, 'svm', train_data.shape[1], predict, test_labels, \n","                      elapsed_time, metrics, ROC)\n","    \n","    print(\" done.\")\n","    return"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"muZmidvcby8A","colab":{}},"source":["def best_params_decision_tree(train_data, train_labels):\n","    parameters={'min_samples_split' : [2,3,5,10]}\n","    clf_tree=DecisionTreeClassifier()\n","    clf=GridSearchCV(clf_tree,parameters, cv=3, scoring='accuracy')\n","    clf.fit(train_data, train_labels)\n","    \n","    # Show the best parameters to use for decision tree\n","    print(' Best param:', clf.best_params_)\n","    print(' Accuracy:  ', np.round(clf.best_score_, 4) )\n","    \n","    return clf.best_params_\n","\n","#\n","# Decision tree\n","#\n","def run_decision_tree(train_data, train_labels, test_data, test_labels, \n","                      name, hyper_params, metrics, ROC=False):\n","\n","    existing = [record for record in metrics if record['name'] == name and record['classifier'] == 'dt']\n","    if (len(existing) > 0):\n","      print(\"\\nDecision Tree (skipping)\")\n","      return\n","    \n","    print(\"\\nDecision Tree\", name)\n","    \n","    if name in hyper_params and 'dt' in hyper_params[name]:\n","        best_params_dt = hyper_params[name]['dt']\n","    else:\n","      print(\"Running grid search on Decision Tree...\")\n","      best_params_dt = best_params_decision_tree(train_data, train_labels)\n","\n","    start = time.process_time()\n","    dt = DecisionTreeClassifier(min_samples_split=best_params_dt['min_samples_split'])\n","    \n","    dt.fit(train_data, train_labels,) \n","    predict = dt.predict(test_data)\n","    elapsed_time = time.process_time() - start\n","\n","\n","    calculate_metrics(name, 'dt', train_data.shape[1], predict, test_labels, \n","                      elapsed_time, metrics, ROC = False)\n","    \n","    print(\" done.\")\n","    return"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aK-uq9g0by8C","colab":{}},"source":["#\n","# Random forest\n","#\n","def run_random_forest(train_data, train_labels, test_data, test_labels, name,\n","                      hyper_params, metrics, ROC=False):\n","  \n","    existing = [record for record in metrics if record['name'] == name and record['classifier'] == 'rf']\n","    if (len(existing) > 0):\n","      print(\"\\nRandom Forest (skipping)\")\n","      return\n","    \n","    print(\"\\nRandom Forest\", name)\n","    start = time.process_time()\n","    rf = RandomForestClassifier(n_estimators=1800, \n","                                min_samples_split=10, \n","                                min_samples_leaf=2, \n","                                max_features='auto',\n","                                max_depth=110, \n","                                bootstrap=False)\n","    \n","    rf.fit(train_data, train_labels,) \n","    predict = rf.predict(test_data)\n","    elapsed_time = time.process_time() - start\n","\n","    calculate_metrics(name, 'rf', train_data.shape[1], predict, test_labels, \n","                      elapsed_time, metrics, ROC)\n","    \n","    print(\" done.\")\n","    return"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"W7u0wd8oby8F","colab":{}},"source":["\n","#\n","# Neural Net\n","#\n","def run_neural_net(train_data, train_labels, test_data, test_labels, name, \n","                   hyper_params, metrics, ROC=False):\n","  \n","    existing = [record for record in metrics if record['name'] == name and record['classifier'] == 'nn']\n","    if (len(existing) > 0):\n","      print(\"\\nNeural Net (skipping)\")\n","      return\n","    \n","    print(\"\\nNeural Net\", name)\n","    tr_lab = to_categorical(train_labels)\n","    test_lab = to_categorical(test_labels)\n","    \n","    number_of_classes = len(tr_lab[0])\n","    \n","    start = time.process_time()\n","    model = K.Sequential()\n","    model.add(Dense(2000, input_dim=train_data.shape[1], activation='relu', \n","                    kernel_regularizer=regularizers.l1_l2(l2=0.01,l1=0.01)))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(1000, activation='relu'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(400, activation='relu'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(100, activation='relu'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(64, activation='relu'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(number_of_classes, activation='sigmoid'))\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = [\"accuracy\"])\n","    \n","    \n","    #model.fit(train_data, tr_lab, epochs=200, batch_size=100)\n","    if name == 'after_pca':\n","      n_epochs = 10\n","    else:\n","      n_epochs = 140\n","    \n","\n","    hist = model.fit(train_data, tr_lab, epochs=n_epochs, batch_size=100,\n","                     validation_data=(test_data, test_lab))\n","    \n","    \n","    evaluate = model.evaluate(x = test_data, y = test_lab)\n","    predict = model.predict(test_data)    \n","    \n","    elapsed_time = time.process_time() - start\n","\n","    calculate_metrics(name, 'nn', train_data.shape[1],\n","                      np.argmax(predict,1), test_labels, elapsed_time, \n","                      metrics, ROC)\n","\n","    print(\" done.\")\n","    \n","    \n","    return\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dwdypavvby8K"},"source":["### Run the different classifiers for the different feature sets"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MPlio9KCby8R","colab":{}},"source":["hyper_params = {\n","    'l1reg_c0.025':         {'lr': {'C': 0.25}, 'svm': {'C': 0.01},\n","                            'dt': { 'min_samples_split': 10}}, \n","    'l1reg_c0.05':          {'lr': {'C': 0.25}, 'svm': {'C': 0.01},\n","                            'dt': {'min_samples_split': 10}}, \n","    'l1reg_c0.1':           {'lr': {'C': 0.25}, 'svm': {'C': 0.01},\n","                            'dt': {'min_samples_split': 5}}, \n","    'l1reg_c0.25':           {'lr': {'C': 0.25}, 'svm': {'C': 0.01},\n","                             'dt': {'min_samples_split': 5}}, \n","    'l1reg_c0.5':           {'lr': {'C': 0.25}, 'svm': {'C': 0.01},\n","                            'dt': {'min_samples_split': 10}},\n","    'l1reg_c1':             {'lr': {'C': 0.25}, 'svm': {'C': 0.01},\n","                            'dt': {'min_samples_split': 10}},\n","    'l1reg_c10':            {'lr': {'C': 0.1},  'svm': {'C': 0.01},\n","                            'dt': {'min_samples_split': 10}},\n","    'l1reg_c100':           {'lr': {'C': 0.25}, 'svm': {'C': 0.01},\n","                            'dt': {'min_samples_split': 2}},\n","    \n","    'top_100_genes':        {'lr': {'C': 0.1},  'svm': {'C': 0.01}, \n","                             'dt': {'min_samples_split': 3}},\n","    \n","   \n","\n","    'bestfit_100':          {'lr': {'C': 0.1 }, 'svm': {'C': 0.01},\n","                            'dt':  {'min_samples_split': 10}},\n","    'bestfit_800':          {'lr': {'C': 0.1 }, 'svm': {'C': 0.01},\n","                            'dt':  {'min_samples_split': 10}},\n","    'bestfit_4000':         {'dt': {'min_samples_split': 3}},\n","\n","    'bestfit_8000':         {'dt': {'min_samples_split': 5}},\n","    \n","    'all':                  {'lr': {'C': 0.25}, 'svm': {'C': 0.01}, \n","                             'dt': {'min_samples_split': 3}},\n","    \n","    'all_patient':          {'lr': {'C': 0.25}, 'svm': {'C': 0.01}, \n","                             'dt': {'min_samples_split': 3}},\n","    \n","    \n","    'after_pca':            {'lr': {'C': 0.5 }, 'svm': {'C': 0.01},\n","                            'dt': {'min_samples_split': 3}},\n","    \n","    'after_rf':             {'dt': {'min_samples_split': 3}},\n","    \n","    'rfe_100':              {'lr': {'C': 0.5},  'svm': {'C': 0.1},\n","                            'dt': {'min_samples_split': 3}}, \n","\n","    'rfe_800':              {'lr': {'C': 0.5},  'svm': {'C': 0.1},\n","                            'dt': {'min_samples_split': 3}}, \n","    \n","    'rfe_4000':             {'lr': {'C': 0.1},  'svm': {'C': 0.01},\n","                            'dt': {'min_samples_split': 3}}, \n","    \n","    'rfe_8000':             {'lr': {'C': 0.25}, 'svm': {'C': 0.01}, \n","                            'dt': {'min_samples_split': 3}}\n","}\n","\n","\n","metrics = get_saved_metrics()\n","\n","\n","for name in all_train_data.keys():\n","    print(\"************************\")\n","    print(name)\n","    print(\"************************\")\n","\n","    train      = all_train_data[name]\n","    test       = all_test_data[name]\n","    \n","    \n","\n","    run_logistic_regression(train['data'], train['labels'], test['data'], test['labels'], \n","                            name, hyper_params, metrics, ROC=False)\n","    \n","    run_linear_svm(train['data'], train['labels'], test['data'], test['labels'], \n","                   name, hyper_params, metrics, ROC=True)\n","\n","    run_decision_tree(train['data'], train['labels'], test['data'], test['labels'], \n","                   name, hyper_params, metrics, ROC=True)\n","    \n","    run_random_forest(train['data'], train['labels'], test['data'], test['labels'], \n","                   name, hyper_params, metrics, ROC=True)\n","    \n","    run_neural_net(train['data'], train['labels'], test['data'], test['labels'], \n","                   name, hyper_params, metrics, ROC=True)\n","    \n","    "],"execution_count":0,"outputs":[]}]}