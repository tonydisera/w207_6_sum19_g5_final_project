{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dRLi1FBsby4R"
   },
   "source": [
    "# W207.6 Final Project - Predicting Cancer Type from Tumor Mutations\n",
    "### Tony Di Sera, Vijay Singh, Rajiv Nair, Jeremey Fraenkel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6NrLTq1-bVmt"
   },
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u1NF-T6Jby4U"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "from textwrap import wrap\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import time\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "#import tensorflow as tf\n",
    "#import tensorflow.keras as K\n",
    "#from tensorflow.keras.layers import Dense as Dense\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "#from tensorflow.keras import regularizers\n",
    "#from tensorflow.keras.layers import Dropout\n",
    "#from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "# Establish the colors for each cancer type\n",
    "label_colors = []\n",
    "cm = plt.get_cmap('tab20b')\n",
    "for i in range(20):\n",
    "    label_colors.append(cm(i))\n",
    "cm = plt.get_cmap('tab20c')\n",
    "for i in range(13):\n",
    "    label_colors.append(cm(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "NVVoSJj8by4i",
    "outputId": "78557bfc-1622-4c33-96e3-36e17e0d1a0e"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "BLpMLAMqby4l",
    "outputId": "56444f10-50f0-4c22-dbfc-252569929c4e"
   },
   "outputs": [],
   "source": [
    "#cd /content/drive/My Drive/berkeley/W207 machine learning/Final Project/w207_6_sum19_g5_final_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "cruqTsRrby4e",
    "outputId": "85cfe90d-4189-4801-d5df-84b5ccbc85c2"
   },
   "outputs": [],
   "source": [
    "#if tf.test.gpu_device_name() != '/device:GPU:0':\n",
    "#  print('WARNING: GPU device not found.')\n",
    "#else:\n",
    "#  print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O-7lMnfrby4y"
   },
   "outputs": [],
   "source": [
    "# create the directory where the downloaded directory is stored\n",
    "data_dir = \"./data\"\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    \n",
    "# create the directory where the metrics are stored\n",
    "metrics_dir = \"./metrics\"\n",
    "if not os.path.isdir(metrics_dir):\n",
    "    os.makedirs(metrics_dir)\n",
    "    \n",
    "# create the raw where the source data is stored\n",
    "raw_dir = \"./raw\"\n",
    "if not os.path.isdir(raw_dir):\n",
    "    os.makedirs(raw_dir)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OUYcwsHcIelo"
   },
   "outputs": [],
   "source": [
    "# This downloads a dictionary file\n",
    "dictionary_filename = \"./raw/tcga_dictionaries.txt\"\n",
    "if os.path.isfile(dictionary_filename):\n",
    "    print(\"Skipping download, as file %s is present\" %(dictionary_filename))\n",
    "else:\n",
    "    print('Downloading dictionary file...')\n",
    "    url = 'https://w207-final-project.s3.amazonaws.com/raw/tcga_dictionaries.txt'  \n",
    "    urllib.request.urlretrieve(url, dictionary_filename)  \n",
    "print(\"done.\")\n",
    "\n",
    "\n",
    "# This loads the data dictionary to will convert\n",
    "# the tumor_sample_barcode into a cancer_type\n",
    "# and provide full names for the cancer types\n",
    "tcga_dict = open(\"./raw/tcga_dictionaries.txt\",\"r\")\n",
    "dict_name_index = 0 #Set dictionary index counter to 0\n",
    "for line in tcga_dict:\n",
    "    if line.startswith(\"#\"): #If line starts with #, the next line will be a known dictionary\n",
    "        dict_name_index += 1\n",
    "    elif dict_name_index == 4:\n",
    "        tissue_source_site = eval(line)            \n",
    "    elif dict_name_index == 5:\n",
    "        code_to_disease = eval(line)\n",
    "    elif dict_name_index == 6:\n",
    "        disease_to_code = eval(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uVrkAG7Cby8X"
   },
   "source": [
    "# Visualize Performance across different feature sets, different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_saved_metrics():\n",
    "    metrics_filename = \"./metrics/metrics.csv\"\n",
    "    if os.path.isfile(metrics_filename):\n",
    "        metrics_df = pd.read_csv(metrics_filename)\n",
    "        metrics =  [row for row in metrics_df.T.to_dict().values()]\n",
    "        return metrics\n",
    "    else:\n",
    "        return []\n",
    "      \n",
    "def get_saved_metrics_dataframe():\n",
    "    metrics_filename = \"./metrics/metrics.csv\"\n",
    "    if os.path.isfile(metrics_filename):\n",
    "        metrics_df = pd.read_csv(metrics_filename)\n",
    "        return metrics_df\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def save_metrics(name, classifier, metrics, prf_by_label, confusion_mx):\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics, columns=['name', 'classifier', 'feature_size', \n",
    "                                                'accuracy', 'precision', 'recall', 'f1', \n",
    "                                                'time'])\n",
    "    \n",
    "    # Write out scores as csv files\n",
    "    metrics_df.to_csv(\"./metrics/metrics.csv\")\n",
    "    \n",
    "    # Write out confusion matrix to csv file    \n",
    "    confusion_mx_df = pd.DataFrame.from_dict(confusion_mx)\n",
    "    filename = \"./metrics/confusion_\" + name + \"_\" + classifier + \".csv\"\n",
    "    confusion_mx_df.to_csv(filename)\n",
    "    \n",
    "    # Write out precision, recall, f1 by class to csv file\n",
    "    prf_by_label_df = pd.DataFrame(prf_by_label)\n",
    "    prf_by_label_list = []\n",
    "    for row in prf_by_label:\n",
    "      prf_by_label_list.append(list(row))\n",
    "    prf_by_label_df = pd.DataFrame(prf_by_label_list)\n",
    "    filename = \"./metrics/prf_by_class_\" + name + \"_\" + classifier + \".csv\"\n",
    "    prf_by_label_df.to_csv(filename)\n",
    "    \n",
    "def get_prf_by_label(name, classifier):\n",
    "    filename = \"./metrics/prf_by_class_\" + name + \"_\" + classifier + \".csv\"\n",
    "    if os.path.isfile(filename):\n",
    "        prf_by_label_df = pd.read_csv(filename)\n",
    "        return prf_by_label_df[prf_by_label_df.columns[1:]]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_confusion_matrix(name, classifier):\n",
    "    filename = \"./metrics/confusion_\" + name + \"_\" + classifier + \".csv\"\n",
    "    if os.path.isfile(filename):\n",
    "        confusion_df = pd.read_csv(filename)\n",
    "        return confusion_df[confusion_df.columns[1:]]\n",
    "    else:\n",
    "        return None\n",
    "      \n",
    "def calculate_metrics(name, classifier, feature_size, predict, test_labels, \n",
    "                      elapsed_time, metrics):\n",
    "    # Get precision, recall, f1 scores\n",
    "    prf_scores          = precision_recall_fscore_support(test_labels, predict, \n",
    "                                                          average='weighted')\n",
    "    acc_score           = accuracy_score(test_labels, predict)\n",
    "    prf_by_label        = precision_recall_fscore_support(test_labels, predict, \n",
    "                                                          average=None)\n",
    "    classification_rpt  = classification_report(test_labels, predict)\n",
    "\n",
    "    # Get confusion matrix\n",
    "    conf_mx             = confusion_matrix(test_labels, predict)\n",
    "\n",
    "    metrics.append({\n",
    "     'name':               name,\n",
    "     'classifier':         classifier,\n",
    "     'feature_size':       feature_size,\n",
    "     'accuracy':           acc_score,\n",
    "     'precision':          prf_scores[0],\n",
    "     'recall':             prf_scores[1],\n",
    "     'f1':                 prf_scores[2],\n",
    "     'time':               elapsed_time \n",
    "    })\n",
    "    save_metrics(name, classifier, metrics, prf_by_label, conf_mx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PWMrpYFIFvEL"
   },
   "source": [
    "### Load the metrics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0v60WuOBby8X"
   },
   "outputs": [],
   "source": [
    "metrics_df = get_saved_metrics_dataframe()\n",
    "metrics_df = metrics_df.sort_values(by=['feature_size', 'name', 'classifier'], ascending=[1,1,1])\n",
    "metrics_df = metrics_df[metrics_df.columns[1:]]\n",
    "\n",
    "metrics_df = metrics_df.sort_values(by=['classifier', 'feature_size', 'name'], ascending=[1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tIBzDQt3by8a"
   },
   "outputs": [],
   "source": [
    "colors = {'lr': 'olivedrab', 'svm': 'slateblue', \n",
    "          'dt': 'mediumseagreen', 'rf': 'goldenrod',\n",
    "          'xgb': 'coral', 'nn': 'crimson'}\n",
    "\n",
    "def plot_classifier_metrics(metrics_df, label_encoder, description):\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (20,14)\n",
    "\n",
    "    labels = []\n",
    "    for key, group in metrics_df.groupby(['feature_size', 'name']):\n",
    "        labels.append(str(key[0]) + '\\n' + key[1])\n",
    "    \n",
    "\n",
    "    sorted_df_report = metrics_df.sort_values(by=['classifier', 'feature_size', 'name'], ascending=[1,1,1])\n",
    "\n",
    "\n",
    "        \n",
    "    for classifier, group in sorted_df_report.groupby(['classifier']):\n",
    "\n",
    "        plt.plot(labels, group.precision.values, color=colors[classifier], \n",
    "                 linewidth=2, label=classifier + \" precision\", marker='o' )\n",
    "        plt.plot(labels, group.recall.values, color=colors[classifier], linestyle=\"dashed\",\n",
    "                 linewidth=2, label=classifier + \" recall\", marker='o' )\n",
    "    \n",
    "\n",
    "    plt.yticks(np.arange(0, .70, .01))\n",
    "    plt.title(description, fontsize=20)\n",
    "    plt.ylabel('Precision, Recall', fontsize=14)\n",
    "    plt.xlabel('Feature Sets', fontsize=14, labelpad=14)\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    for classifier, group in sorted_df_report.groupby(['classifier']):\n",
    "\n",
    "        plt.plot(labels, group.accuracy.values, color=colors[classifier], \n",
    "                 linewidth=2, label=classifier + \" accuracy\", marker='o' )\n",
    "    \n",
    "\n",
    "    plt.yticks(np.arange(0, .70, .01))\n",
    "    plt.ylabel('Accuracy', fontsize=14)\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.xlabel('Features and Classifiers', fontsize=14, labelpad=20)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_classifier_times(metrics_df, label_encoder, description):\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (20,6)\n",
    "\n",
    "    labels = []\n",
    "    for key, group in metrics_df.groupby(['feature_size', 'name']):\n",
    "        labels.append(str(key[0]) + '\\n' + key[1])\n",
    "        \n",
    "    sorted_df_report = metrics_df.sort_values(by=['classifier', 'feature_size', 'name'], ascending=[1,1,1])\n",
    "\n",
    "\n",
    "        \n",
    "    for classifier, group in sorted_df_report.groupby(['classifier']):\n",
    "\n",
    "        plt.plot(labels, group.time.values, color=colors[classifier], \n",
    "                 linewidth=2, label=classifier + \" precision\", marker='o' )\n",
    "        \n",
    "    \n",
    "\n",
    "    plt.ylabel('Time to train and predict', fontsize=14)\n",
    "    plt.xlabel('Feature Sets', fontsize=14, labelpad=14)\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "def coords_of_max(theArray, n):\n",
    "    # Flatten the 2D array\n",
    "    flat = theArray.flatten()\n",
    "    # Partition so that the we know the sort order for\n",
    "    # the cells with the highest values.  We just\n",
    "    # care about the top n highest values.  So for example,\n",
    "    # if n = 3, get return 3 indices.  \n",
    "    indices = np.argpartition(flat, -n)[-n:]\n",
    "    # Reverse so that we show index of highest value first\n",
    "    # (descending)\n",
    "    indices = indices[np.argsort(-flat[indices])]\n",
    "    # Now return the coordinates for these indices\n",
    "    # for a 2D array.  This will return 2 arrays,\n",
    "    # the first for the row index, the second for the\n",
    "    # column index.  The row index represents the\n",
    "    # actual digit, the column index represents\n",
    "    # the confused digit\n",
    "    return np.unravel_index(indices, theArray.shape)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_MYKrX8Dby8o"
   },
   "source": [
    "### Plot precision metrics across different classifiers and feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "GJSJhTWgby8p",
    "outputId": "18f89378-af4d-404f-d1b6-f9726189afb1"
   },
   "outputs": [],
   "source": [
    "label_encoder   = preprocessing.LabelEncoder()\n",
    "\n",
    "metrics_df = metrics_df[~metrics_df.name.isin(['cna_alone'])]\n",
    "                        \n",
    "somatic_metrics = metrics_df[~metrics_df.name.isin([\n",
    "                                                    'cna_l1reg_c0.025', \n",
    "                                                    'cna_l1reg_c0.01', \n",
    "                                                    'cna_binary_l1reg_c0.025',\n",
    "                                                    'cna_binary_l1reg_c0.01'])]\n",
    "cna_metrics     = metrics_df[metrics_df.name.isin( ['cna_l1reg_c0.025', \n",
    "                                                    'cna_l1reg_c0.01', \n",
    "                                                    'cna_binary_l1reg_c0.025',\n",
    "                                                    'cna_binary_l1reg_c0.01'])]\n",
    "# Plot precision, recall, accuracy across different classifiers\n",
    "# for somatic mutations\n",
    "plot_classifier_metrics(somatic_metrics, label_encoder, 'Somatic mutations')\n",
    "\n",
    "# Plot time across different classifiers\n",
    "# for somatic mutations\n",
    "plot_classifier_times(somatic_metrics, label_encoder, 'Somatic mutations')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7129vqRQby8q"
   },
   "source": [
    "### Report the precision, recall, and f1 score across different classifiers and feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6Jc7L3Ffby8r",
    "outputId": "f0a66ba3-ce0d-4f5a-ebef-fc7f4519fa70"
   },
   "outputs": [],
   "source": [
    "def show_precision_recall_by_label(prf_by_label_df, name, classifier, label_encoder):\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (16,14)\n",
    "    \n",
    "    labels = []\n",
    "    for i in range(prf_by_label_df.shape[1]):\n",
    "        label = label_encoder.inverse_transform([i])[0]\n",
    "        labels.append(label)\n",
    "    \n",
    "    \n",
    "    y_pos = np.arange(len(labels))    \n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=False)\n",
    "\n",
    "    ax1.invert_xaxis()\n",
    "    ax1.invert_yaxis()\n",
    "    ax1.yaxis.tick_right()\n",
    "    \n",
    "    ax1.set_yticks(y_pos)\n",
    "    ax1.set_yticklabels(labels)\n",
    "    \n",
    "    ax2.invert_yaxis()\n",
    "    ax2.set_yticks(y_pos)\n",
    "    ax2.set_yticklabels(labels)\n",
    "        \n",
    "    ax1.barh(y_pos, prf_by_label_df.iloc[0].values, color=label_colors , label=\"precision\")\n",
    "    ax2.barh(y_pos, prf_by_label_df.iloc[1].values, color=label_colors,  label='recall')\n",
    "\n",
    "    ax1.set_title('Precision( ' + classifier + ')')\n",
    "    ax2.set_title('Recall (' + classifier + ')')\n",
    "    ax1.grid()\n",
    "    ax2.grid()\n",
    "    \n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# best precision\n",
    "sorted_df = somatic_metrics.sort_values(by='precision', ascending=0)\n",
    "best_precision = sorted_df.head(1)\n",
    "\n",
    "# best recall\n",
    "sorted_df = somatic_metrics.sort_values(by='recall', ascending=0)\n",
    "best_recall = sorted_df.head(1)\n",
    "\n",
    "# best f1\n",
    "sorted_df = somatic_metrics.sort_values(by='f1', ascending=0)\n",
    "best_f1 = sorted_df.head(1)\n",
    "\n",
    "# best accuracy\n",
    "sorted_df = somatic_metrics.sort_values(by='accuracy', ascending=0)\n",
    "best_accuracy = sorted_df.head(1)\n",
    "\n",
    "\n",
    "# Show the feature set and classifier with the best \n",
    "# precision, recall, and f1 scores\n",
    "print(\"\\n\\nBest precision\")\n",
    "display(best_precision)\n",
    "print(\"\\n\\nBest recall\")\n",
    "display(best_recall)\n",
    "print(\"\\n\\nBest f1\")\n",
    "display(best_f1)\n",
    "print(\"\\n\\nBest accuracy\")\n",
    "display(best_accuracy)\n",
    "\n",
    "# get the scores by label and confusion matrix\n",
    "# for the best prediction\n",
    "best_prediction = best_precision\n",
    "best_name       = best_prediction.name.values[0]\n",
    "best_classifier = best_prediction.classifier.values[0]\n",
    "\n",
    "\n",
    "print(\"best name\", best_name)\n",
    "\n",
    "best_prf_by_label_df = get_prf_by_label(best_name, best_classifier)\n",
    "best_confusion_mx_df = get_confusion_matrix(best_name, best_classifier)\n",
    "\n",
    "feature_matrix = pd.read_csv(\"./data/features_\" + best_name + \".train.csv\")\n",
    "label_encoder.fit(feature_matrix.cancer_type.unique())\n",
    "\n",
    "# show a side-by-side barchart of precision and recall for each label\n",
    "print(\"\\n\\nPrecision and Recall by Label with Best F1 score \")\n",
    "print(\"Classifier:\", best_classifier, \"Feature set:\", best_name)\n",
    "show_precision_recall_by_label(best_prf_by_label_df,\n",
    "                               best_name, best_classifier, label_encoder)\n",
    "                                                      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-t7BzkrmImi"
   },
   "source": [
    "## Visualizations for Diagnosing Poor Performing Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KPOgeimaBmYR"
   },
   "source": [
    "### How many genes are in common for a cancer type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pCGcizYvmNeJ",
    "outputId": "27f3b031-6b17-4578-f85c-02bb3c306f16"
   },
   "outputs": [],
   "source": [
    "features       = feature_matrix[feature_matrix.columns[1:]]\n",
    "cancer_types   = sorted(features.cancer_type.unique())\n",
    "best_precision = np.round(best_prf_by_label_df.loc[0:0].values[0], 2)  \n",
    "best_recall    = np.round(best_prf_by_label_df.loc[0:1].values[0], 2)  \n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "fig = plt.figure()\n",
    "suptitle = fig.suptitle(\"Number of Genes in Common for Samples of a Cancer Type\", fontsize=20)\n",
    "ax = fig.subplots(7, 5, sharex=False, sharey=False, squeeze=True)\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "ax = ax.flatten()\n",
    "_ = ax[33].axis('off')\n",
    "_ = ax[34].axis('off')\n",
    "\n",
    "\n",
    "num_samples_per_cancer_type = []\n",
    "num_genes_per_cancer_type   = []\n",
    "num_multisample_genes_per_cancer_type = []\n",
    "pct_multisample_genes_per_cancer_type = []\n",
    "avg_num_samples_sharing_genes = []\n",
    "\n",
    "\n",
    "for idx, cancer_type in enumerate(cancer_types, start=0):\n",
    "  features_ct = features.loc[features.cancer_type == cancer_type]\n",
    "  features_ct = features_ct[features_ct.columns[2:]]\n",
    "\n",
    "  print(\".\", end='')\n",
    "\n",
    "  \n",
    "  gene_sums_all = features_ct.sum(axis=0) \n",
    "  gene_sums_all = gene_sums_all[gene_sums_all > 0]\n",
    "  gene_sums = gene_sums_all[gene_sums_all > 1]\n",
    "  gene_sums.columns = ['gene_count']\n",
    "\n",
    "  \n",
    "  num_samples_per_cancer_type.append(features_ct.shape[0])\n",
    "  num_genes_per_cancer_type.append(gene_sums_all.shape[0])\n",
    "  num_multisample_genes_per_cancer_type.append(gene_sums.shape[0])\n",
    "  pct_multisample_genes_per_cancer_type.append((gene_sums.shape[0] / gene_sums_all.shape[0]) * 100)\n",
    "  avg_num_samples_sharing_genes.append(gene_sums.mean(axis=0))\n",
    "  \n",
    "  bins = np.arange(31) - 0.5\n",
    "  _ = gene_sums.hist(ax=ax[idx], bins=bins, density=True, range=[0,31], color=label_colors[idx] )\n",
    "  _ = ax[idx].set_title(cancer_type + \"\\n\" \n",
    "                        + str(best_precision[idx]) + \" prec, \" + str(best_recall[idx]) + \" recall \\n\"\n",
    "                        + str(gene_sums_all.shape[0]) + \" genes, \" + str(features_ct.shape[0]) + \" samples\\n\" \n",
    "                        + str(int(np.round(gene_sums.shape[0] / gene_sums_all.shape[0], 2) * 100)) + \"% genes in mult. samples \")\n",
    "  \n",
    "  _ = ax[idx].axvline(gene_sums.mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "  _ = ax[idx].set_xlabel(\"Number of samples with genes in common\")\n",
    "  _ = ax[idx].set_ylim((0,1))\n",
    "  _ = ax[idx].set_xticks(np.arange(0, 30, 3))\n",
    "  _ = ax[idx].set_ylabel(\"Number of genes in common\")\n",
    "\n",
    "_ = fig.tight_layout()\n",
    "_ = suptitle.set_y(1.05)\n",
    "_ = fig.subplots_adjust(top=.95)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Csdqf5Q2B5e8"
   },
   "source": [
    "### How many genes are common across all cancer types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "qILJEym3BP74",
    "outputId": "715f7442-4ec1-4e87-c126-8692619f6cc6"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "fig = plt.figure()\n",
    "suptitle = fig.suptitle(\"Number of Genes for a Cancer Type that are common across other Cancer Types\", fontsize=20)\n",
    "ax = fig.subplots(7, 5, sharex=False, sharey=False, squeeze=True)\n",
    "_ = plt.subplots_adjust(hspace=0.4)\n",
    "ax = ax.flatten()\n",
    "_ = ax[33].axis('off')\n",
    "_ = ax[34].axis('off')\n",
    "\n",
    "mean_common_cancer_types = []\n",
    "\n",
    "features_by_cc = features[features.columns[1:]].groupby(['cancer_type']).sum()\n",
    "for col in features_by_cc.columns:\n",
    "  features_by_cc[col] = features_by_cc[col].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "\n",
    "diff_pairings = []\n",
    "\n",
    "for idx, cancer_type in enumerate(cancer_types, start=0):\n",
    "  print(\".\", end='')\n",
    "  features_ct = features_by_cc.loc[[cancer_type]]\n",
    "  \n",
    "  gene_counts_ct = features_ct.T\n",
    "  non_zero_genes = list(gene_counts_ct[gene_counts_ct[cancer_type] > 0].index)\n",
    "  \n",
    "  other_cancer_types = [c for c in cancer_types if c != cancer_type]\n",
    "  features_other = features_by_cc.loc[other_cancer_types, non_zero_genes]\n",
    "  \n",
    "  gene_sums_ct = features_ct.sum(axis=0) \n",
    "  gene_sums_ct = gene_sums_ct[gene_sums_ct > 0]\n",
    "  gene_sums_ct.columns = ['gene_count']\n",
    "  \n",
    "  gene_sums_other = features_other.sum(axis=0) \n",
    "  gene_sums_other = gene_sums_other[gene_sums_ct > 0]\n",
    "  gene_sums_other.columns = ['gene_count']\n",
    "  \n",
    "  sums_other     = features_other.sum(axis=0)\n",
    "  \n",
    "  mean_common_cancer_types.append(sums_other.mean())\n",
    "  \n",
    "  \n",
    "  diff_pairing       = []\n",
    "  diff_pairing_norm  = []\n",
    "  for x, cancer_type_pairing in enumerate(cancer_types, start=0):\n",
    "    features_pairing    = features_by_cc.loc[[cancer_type_pairing]]\n",
    "    gene_counts_pairing = features_pairing.T\n",
    "    non_zero_target     = set(non_zero_genes)\n",
    "    non_zero_other      = list(gene_counts_pairing[gene_counts_pairing[cancer_type_pairing] > 0].index)\n",
    "    non_zero_other      = set(non_zero_other)\n",
    "  \n",
    "    diff = non_zero_target - non_zero_other\n",
    "    \n",
    "    diff_pairing.append(len(diff))\n",
    "    \n",
    "  diff_pairings.append(diff_pairing)\n",
    "  \n",
    "  bins = np.arange(32) - 0.5\n",
    "  _ = sums_other.hist(ax=ax[idx], bins=bins, range=[0,33], color=label_colors[idx])\n",
    "  _ = ax[idx].set_ylim((0,1500))\n",
    "  _ = ax[idx].axvline(sums_other.mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "  _ = ax[idx].set_title(cancer_type + \" (\" + str(gene_sums_ct.shape[0]) + \" genes, \"\n",
    "                       + \"prec=\" + str(best_precision[idx]) + \")\")\n",
    "  \n",
    "  _ = ax[idx].set_title(cancer_type + \"\\n\" \n",
    "                        + str(best_precision[idx]) + \" prec, \" + str(best_recall[idx]) + \" recall \\n\"\n",
    "                        + str(gene_sums_ct.shape[0]) + \" genes, \" + str(num_samples_per_cancer_type[idx]) + \" samples\")\n",
    "  \n",
    "  _ = ax[idx].set_xlabel(\"Number of Cancer types\")\n",
    "  _ = ax[idx].set_ylabel(\"Number of Shared genes\")\n",
    "\n",
    "  \n",
    "fig.tight_layout()\n",
    "suptitle.set_y(1)\n",
    "fig.subplots_adjust(top=.95)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 902
    },
    "colab_type": "code",
    "id": "c7qQL6vKGRQd",
    "outputId": "d86a8659-0d64-4130-e205-003244e13f6f"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (8,4)\n",
    "fig = plt.figure()\n",
    "suptitle = fig.suptitle(\"Is Cancer Type Precision Affected by Number of Samples or Number of Genes?\", \n",
    "                        fontsize=16)\n",
    "ax = fig.subplots(1, 2, sharex=False, sharey=False, squeeze=True)\n",
    "\n",
    "_ = ax[0].scatter(num_samples_per_cancer_type, best_precision, color=label_colors)\n",
    "_ = ax[0].set_ylabel(\"Precision\")\n",
    "_ = ax[0].set_xlabel(\"Number of Samples\")\n",
    "\n",
    "_ = ax[1].scatter(num_genes_per_cancer_type, best_precision, color=label_colors)\n",
    "_ = ax[1].set_ylabel(\"Precision\")\n",
    "_ = ax[1].set_xlabel(\"Number of Genes\")\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,4)\n",
    "fig = plt.figure()\n",
    "suptitle = fig.suptitle(\"Is Cancer Type Precision Affected by How Many Samples Share the same Genes?\",\n",
    "                        fontsize=16)\n",
    "ax = fig.subplots(1, 3, sharex=False, sharey=False, squeeze=True)\n",
    "\n",
    "_ = ax[0].scatter(num_multisample_genes_per_cancer_type, best_precision, color=label_colors)\n",
    "_ = ax[0].set_ylabel(\"Precision\")\n",
    "_ = ax[0].set_xlabel(\"Number of Genes of Cancer Type\\nthat have Samples in Common\")\n",
    "\n",
    "\n",
    "_ = ax[1].scatter(pct_multisample_genes_per_cancer_type , best_precision, color=label_colors)\n",
    "_ = ax[1].set_ylabel(\"Precision\")\n",
    "_ = ax[1].set_xlabel(\"% of all Genes of Cancer Type\\nthat have Samples in Common\")\n",
    "\n",
    "\n",
    "_ = ax[2].scatter(avg_num_samples_sharing_genes, best_precision, color=label_colors)\n",
    "_ = ax[2].set_ylabel(\"Precision\")\n",
    "_ = ax[2].set_xlabel(\"Avg Number of Samples of Cancer Type\\nthat have Genes Common \")\n",
    "\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (5,4)\n",
    "fig = plt.figure()\n",
    "suptitle = fig.suptitle(\"Is Cancer Type Precision Affected by How Common Genes are Across different Cancers?\", \n",
    "                        fontsize=16)\n",
    "ax = fig.subplots(1, 1, sharex=False, sharey=False, squeeze=True)\n",
    "\n",
    "_ = ax.scatter(mean_common_cancer_types, best_precision, color=label_colors)\n",
    "_ = ax.set_ylabel(\"Precision\")\n",
    "_ = ax.set_xlabel(\"Number of Cancer Types sharing genes\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "10mUVouOCFBb"
   },
   "source": [
    "### Pairwise comparison of cancer types, how unique is the set of genes for each cancer type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "colab_type": "code",
    "id": "mCo7VgdZspur",
    "outputId": "cdd807d5-f5e7-4fa6-eb44-6ba097f402c3"
   },
   "outputs": [],
   "source": [
    "\n",
    "informative_labels = []\n",
    "for i in range(len(cancer_types)):\n",
    "  informative_labels.append(cancer_types[i] + \" (prec=\" + str(best_precision[i]))\n",
    "  \n",
    "def plot_pairwise_comparison(pairings, title):\n",
    "  \n",
    "  pairing_df = pd.DataFrame(pairings, columns=informative_labels, index=informative_labels)\n",
    "  pairing_df['precision'] = best_precision\n",
    "\n",
    "  plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "  fig = plt.figure()\n",
    "  ax = fig.add_subplot(111)\n",
    "  cax = ax.matshow(pairing_df)\n",
    "  the_title = plt.title(title, fontsize=20)\n",
    "  _ = fig.colorbar(cax)\n",
    "  _ = ax.set_xticks(np.arange(0, 33, 1.0))\n",
    "  _ = ax.set_yticks(np.arange(0, 33, 1.0))\n",
    "  _ = ax.set_xticklabels(informative_labels, rotation='vertical')\n",
    "  _ = ax.set_yticklabels(informative_labels)\n",
    "  _ = plt.xlabel('Compared to')\n",
    "  _ = plt.ylabel('Cancer Type')\n",
    "  _ = the_title.set_y(1.18)\n",
    "  _ = fig.subplots_adjust(top=.95)\n",
    "  plt.show()\n",
    "\n",
    "plot_pairwise_comparison(diff_pairings, \"Unique genes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FA9nG88nby8s"
   },
   "source": [
    "### Show the confusion matrix for the best performing classifier/feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RXNBflwyby8t",
    "outputId": "17de0f2d-0f4b-4be7-c680-700d6c5ed914"
   },
   "outputs": [],
   "source": [
    "def show_confusion_matrix(conf_mx, label_encoder):\n",
    "\n",
    "  \n",
    "    # Determine the error rates for each misclassification pair\n",
    "    row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "    norm_conf_mx = conf_mx / row_sums\n",
    "    # Set the error rates for correctly classified pairs (the diagonal) to zero\n",
    "    np.fill_diagonal(norm_conf_mx, 0)\n",
    "    \n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(norm_conf_mx)\n",
    "    _ = plt.title('Confusion matrix')\n",
    "    _ = fig.colorbar(cax)\n",
    "    _ = ax.set_xticks(np.arange(0, 33, 1.0))\n",
    "    _ = ax.set_yticks(np.arange(0, 33, 1.0))\n",
    "    _ = ax.set_xticklabels(cancer_types, rotation='vertical')\n",
    "    _ = ax.set_yticklabels(cancer_types)\n",
    "    _ = plt.xlabel('Predicted')\n",
    "    _ = plt.ylabel('True')\n",
    "    plt.show()\n",
    "    \n",
    "    max_coords = coords_of_max(norm_conf_mx, 50)\n",
    "    confusion_rows = []\n",
    "    for i in range(len(max_coords[0])):\n",
    "\n",
    "        # This is the actual label\n",
    "        actual_label_idx  = max_coords[0][i]\n",
    "        actual_label      = label_encoder.inverse_transform([actual_label_idx])[0]\n",
    "\n",
    "        # This is the predicted label\n",
    "        predicted_label_idx = max_coords[1][i]\n",
    "        predicted_label = label_encoder.inverse_transform([predicted_label_idx])[0]\n",
    "        \n",
    "        # This is the error rate\n",
    "        error_rate  = norm_conf_mx[max_coords[0][i], max_coords[1][i]]\n",
    "        error_count = conf_mx[max_coords[0][i], max_coords[1][i]]\n",
    "\n",
    "        row = list([ actual_label,                     \n",
    "                     predicted_label,\n",
    "                     code_to_disease[actual_label][0], \n",
    "                     code_to_disease[predicted_label][0], \n",
    "                     error_rate, \n",
    "                     error_count ])\n",
    "        confusion_rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(confusion_rows, columns=['actual', 'predicted',  'actual_name', 'predicted_name', 'error_rate', 'error_count'])\n",
    "    display(df)\n",
    "    \n",
    "\n",
    "cols = [c for c in best_confusion_mx_df.columns]\n",
    "best_confusion_mx = best_confusion_mx_df[cols].values\n",
    "show_confusion_matrix(best_confusion_mx, label_encoder)                                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KZ1t3OPZtSGY"
   },
   "source": [
    "### TSNE Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "t3wZ9Y03tVk1",
    "outputId": "62864444-667e-4db3-9c17-0a6020022f45"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib as mpl\n",
    "\n",
    "label_encoder   = preprocessing.LabelEncoder()\n",
    "\n",
    "labels  = list(feature_matrix.cancer_type.unique())\n",
    "labels.sort()\n",
    "X       = feature_matrix[feature_matrix.columns[3:]]\n",
    "label_encoder.fit(labels)\n",
    "\n",
    "print(\"Plot TSNE...\")\n",
    "N = len(labels)\n",
    "colors = mpl.cm.rainbow(np.linspace(0, 1, N))\n",
    "fig, axes = plt.subplots(nrows=11, ncols=3, figsize=(11, 33))\n",
    "_ = plt.tight_layout()\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if (i < len(labels)):\n",
    "      ax.title.set_text(\"cancer = {}\".format(labels[i]))\n",
    "      d = X[feature_matrix['cancer_type'] == labels[i]]\n",
    "      dd = TSNE(n_components=2).fit_transform(d)\n",
    "      _ = ax.scatter(dd[:,0], dd[:,1], color=label_colors[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "disera_nair_singh_fraenkel_final_project.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
