{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GG-owVTcFgUA"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from textwrap import wrap\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "#import xgboost as xgb\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "from tensorflow.keras.layers import Dense as Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "\n",
    "import glob\n",
    "from textwrap import wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1563828950910,
     "user": {
      "displayName": "Tonya Di Sera",
      "photoUrl": "https://lh3.googleusercontent.com/-PIQrExnDWnE/AAAAAAAAAAI/AAAAAAAAABk/N0sOhMjcejE/s64/photo.jpg",
      "userId": "15321878092886920267"
     },
     "user_tz": 360
    },
    "id": "6kfYiWzSFlV1",
    "outputId": "401edf46-2f7a-4c15-90a7-7e70751b1fa1"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 382,
     "status": "ok",
     "timestamp": 1563828956775,
     "user": {
      "displayName": "Tonya Di Sera",
      "photoUrl": "https://lh3.googleusercontent.com/-PIQrExnDWnE/AAAAAAAAAAI/AAAAAAAAABk/N0sOhMjcejE/s64/photo.jpg",
      "userId": "15321878092886920267"
     },
     "user_tz": 360
    },
    "id": "p3daM1KQGNrE",
    "outputId": "648570ee-8726-4006-bab9-c57983dc91c6"
   },
   "outputs": [],
   "source": [
    "#cd /content/drive/My Drive/berkeley/W207 machine learning/Final Project/w207_6_sum19_g5_final_project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dMSu6y23FgUE"
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YI5RociCFgUF"
   },
   "outputs": [],
   "source": [
    "# TCGA dictionary information\n",
    "tcga_dict = open(\"./data/tcga_dictionaries.txt\",\"r\")\n",
    "dict_name_index = 0 #Set dictionary index counter to 0\n",
    "for line in tcga_dict:\n",
    "    if line.startswith(\"#\"): #If line starts with #, the next line will be a known dictionary\n",
    "        dict_name_index += 1\n",
    "    elif dict_name_index == 5:\n",
    "        code_to_disease = eval(line)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jof4hF9XFgUH"
   },
   "outputs": [],
   "source": [
    "def getDataAndLabels(name, features, label_encoder):\n",
    "    labels_string = features.cancer_type\n",
    "   \n",
    "    labels        = label_encoder.fit_transform(labels_string)\n",
    "\n",
    "    # Get rid of the cancer type and patient_barcode columns \n",
    "    if (name == 'after_pca'):\n",
    "        data = features[features.columns[1:-2]]\n",
    "    else:\n",
    "        data = features[features.columns[3:]]\n",
    "\n",
    "    return {'name': name, 'feature_size': data.shape[1],\n",
    "            'data': data, 'labels': labels , 'label_encoder': label_encoder }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 250687,
     "status": "ok",
     "timestamp": 1563829225458,
     "user": {
      "displayName": "Tonya Di Sera",
      "photoUrl": "https://lh3.googleusercontent.com/-PIQrExnDWnE/AAAAAAAAAAI/AAAAAAAAABk/N0sOhMjcejE/s64/photo.jpg",
      "userId": "15321878092886920267"
     },
     "user_tz": 360
    },
    "id": "DF9Ae-PmFgUJ",
    "outputId": "7f424b32-f5e4-4ec1-eb7a-c841520d0caa"
   },
   "outputs": [],
   "source": [
    "print('Loading training data ...')\n",
    "# label encoder\n",
    "label_encoder   = preprocessing.LabelEncoder()\n",
    "\n",
    "# get all file names that start with features_\n",
    "train_files = glob.glob(\"./data/features_*.train.csv\")\n",
    "all_train_data = {}\n",
    "\n",
    "# load all of the files\n",
    "for filename in train_files:\n",
    "    \n",
    "    name = filename[16:-10]\n",
    "    #if (name != 'after_pca'):\n",
    "    print(\" \", name)\n",
    "    train_features = pd.read_csv(filename)\n",
    "    all_train_data[name] = getDataAndLabels(name, train_features, label_encoder)\n",
    "\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 292177,
     "status": "ok",
     "timestamp": 1563829290678,
     "user": {
      "displayName": "Tonya Di Sera",
      "photoUrl": "https://lh3.googleusercontent.com/-PIQrExnDWnE/AAAAAAAAAAI/AAAAAAAAABk/N0sOhMjcejE/s64/photo.jpg",
      "userId": "15321878092886920267"
     },
     "user_tz": 360
    },
    "id": "O_9g9eQDFgUL",
    "outputId": "3dbfdb86-00f6-4425-f375-42cafbac0209"
   },
   "outputs": [],
   "source": [
    "print('Loading test data ...')\n",
    "\n",
    "test_files = glob.glob(\"./data/features_*.test.csv\")\n",
    "all_test_data = {}\n",
    "for filename in test_files:\n",
    "    \n",
    "    name = filename[16:-9]\n",
    "    #if (name != 'after_pca'):\n",
    "    print(\" \", name)\n",
    "    test_features = pd.read_csv(filename)\n",
    "    all_test_data[name] = getDataAndLabels(name, test_features, label_encoder)\n",
    "\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "se3h40ydFgUN"
   },
   "source": [
    "## Functions for running different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "try7s9inFgUN"
   },
   "outputs": [],
   "source": [
    "def getBestParamsLogit(train_data, train_labels):\n",
    "    #\n",
    "    # Logistic Regression\n",
    "    #\n",
    "    lr = LogisticRegression(penalty='l2', multi_class = 'ovr', solver='liblinear', max_iter=150)\n",
    "    params = {'C': [0.1, 0.25,  0.5,]}\n",
    "    logit = GridSearchCV(lr, params, cv=5,\n",
    "                         scoring='accuracy', return_train_score=True)\n",
    "\n",
    "    # Fit  training data\n",
    "    logit.fit(train_data, train_labels)  \n",
    "    # Show the best C parameter to use and the expected accuracy\n",
    "    print(' Best param:', logit.best_params_)\n",
    "    print(' Accuracy:  ', np.round(logit.best_score_, 4) )\n",
    "    \n",
    "    return logit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ro6pztJqFgUP"
   },
   "outputs": [],
   "source": [
    "def getBestParamsSVM(train_data, train_labels):\n",
    "    #\n",
    "    # SVM\n",
    "    #\n",
    "    classifier = LinearSVC(penalty='l2')\n",
    "\n",
    "    params = {'C': [0.01, 0.1, 0.5]}\n",
    "    svm = GridSearchCV(classifier, params, cv=4, \n",
    "                       scoring='accuracy', return_train_score=True)\n",
    "\n",
    "    # Fit  training data\n",
    "    svm.fit(train_data, train_labels)  \n",
    "    # Show the best C parameter to use and the expected accuracy\n",
    "    print(' Best param:', svm.best_params_)\n",
    "    print(' Accuracy:  ', np.round(svm.best_score_, 4) )\n",
    "    \n",
    "    return svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l9Z8JabXTr93"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Logistic regression\n",
    "#\n",
    "def run_logistic_regression(train_data, train_labels, test_data, test_labels, name, hyper_params, scores):\n",
    "  if name in hyper_params and 'lr' in hyper_params[name]:\n",
    "      best_params_logit = hyper_params[name]['lr']\n",
    "  else:\n",
    "      print(\"Running grid search on Logistic Regression...\")\n",
    "      best_params_logit = getBestParamsLogit(train_data, train_labels)\n",
    "\n",
    "  # Run logistic regression with L2 regularization on reduced\n",
    "  # feature set\n",
    "  lr = LogisticRegression(penalty='l2', tol=.01, max_iter=150, \n",
    "                          C=best_params_logit['C'], \n",
    "                          solver=\"liblinear\", multi_class=\"ovr\")\n",
    "  lr.fit(train_data, train_labels) \n",
    "  predict = lr.predict(test_data)\n",
    "\n",
    "  # Get precision, recall, f1 scores\n",
    "  logit_prf_scores      = precision_recall_fscore_support(test_labels, predict, average='weighted')\n",
    "  logit_scores_by_label = precision_recall_fscore_support(test_labels, predict, average=None)\n",
    "\n",
    "  # Get confusion matrix\n",
    "  logit_confusion       = confusion_matrix(test_labels, predict)\n",
    "\n",
    "  print(\"\\nLogistic Regression\", name)\n",
    "  print(\"  precision:\", np.round(logit_prf_scores[0], 4))  \n",
    "  print(\"  recall:   \", np.round(logit_prf_scores[1], 4))  \n",
    "  print(\"  f1:       \", np.round(logit_prf_scores[2], 4))   \n",
    "\n",
    "  return [\n",
    "          logit_prf_scores[0],\n",
    "          logit_prf_scores[1],\n",
    "          logit_prf_scores[2],\n",
    "          logit_scores_by_label,\n",
    "          logit_confusion]\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oUvXEb4YWgr7"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Linear SVM\n",
    "#\n",
    "def run_linear_svm(train_data, train_labels, test_data, test_labels, name, hyper_params, scores):\n",
    "  print(\"\\nLinear SVM\", name)\n",
    "\n",
    "  if name in hyper_params and 'svm' in hyper_params[name]:\n",
    "    best_params_svm = hyper_params[name]['svm']\n",
    "  else:\n",
    "      print(\"Running grid search on Linear SVM...\")\n",
    "      best_params_svm = getBestParamsSVM(train_data, train_labels)\n",
    "\n",
    "  svm = LinearSVC(penalty='l2', C=best_params_svm['C'])\n",
    "\n",
    "  svm.fit(train_data, train_labels,) \n",
    "  predict = svm.predict(test_data)\n",
    "\n",
    "  # Get precision, recall, f1 scores\n",
    "  svm_prf_scores      = precision_recall_fscore_support(test_labels, predict, average='weighted')\n",
    "  svm_scores_by_label = precision_recall_fscore_support(test_labels, predict, average=None)\n",
    "\n",
    "  # Get confusion matrix\n",
    "  svm_confusion       = confusion_matrix(test_labels, predict)\n",
    "\n",
    "  print(\"  precision:\", np.round(svm_prf_scores[0], 4))  \n",
    "  print(\"  recall:   \", np.round(svm_prf_scores[1], 4))  \n",
    "  print(\"  f1:       \", np.round(svm_prf_scores[2], 4))      \n",
    "  \n",
    "  return [\n",
    "          svm_prf_scores[0],\n",
    "          svm_prf_scores[1],\n",
    "          svm_prf_scores[2],\n",
    "          svm_scores_by_label,\n",
    "          svm_confusion]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OYtZYFDAXFwS"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Decision tree\n",
    "#\n",
    "def run_decision_tree(train_data, train_labels, test_data, test_labels, name, hyper_params, scores):\n",
    "\n",
    "    print(\"\\nDecision Tree\", name)\n",
    "\n",
    "    dt = DecisionTreeClassifier()\n",
    "    \n",
    "    dt.fit(train_data, train_labels,) \n",
    "    predict = dt.predict(test_data)\n",
    "\n",
    "    # Get precision, recall, f1 scores\n",
    "    dt_prf_scores      = precision_recall_fscore_support(test_labels, predict, average='weighted')\n",
    "    dt_scores_by_label = precision_recall_fscore_support(test_labels, predict, average=None)\n",
    "\n",
    "    # Get confusion matrix\n",
    "    dt_confusion       = confusion_matrix(test_labels, predict)\n",
    "\n",
    "    \n",
    "    print(\"  precision:\", np.round(dt_prf_scores[0], 4))  \n",
    "    print(\"  recall:   \", np.round(dt_prf_scores[1], 4))  \n",
    "    print(\"  f1:       \", np.round(dt_prf_scores[2], 4))\n",
    "    \n",
    "    return [\n",
    "          dt_prf_scores[0],\n",
    "          dt_prf_scores[1],\n",
    "          dt_prf_scores[2],\n",
    "          dt_scores_by_label,\n",
    "          dt_confusion]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "piMfuyC6Xg37"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Random forest\n",
    "#\n",
    "def run_random_forest(train_data, train_labels, test_data, test_labels, name, hyper_params, scores):\n",
    "    print(\"\\nRandom Forest\", name)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=500)\n",
    "    \n",
    "    rf.fit(train_data, train_labels,) \n",
    "    predict = rf.predict(test_data)\n",
    "\n",
    "    # Get precision, recall, f1 scores\n",
    "    rf_prf_scores      = precision_recall_fscore_support(test_labels, predict, average='weighted')\n",
    "    rf_scores_by_label = precision_recall_fscore_support(test_labels, predict, average=None)\n",
    "\n",
    "    # Get confusion matrix\n",
    "    rf_confusion       = confusion_matrix(test_labels, predict)\n",
    "    \n",
    "    print(\"  precision:\", np.round(rf_prf_scores[0], 4))  \n",
    "    print(\"  recall:   \", np.round(rf_prf_scores[1], 4))  \n",
    "    print(\"  f1:       \", np.round(rf_prf_scores[2], 4)) \n",
    "    \n",
    "    return [\n",
    "          rf_prf_scores[0],\n",
    "          rf_prf_scores[1],\n",
    "          rf_prf_scores[2],\n",
    "          rf_scores_by_label,\n",
    "          rf_confusion]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZlzuesnnX0-u"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Neural Net\n",
    "#\n",
    "def run_neural_net(train_data, train_labels, test_data, test_labels, name, hyper_params, scores):\n",
    "    print(\"\\nNeural Net\", name)\n",
    "\n",
    "    tr_lab = to_categorical(train_labels)\n",
    "    test_lab = to_categorical(test_labels)\n",
    "    model = K.Sequential()\n",
    "    model.add(Dense(2000, input_dim=train_data.shape[1], activation='relu', \n",
    "                    kernel_regularizer=regularizers.l1_l2(l2=0.01,l1=0.01)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(400, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = [\"accuracy\"])\n",
    "    #model.fit(train_data, tr_lab, epochs=1000, batch_size=100)\n",
    "    model.fit(train_data, tr_lab, epochs=100, batch_size=100)\n",
    "    evaluate = model.evaluate(x = test_data, y = test_lab)\n",
    "    predict = model.predict(test_data)    \n",
    "    \n",
    "    # Get precision, recall, f1 scores\n",
    "    nn_prf_scores      = precision_recall_fscore_support(test_labels,np.argmax(predict,1), average='weighted')\n",
    "    nn_scores_by_label = precision_recall_fscore_support(test_labels,np.argmax(predict,1), average=None)\n",
    "\n",
    "    # Get confusion matrix\n",
    "    #nn_confusion       = confusion_matrix(test_labels, predict)\n",
    "    \n",
    "    print(\"  precision:\", np.round(nn_prf_scores[0], 4))  \n",
    "    print(\"  recall:   \", np.round(nn_prf_scores[1], 4))  \n",
    "    print(\"  f1:       \", np.round(nn_prf_scores[2], 4))  \n",
    "    \n",
    "    return [\n",
    "          nn_prf_scores[0],\n",
    "          nn_prf_scores[1],\n",
    "          nn_prf_scores[2],\n",
    "          nn_scores_by_label,\n",
    "          []]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OWWUhvPdUQEz"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# XGBoost\n",
    "#\n",
    "def run_xg_boost(train_data, train_labels, test_data, test_labels, name, hyper_params, scores):\n",
    "    print(\"\\nXG Boost\", name)\n",
    "\n",
    "    xgb_params = {\n",
    "    'max_depth': 2, \n",
    "    'eta': 0.3,  \n",
    "    'silent': False,  \n",
    "    'verbose': True,\n",
    "    'objective': 'multi:softprob',  \n",
    "    'num_class': 32,\n",
    "    'num_boost_round' : 2}  \n",
    "\n",
    "    xgb_cfr = xgb.XGBClassifier(**xgb_params)\n",
    "    xgb_cfr.fit(train_data, train_labels)\n",
    "    \n",
    "    predict = xgb_cfr.predict(test_ata)\n",
    "    \n",
    "    # Get precision, recall, f1 scores\n",
    "    xgb_prf_scores      = precision_recall_fscore_support(test_labels, predict, average='weighted')\n",
    "    xgb_scores_by_label = precision_recall_fscore_support(test_labels, predict, average=None)\n",
    "\n",
    "    # Get confusion matrix\n",
    "    xgb_confusion       = confusion_matrix(test_labels, predict)\n",
    "    \n",
    "    print(\"  precision:\", np.round(xgb_prf_scores[0], 4))  \n",
    "    print(\"  recall:   \", np.round(xgb_prf_scores[1], 4))  \n",
    "    print(\"  f1:       \", np.round(xgb_prf_scores[2], 4))  \n",
    "    \n",
    "    return  [\n",
    "            xgb_prf_scores[0],\n",
    "            xgb_prf_scores[1],\n",
    "            xgb_prf_scores[2],\n",
    "            xgb_scores_by_label,\n",
    "            xgb_confusion]\n",
    "           \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S3hn21PXFgUS"
   },
   "source": [
    "## Run the different classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GT3Q5Mv7FgUT"
   },
   "outputs": [],
   "source": [
    "def runClassifiers(train_data, train_labels, test_data, test_labels, name, hyper_params, scores):\n",
    "\n",
    "    lr_scores = run_logistic_regression(train_data, train_labels, test_data, test_labels, name, hyper_params, scores)\n",
    "\n",
    "    svm_scores = run_linear_svm(train_data, train_labels, test_data, test_labels, name, hyper_params, scores)\n",
    "    \n",
    "    dt_scores = run_decision_tree(train_data, train_labels, test_data, test_labels, name, hyper_params, scores)\n",
    "\n",
    "    rf_scores = run_random_forest(train_data, train_labels, test_data, test_labels, name, hyper_params, scores)\n",
    "       \n",
    "    nn_scores = run_neural_net(train_data, train_labels, test_data, test_labels, name, hyper_params, scores)\n",
    "\n",
    "    scores[name] = {}\n",
    "    scores[name]['lr'] = lr_scores\n",
    "    scores[name]['svm'] = svm_scores\n",
    "    scores[name]['dt'] = dt_scores\n",
    "    scores[name]['rf'] = rf_scores\n",
    "    scores[name]['nn'] = nn_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 42463
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6535847,
     "status": "ok",
     "timestamp": 1563836428141,
     "user": {
      "displayName": "Tonya Di Sera",
      "photoUrl": "https://lh3.googleusercontent.com/-PIQrExnDWnE/AAAAAAAAAAI/AAAAAAAAABk/N0sOhMjcejE/s64/photo.jpg",
      "userId": "15321878092886920267"
     },
     "user_tz": 360
    },
    "id": "wkru3nb8FgUV",
    "outputId": "e6238a81-235d-47a6-8ca6-d36389dc4b4f"
   },
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    'l1reg_c0.5':           {'lr': {'C': 0.25}, 'svm': {'C': 0.01}},\n",
    "    'l1reg_c1':             {'lr': {'C': 0.25}, 'svm': {'C': 0.01}},\n",
    "    'l1reg_c10':            {'lr': {'C': 0.1},  'svm': {'C': 0.01}},\n",
    "    'l1reg_c100':           {'lr': {'C': 0.25}, 'svm': {'C': 0.01}},\n",
    "    'topgenes_small':       {'lr': {'C': 0.25}, 'svm': {'C': 0.01}},\n",
    "    'bestfit_med':          {'lr': {'C': 0.1 }, 'svm': {'C': 0.01}},\n",
    "    'bestfit_large':        {'lr': {'C': 0.1 }, 'svm': {'C': 0.01}},\n",
    "    'all':                  {'lr': {'C': 0.25}, 'svm': {'C': 0.01}},\n",
    "    'bestfit_with_topgenes':{'lr': {'C': 0.1 }, 'svm': {'C': 0.01}},\n",
    "    'after_pca':            {'lr': {'C': 0.5 }, 'svm': {'C': 0.01}}\n",
    "}\n",
    "\n",
    "\n",
    "scores = {}\n",
    "\n",
    "\n",
    "for name in all_train_data.keys():\n",
    "    print(\"************************\")\n",
    "    print(name)\n",
    "    print(\"************************\")\n",
    "\n",
    "    train      = all_train_data[name]\n",
    "    test       = all_test_data[name]\n",
    "\n",
    "    runClassifiers(train['data'], train['labels'], test['data'], test['labels'], name, hyper_params, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oNNPfz_GFgUY"
   },
   "source": [
    "## Visualize Performance across different feature sets, different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0VkSXg7FgUZ"
   },
   "outputs": [],
   "source": [
    "colors = {'lr': 'olivedrab', 'svm': 'slateblue', \n",
    "          'dt': 'mediumseagreen', 'rf': 'goldenrod',\n",
    "          'xgb': 'coral', 'nn': 'crimson'}\n",
    "\n",
    "df_scores = pd.DataFrame(scores)\n",
    "rows = []\n",
    "for name in all_train_data.keys():    \n",
    "    for classifier in ['lr', 'svm', 'dt', 'rf', 'nn']:\n",
    "        rows.append([name,\n",
    "                     all_train_data[name]['feature_size'],\n",
    "                    classifier,\n",
    "                    df_scores.loc[classifier][name][0],\n",
    "                    df_scores.loc[classifier][name][1],\n",
    "                    df_scores.loc[classifier][name][2]])\n",
    "\n",
    "df_report = pd.DataFrame(rows, columns=['name', 'feature_size', 'classifier', 'precision', 'recall', 'f1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S9dOyXUDFgUb"
   },
   "outputs": [],
   "source": [
    "def plot_classifier_metrics(df_report, label_encoder):\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "\n",
    "    labels = []\n",
    "    for key, group in df_report.groupby(['feature_size', 'name']):\n",
    "        labels.append(str(key[0]) + '\\n' + key[1])\n",
    "        \n",
    "    sorted_df_report = df_report.sort_values(by=['classifier', 'feature_size', 'name'], ascending=[1,1,1])\n",
    "\n",
    "\n",
    "        \n",
    "    for classifier, group in sorted_df_report.groupby(['classifier']):\n",
    "\n",
    "        plt.plot(labels, group.precision.values, color=colors[classifier], \n",
    "                 linewidth=3, label=classifier + \" precision\", marker='o' )\n",
    "        plt.plot(labels, group.recall.values, color=colors[classifier], linestyle=\"dashed\",\n",
    "                 linewidth=3, label=classifier + \" recall\", marker='o' )\n",
    "    \n",
    "\n",
    "    plt.yticks(np.arange(0, .65, .01))\n",
    "    plt.ylabel('Precision, Recall', fontsize=20)\n",
    "    plt.xlabel('Precision and Recall across different Features and Classifiers', fontsize=20, labelpad=20)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G4f32K03FgUd"
   },
   "outputs": [],
   "source": [
    "def show_precision_recall_by_label(precision_by_label, recall_by_label, name, classifier, label_encoder):\n",
    "\n",
    "    labels = []\n",
    "    for i in range(len(precision_by_label)):\n",
    "        label = label_encoder.inverse_transform([i])[0]\n",
    "        labels.append(label)\n",
    "    \n",
    "    y_pos = np.arange(len(labels))    \n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=False)\n",
    "\n",
    "    ax1.invert_xaxis()\n",
    "    ax1.yaxis.tick_right()\n",
    "    \n",
    "    ax1.set_yticks(y_pos)\n",
    "    ax1.set_yticklabels(labels)\n",
    "    \n",
    "    ax2.set_yticks(y_pos)\n",
    "    ax2.set_yticklabels(labels)\n",
    "        \n",
    "    ax1.barh(y_pos, precision_by_label, color=colors[classifier] , label=\"precision\")\n",
    "    ax2.barh(y_pos, recall_by_label,    color=colors[classifier],  label='recall')\n",
    "\n",
    "    ax1.set_title('Precision( ' + classifier + ')')\n",
    "    ax2.set_title('Recall (' + classifier + ')')\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ucMlbHQ4FgUe"
   },
   "outputs": [],
   "source": [
    "def coords_of_max(theArray, n):\n",
    "    # Flatten the 2D array\n",
    "    flat = theArray.flatten()\n",
    "    # Partition so that the we know the sort order for\n",
    "    # the cells with the highest values.  We just\n",
    "    # care about the top n highest values.  So for example,\n",
    "    # if n = 3, get return 3 indices.  \n",
    "    indices = np.argpartition(flat, -n)[-n:]\n",
    "    # Reverse so that we show index of highest value first\n",
    "    # (descending)\n",
    "    indices = indices[np.argsort(-flat[indices])]\n",
    "    # Now return the coordinates for these indices\n",
    "    # for a 2D array.  This will return 2 arrays,\n",
    "    # the first for the row index, the second for the\n",
    "    # column index.  The row index represents the\n",
    "    # actual digit, the column index represents\n",
    "    # the confused digit\n",
    "    return np.unravel_index(indices, theArray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DwTeLwDDFgUg"
   },
   "outputs": [],
   "source": [
    "def show_confusion_matrix(conf_mx, label_encoder):\n",
    "    # Determine the error rates for each misclassification pair\n",
    "    row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "    norm_conf_mx = conf_mx / row_sums\n",
    "    # Set the error rates for correctly classified pairs (the diagonal) to zero\n",
    "    np.fill_diagonal(norm_conf_mx, 0)\n",
    "    \n",
    "    max_coords = coords_of_max(norm_conf_mx, 20)\n",
    "    confusion_rows = []\n",
    "    for i in range(len(max_coords[0])):\n",
    "\n",
    "        # This is the actual label\n",
    "        actual_label_idx  = max_coords[0][i]\n",
    "        actual_label      = label_encoder.inverse_transform([actual_label_idx])[0]\n",
    "\n",
    "        # This is the predicted label\n",
    "        predicted_label_idx = max_coords[1][i]\n",
    "        predicted_label = label_encoder.inverse_transform([predicted_label_idx])[0]\n",
    "        \n",
    "        # This is the error rate\n",
    "        error_rate  = norm_conf_mx[max_coords[0][i], max_coords[1][i]]\n",
    "        error_count = conf_mx[max_coords[0][i], max_coords[1][i]]\n",
    "\n",
    "        row = list([ actual_label,                     \n",
    "                     predicted_label,\n",
    "                     code_to_disease[actual_label][0], \n",
    "                     code_to_disease[predicted_label][0], \n",
    "                     error_rate, \n",
    "                     error_count ])\n",
    "        confusion_rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(confusion_rows, columns=['actual', 'predicted',  'actual_name', 'predicted_name', 'error_rate', 'error_count'])\n",
    "    display(df)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1210
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2430,
     "status": "ok",
     "timestamp": 1563838556262,
     "user": {
      "displayName": "Tonya Di Sera",
      "photoUrl": "https://lh3.googleusercontent.com/-PIQrExnDWnE/AAAAAAAAAAI/AAAAAAAAABk/N0sOhMjcejE/s64/photo.jpg",
      "userId": "15321878092886920267"
     },
     "user_tz": 360
    },
    "id": "ju0BGqiAFgUi",
    "outputId": "507d3d00-19e4-4717-8517-fd47c513b7c3"
   },
   "outputs": [],
   "source": [
    "# Plot precision and accuracy across different classifiers\n",
    "plot_classifier_metrics(df_report, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1599
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 892,
     "status": "ok",
     "timestamp": 1563838585819,
     "user": {
      "displayName": "Tonya Di Sera",
      "photoUrl": "https://lh3.googleusercontent.com/-PIQrExnDWnE/AAAAAAAAAAI/AAAAAAAAABk/N0sOhMjcejE/s64/photo.jpg",
      "userId": "15321878092886920267"
     },
     "user_tz": 360
    },
    "id": "UX0KeV8UC5fM",
    "outputId": "280956be-6369-44f0-e539-bcd06367b8dc"
   },
   "outputs": [],
   "source": [
    "display(df_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2297
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1629,
     "status": "ok",
     "timestamp": 1563838591731,
     "user": {
      "displayName": "Tonya Di Sera",
      "photoUrl": "https://lh3.googleusercontent.com/-PIQrExnDWnE/AAAAAAAAAAI/AAAAAAAAABk/N0sOhMjcejE/s64/photo.jpg",
      "userId": "15321878092886920267"
     },
     "user_tz": 360
    },
    "id": "DFkwRBwGFgUk",
    "outputId": "08f7d2b8-a381-4c20-abb2-d3343a7fe58a"
   },
   "outputs": [],
   "source": [
    "# best precision\n",
    "sorted_df = df_report.sort_values(by='precision', ascending=0)\n",
    "best_precision = sorted_df.head(1)\n",
    "\n",
    "# best recall\n",
    "sorted_df = df_report.sort_values(by='recall', ascending=0)\n",
    "best_recall = sorted_df.head(1)\n",
    "\n",
    "# best f1\n",
    "sorted_df = df_report.sort_values(by='f1', ascending=0)\n",
    "best_f1 = sorted_df.head(1)\n",
    "\n",
    "# Show the feature set and classifier with the best \n",
    "# precision, recall, and f1 scores\n",
    "print(\"\\n\\nBest precision\")\n",
    "display(best_precision)\n",
    "print(\"\\n\\nBest recall\")\n",
    "display(best_recall)\n",
    "print(\"\\n\\nBest f1\")\n",
    "display(best_f1)\n",
    "\n",
    "# get the scores by label and confusion matrix\n",
    "# for the best prediction\n",
    "best_prediction = best_precision\n",
    "best_name       = best_prediction.name.values[0]\n",
    "best_classifier = best_prediction.classifier.values[0]\n",
    "precision_by_label = scores[best_name][best_classifier][3][0]\n",
    "recall_by_label = scores[best_name][best_classifier][3][1]\n",
    "best_confusion_matrix = scores[best_name][best_classifier][4]\n",
    "\n",
    "# show a side-by-side barchart of precision and recall for each label\n",
    "print(\"\\n\\nPrecision and Recall by Label for classifier \")\n",
    "print(\"Classifier:\", best_classifier, \"Feature set:\", best_name)\n",
    "show_precision_recall_by_label(precision_by_label, recall_by_label,\n",
    "                               best_name, best_classifier, label_encoder)\n",
    "                                                      \n",
    "                                                      \n",
    "# show the confusion matrix for the best performing classifier/feature set\n",
    "show_confusion_matrix(best_confusion_matrix, label_encoder)                                                      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1653
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 592,
     "status": "ok",
     "timestamp": 1563838703720,
     "user": {
      "displayName": "Tonya Di Sera",
      "photoUrl": "https://lh3.googleusercontent.com/-PIQrExnDWnE/AAAAAAAAAAI/AAAAAAAAABk/N0sOhMjcejE/s64/photo.jpg",
      "userId": "15321878092886920267"
     },
     "user_tz": 360
    },
    "id": "hV9z4_ocFgUm",
    "outputId": "d89e2dd7-b48b-43b9-e221-5178cebf3f7f"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Write out scores as csv files\n",
    "print(\"\\nWriting metrics ...\")\n",
    "df_report.to_csv(\"./data/metrics.csv\")\n",
    "print(\"done.\")\n",
    "\n",
    "display(df_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1563838709232,
     "user": {
      "displayName": "Tonya Di Sera",
      "photoUrl": "https://lh3.googleusercontent.com/-PIQrExnDWnE/AAAAAAAAAAI/AAAAAAAAABk/N0sOhMjcejE/s64/photo.jpg",
      "userId": "15321878092886920267"
     },
     "user_tz": 360
    },
    "id": "VuEnYjYx3ET8",
    "outputId": "a9da4adb-24af-4c5b-f2ba-3e84f0bdf2ba"
   },
   "outputs": [],
   "source": [
    "\n",
    "df_confusion_matrix = pd.DataFrame(best_confusion_matrix)\n",
    "df_precision_by_label = pd.DataFrame(precision_by_label)\n",
    "df_recall_by_label = pd.DataFrame(recall_by_label)\n",
    "\n",
    "print(\"\\nWriting metrics ...\")\n",
    "df_confusion_matrix.to_csv(\"./data/metrics_confusion_matrix.csv\")\n",
    "print(\"done.\")\n",
    "\n",
    "print(\"\\nWriting metrics ...\")\n",
    "df_precision_by_label.to_csv(\"./data/metrics_precision_by_label.csv\")\n",
    "print(\"done.\")\n",
    "\n",
    "print(\"\\nWriting metrics ...\")\n",
    "df_recall_by_label.to_csv(\"./data/metrics_recall_by_label.csv\")\n",
    "print(\"done.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "03_run_classifiers.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
