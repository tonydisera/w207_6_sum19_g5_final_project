{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dRLi1FBsby4R"
   },
   "source": [
    "# W207.6 Final Project - Predicting Cancer Type from Tumor Mutations\n",
    "### Tony Di Sera, Vijay Singh, Rajiv Nair, Jeremey Fraenkel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k9RmDjIzby4S"
   },
   "source": [
    "# Overview\n",
    "\n",
    "In this project, we analyze the tumor mutation dataset from PanCancer Atlas Initiative https://www.cell.com/pb-assets/consortium/pancanceratlas/pancani3/index.html. This is a cancer dataset comprising over 10,000 patients diagnosed with cancer.  Overall, the study collected diverse and detailed molecular information on each patient's tumor, including DNA sequencing.\n",
    "\n",
    "#### Primary Dataset\n",
    "The primary dataset we will be using is the somatic mutations file. This file encodes whether or not a gene was found mutated in the biopsied tumor. In addition, we may pull some patient features like gender and age at diagnosis from the clinical patient file.\n",
    "\n",
    "Number of Instances:  3,600,963 somatic mutations for 10,956 cancer patients\n",
    "Number of Attributes:  ~100 attributes for mutations, ~700 clinical attributes for patients. We will aggregate the mutation data by gene for each patient, reducing the number of attributes by patient to ~ 500-1000 features.\n",
    "\n",
    "#### Background\n",
    "By comparing the DNA from normal tissue cells to those of the cancerous cells, somatic mutations can be identified and characterized. Somatic mutations are non-inherited variations to the DNA of a cell that arise during an individual's lifetime. We will use these DNA mutations to predict cancer type, classified into 33 different tissue/organ types.  \n",
    "\n",
    "#### Motivation\n",
    "There is clinical value in being able to predict cancer type based on molecular profiles.  For some patients diagnosed with cancer, the biopsied tumor doesn't match the histologic characteristics of the organ/tissue site.  For example, a patient may have a liver tumor that cannot be characterized as liver cells when reviewed by the pathologist.  In these cases, the cancer may have originated from another site and has metastasized to the liver.  This is where genomic tumor data may provide insights by predicting the 'cell of origin', leading to a better-suited therapy for the patient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6NrLTq1-bVmt"
   },
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u1NF-T6Jby4U"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "from textwrap import wrap\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import time\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "#import tensorflow as tf\n",
    "#import tensorflow.keras as K\n",
    "#from tensorflow.keras.layers import Dense as Dense\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "#from tensorflow.keras import regularizers\n",
    "#from tensorflow.keras.layers import Dropout\n",
    "#from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "# Establish the colors for each cancer type\n",
    "label_colors = []\n",
    "cm = plt.get_cmap('tab20b')\n",
    "for i in range(20):\n",
    "    label_colors.append(cm(i))\n",
    "cm = plt.get_cmap('tab20c')\n",
    "for i in range(13):\n",
    "    label_colors.append(cm(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "NVVoSJj8by4i",
    "outputId": "78557bfc-1622-4c33-96e3-36e17e0d1a0e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "BLpMLAMqby4l",
    "outputId": "56444f10-50f0-4c22-dbfc-252569929c4e"
   },
   "outputs": [],
   "source": [
    "cd /content/drive/My Drive/berkeley/W207 machine learning/Final Project/w207_6_sum19_g5_final_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "cruqTsRrby4e",
    "outputId": "85cfe90d-4189-4801-d5df-84b5ccbc85c2"
   },
   "outputs": [],
   "source": [
    "if tf.test.gpu_device_name() != '/device:GPU:0':\n",
    "  print('WARNING: GPU device not found.')\n",
    "else:\n",
    "  print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O-7lMnfrby4y"
   },
   "outputs": [],
   "source": [
    "# create the directory where the downloaded directory is stored\n",
    "data_dir = \"./data\"\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    \n",
    "# create the directory where the metrics are stored\n",
    "metrics_dir = \"./metrics\"\n",
    "if not os.path.isdir(metrics_dir):\n",
    "    os.makedirs(metrics_dir)\n",
    "    \n",
    "# create the raw where the source data is stored\n",
    "raw_dir = \"./raw\"\n",
    "if not os.path.isdir(raw_dir):\n",
    "    os.makedirs(raw_dir)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OUYcwsHcIelo"
   },
   "outputs": [],
   "source": [
    "# This loads the data dictionary to will convert\n",
    "# the tumor_sample_barcode into a cancer_type\n",
    "# and provide full names for the cancer types\n",
    "tcga_dict = open(\"./data/tcga_dictionaries.txt\",\"r\")\n",
    "dict_name_index = 0 #Set dictionary index counter to 0\n",
    "for line in tcga_dict:\n",
    "    if line.startswith(\"#\"): #If line starts with #, the next line will be a known dictionary\n",
    "        dict_name_index += 1\n",
    "    elif dict_name_index == 4:\n",
    "        tissue_source_site = eval(line)            \n",
    "    elif dict_name_index == 5:\n",
    "        code_to_disease = eval(line)\n",
    "    elif dict_name_index == 6:\n",
    "        disease_to_code = eval(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CwztM4ufby4r"
   },
   "source": [
    "# Data Collection\n",
    "For our analysis of cancer prediction using gene mutation and clinical data from patients, we will gather data from multiple sources. First we obtain the somatic mutation data from the PanCancerAtlas website (https://gdc.cancer.gov/about-data/publications/pancanatlas). We also download the patient clinical data that corresponds to the tumor data. At this time, we are not bringing in clinical features, but as the project progresses, we would like to bring in a few features from this clinical dataset (e.g. age a diagnosis, gender). In our notebook, we store this data locally so that it does not have to be downloaded if the notebook kernel is restarted and run multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7jjFc_fPby4t"
   },
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xBHddXTxby42"
   },
   "source": [
    "### Download the somatic mutations file\n",
    "This file is in the 'MAF' file format, a bioinformatics tab separated format that can contains one record\n",
    "for each mutation observed in a patient tumor sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "dhq1fgDQby43",
    "outputId": "8adbf6e5-df60-4ed7-fdc1-5f60879f3df8"
   },
   "outputs": [],
   "source": [
    "# This downloads a 753 MB somatic mutations gzip file.  \n",
    "# This will take about 1-5 mins depending on your\n",
    "# connection speed.\n",
    "mutations_filename = \"./data/somatic_mutations.maf.gz\"\n",
    "if os.path.isfile(mutations_filename):\n",
    "    print(\"Skipping download, as file %s is present\" %(mutations_filename))\n",
    "else:\n",
    "    print('Downloading mutation data. 753 MB (may take a few minutes)...')\n",
    "    url = 'http://api.gdc.cancer.gov/data/1c8cfe5f-e52d-41ba-94da-f15ea1337efc'  \n",
    "    urllib.request.urlretrieve(url, mutations_filename)  \n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KhvgITq4by49"
   },
   "source": [
    "### Download the patient clinical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "r0S2a32Mby4_",
    "outputId": "22111da1-6265-4b72-db05-aca5a8a90f2e"
   },
   "outputs": [],
   "source": [
    "# This downloads an 18 MB patient clinical data file\n",
    "patient_filename = \"./data/patient_clinical_data.txt\"\n",
    "if os.path.isfile(patient_filename):\n",
    "    print(\"Skipping download, as file %s is present\" %(patient_filename))\n",
    "else:\n",
    "    print('Downloading clinical data ...')  \n",
    "    url = 'http://api.gdc.cancer.gov/data/0fc78496-818b-4896-bd83-52db1f533c5c'\n",
    "    urllib.request.urlretrieve(url, patient_filename)  \n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4kvYce6by5P"
   },
   "source": [
    "## Loading Gene Mutation Data ##\n",
    "\n",
    "Here we read the gene mutation data. This data file contains many columns, but after careful curation, we have decided to consider the following colums:\n",
    "\n",
    "1. **tumor_sample_barcode**: this contains the barcode with the first 12 characters identifying the patient\n",
    "2. **gene**: this is the actual gene that has been mutated (for e.g. TACC2, JAKMIP3, PANX3)\n",
    "3. **gene_type**: this indicates if the gene is protein coding or not.\n",
    "4. **chromosome**  **start** **end** **Strand**: the chromosome, start position and end position tells us the location of the gene where the mutation is seen.  Strand indicates if it is on the forward or reverse strand of the DNA.\n",
    "5. **variant_type**: this indicates if it is a single substitution mutation (SNP), a small deletion (DEL), or small insertion (INS), two nucleotide substitution (DNP), three nucleotide substitution (TNP), or more that three nucleotide substitution (ONP)\n",
    "6. **variant_classification**: this indicates what kind of molecular effect that this mutation will have on the protein.  The most common classes indicate if the substitution causes a change to the amino acid (missense vs silent).  Nonsense mutations cause premature termination of the protein; frameshift mutations cause a misreading of the amino acid sequence.\n",
    "7. **variant_impact**: this indicates how damaging the mutation -- HIGH, MODERATE, MODIFIER, or LOW.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "Yd2EN_vWby5Q",
    "outputId": "7c77c380-ef6d-4717-820b-3de3ed2bb11f"
   },
   "outputs": [],
   "source": [
    "# Load the mutations dataframe\n",
    "print('Loading mutations dataframe ...')\n",
    "\n",
    "mutations = pd.read_csv(mutations_filename, compression='gzip',\n",
    "                        sep='\\t',\n",
    "                        usecols=['Tumor_Sample_Barcode','Hugo_Symbol', 'BIOTYPE',\n",
    "                                'Chromosome', 'Start_Position',  'End_Position', 'Strand',\n",
    "                                'Variant_Type',  'Variant_Classification', 'IMPACT' ])\n",
    "\n",
    "print(\"done.\")\n",
    "\n",
    "# Set mutations index\n",
    "mutations['row'] = np.arange(len(mutations))\n",
    "mutations.set_index('row', inplace=True)\n",
    "\n",
    "# Rename the columns to more consistent names\n",
    "renamed_columns = { 'Tumor_Sample_Barcode': 'tumor_sample_barcode', \n",
    "                    'Hugo_Symbol': 'gene', \n",
    "                    'BIOTYPE': 'gene_type', \n",
    "                    'Chromosome': 'chromosome', \n",
    "                    'Start_Position': 'start', \n",
    "                    'End_Position': 'end', \n",
    "                    'Strand': 'strand', \n",
    "                    'Variant_Type': 'variant_type', \n",
    "                    'Variant_Classification': 'variant_classification', \n",
    "                    'IMPACT': 'variant_impact'}\n",
    "mutations.rename(renamed_columns, inplace=True, axis=1)\n",
    "\n",
    "\n",
    "print(\"\\nMutations count:       \", mutations.tumor_sample_barcode.count())\n",
    "print(\"Number of unique samples:\", mutations.tumor_sample_barcode.nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oa9ZzcE-by5V"
   },
   "source": [
    "The actual cancer type can be found by parsing the tumor sample barcode and then looking up\n",
    "the cancer type code in the dictionary based on the tissue source site portion of the\n",
    "tumor sample barcode. For e.g., the *tumor_sample_barcode* 'TCGA-ZX-AA5X-01A-11D-A42O-09' will be parsed into the *tissue source site* **ZX** that is then mapped using the tissue cancer dictionary to *Cervical_squamous_cell_carcinoma_and_endocervical_adenocarcinoma* or *CESC*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "r8g4F_P-by5X",
    "outputId": "8b8e7bb0-9808-4a7e-8ce3-89718517f664"
   },
   "outputs": [],
   "source": [
    "# Parse the tissue source site from the tumor sample barcode.  Then use the\n",
    "# tissue site source to lookup the cancer type from the tcga_dictionaries\n",
    "def parse_cancer_type(tumor_sample_barcode):\n",
    "    tss = tumor_sample_barcode.split(\"-\")[1] #Extra the tissue source site from the tcga_id\n",
    "    cancer_type = disease_to_code[tissue_source_site[tss][1]][0] #Convert from tss to disease to code \n",
    "    return cancer_type\n",
    "\n",
    "\n",
    "mutations['cancer_type'] = mutations['tumor_sample_barcode'].apply(parse_cancer_type)\n",
    "print(\"Number of unique cancer types:\", mutations.cancer_type.nunique())\n",
    "\n",
    "\n",
    "# Get the patient barcode.  This is what we will use to join the mutations to the clinical data\n",
    "def parse_patient_barcode(tumor_sample_barcode):\n",
    "        return tumor_sample_barcode[0:12]\n",
    "\n",
    "mutations['patient_barcode'] = mutations['tumor_sample_barcode'].apply(parse_patient_barcode)\n",
    "#mutations = mutations.drop(['tumor_sample_barcode'], axis=1)\n",
    "#mutations = mutations.drop(['cancer_type'], axis=1)\n",
    "print(\"Number of unique patients:\", mutations['patient_barcode'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JQh6yuqRby5a"
   },
   "source": [
    "## Loading Patient Data##\n",
    "\n",
    "Here we load the clinical data. This is data for patients for whom we collected the gene mutation data above. The patients are identified by $patient\\_barcode$. We will use this field to populate the gene mutation data from the dataframe above in the table we are about to read. The clinical data has patient information such as gender and age at diagnosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "colab_type": "code",
    "id": "eYTG-tYNby5c",
    "outputId": "b6e938af-edaf-474b-ebc9-41c4f245e00d"
   },
   "outputs": [],
   "source": [
    "# Load the clinical data\n",
    "print('Loading clinical dataframe ...')\n",
    "clinical = pd.read_csv(patient_filename, sep='\\t',\n",
    "                        usecols=['bcr_patient_barcode', 'acronym', 'gender', \n",
    "                                 'age_at_initial_pathologic_diagnosis'])\n",
    "\n",
    "# Rename the columns to more consistent names\n",
    "renamed_columns = { 'bcr_patient_barcode': 'patient_barcode', \n",
    "                    'acronym': 'cancer_type' }\n",
    "clinical.rename(renamed_columns, inplace=True, axis=1)\n",
    "\n",
    "print('Clinical count', clinical.patient_barcode.count())\n",
    "\n",
    "# Get cancer types\n",
    "cancer_types = clinical['cancer_type'].unique()\n",
    "print(\"\\nNumber of cancer types\", len(cancer_types))\n",
    "\n",
    "# Get number of cases per cancer type\n",
    "group_by_patient = clinical.groupby(['cancer_type'])['patient_barcode'].nunique()\n",
    "print(\"Number of patients\", group_by_patient.sum())\n",
    "group_by_patient.plot.bar(figsize=(12,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above histogram, we can already see a challenge that we will be faced with in this work. While some cancers such as BRCA (Breast Cancer) have a large number of cases represented in the dataset, other such as Uterine Carcinosarcoma (UCS) have very few cases. We will pay special attention to the robustness of our classifiers in being able to classify the rarer cases with high accuracy as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "nBlojNNBKXsU",
    "outputId": "fe530414-bb02-4708-a143-0f479cdf5162"
   },
   "outputs": [],
   "source": [
    "# Show cancer types that would be filtered out if examples < 60\n",
    "display(group_by_patient[group_by_patient <= 60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qsrJ5cyTby5g"
   },
   "source": [
    "## Creating Merged Data ##\n",
    "\n",
    "Now that we have both gene and cancer data in one dataframe, and the patient clinical data in another dataframe, we will use the **patient_barcode** to merge these into a single table. With this, we can drop the tumor_sample_barcode column, since it has served its purpose. Looking at the data, it seems like some patient data is missing from the gene data. Simultaneously, some data in the gene dataframe does not have corresponding clinical data. Hence our merged dataframe size will be lower than the original mutations dataframe size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Cjg0NcQ9by5l",
    "outputId": "b7fa7047-7179-4a9a-dee9-0cf8a4aba93a"
   },
   "outputs": [],
   "source": [
    "clinical['patient_barcode'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "gbdYkzQDby5o",
    "outputId": "e617a775-8066-42e0-c78b-94affe19206f"
   },
   "outputs": [],
   "source": [
    "missing_count = 0\n",
    "gene_barcode_set = set(mutations.patient_barcode.unique())\n",
    "for bc in gene_barcode_set:\n",
    "    if bc not in set(clinical.patient_barcode.unique()):\n",
    "        missing_count += 1\n",
    "print(\"%d patients with gene data missing in clinical data\" %missing_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "wACcMmb8by5s",
    "outputId": "abb864f9-b1bf-40f5-f244-b4fdcf897b9a"
   },
   "outputs": [],
   "source": [
    "# perform the merge\n",
    "merged = mutations.merge(clinical, left_on='patient_barcode', right_on='patient_barcode')\n",
    "print('Merged mutations count:   ', merged.patient_barcode.count())\n",
    "print('Number of unique patients:', merged.patient_barcode.nunique())\n",
    "merged.rename({'cancer_type_x': 'cancer_type'}, axis=1, inplace=True)\n",
    "print('Number of cancer types:   ', merged.cancer_type.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "68LWlgM1yDoD",
    "outputId": "a2e33aad-a9e3-470e-d0ee-d1c03a35d61c"
   },
   "outputs": [],
   "source": [
    "# store the merged data, and the mutations data into csv format\n",
    "fileName = \"./data/mutations_with_clinical.csv\"\n",
    "print(\"  writing\", fileName, \"...\")\n",
    "merged.to_csv(fileName)\n",
    "print(\"  done.\")\n",
    "\n",
    "fileName = \"./data/mutations.csv\"\n",
    "print(\"  writing\", fileName, \"...\")\n",
    "mutations.to_csv(fileName)\n",
    "print(\"  done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c_5rUleqby5v"
   },
   "source": [
    "## Eliminate any psuedo-genes. \n",
    "\n",
    "This is a common filter in bioinformatics analysis, eliminating pseudo-genes.  These are imperfect copies of functional genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "o6w0mLCnby5y",
    "outputId": "938ec2db-6c7d-42eb-c729-fc886ad3c1eb"
   },
   "outputs": [],
   "source": [
    "# Eliminate psuedo genes\n",
    "psuedo_genes = list(['transcribed_unprocessed_pseudogene',\n",
    "               'polymorphic_pseudogene', \n",
    "               'unprocessed_pseudogene', \n",
    "               'transcribed_processed_pseudogene', 'processed_pseudogene',\n",
    "               'pseudogene', 'unitary_pseudogene'])\n",
    "\n",
    "before_count               = mutations.gene.nunique()\n",
    "mutations_coding           = mutations[~mutations.gene_type.isin(psuedo_genes)]\n",
    "after_count                = mutations_coding.gene.nunique()\n",
    "print(\"Filtered out \", str(before_count - after_count), \"genes\")\n",
    "mutations                  = mutations_coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JQbPODWCby53"
   },
   "source": [
    "## Split the data into training and test datasets\n",
    "Split the data into a training and test split.  We will use a split of 80% training, 20% test.  \n",
    "We will split based on the patient_barcode.  As part of feature engineering, we will be \n",
    "aggregating mutations, so that each example will be represented as a patient (tumor), with\n",
    "columns for each gene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cd-x03T6O_dV"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Split the patients into training and test\n",
    "#\n",
    "def split_patient_data(data):\n",
    "    patient_data = data.patient_barcode.unique()\n",
    "\n",
    "    le     = preprocessing.LabelEncoder()\n",
    "    patient_labels_string = data.groupby('patient_barcode')['cancer_type'].nunique()\n",
    "    patient_labels = le.fit_transform(patient_labels_string)\n",
    "    \n",
    "    print(\"Number of unique patients:           \", patient_data.shape[0])\n",
    "    print(\"Number of labels for unique patients:\", len(patient_labels))\n",
    "    \n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "                                                               patient_data, patient_labels,\n",
    "                                                               stratify=patient_labels, \n",
    "                                                               test_size=0.20)\n",
    "\n",
    "    print(\"\\ntraining patients:  \", train_data.shape[0])\n",
    "    print(\"test patients:      \", test_data.shape[0])\n",
    "    return {'train_patients': train_data, 'test_patients': test_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "w9LaNpshby56",
    "outputId": "58327975-d443-4a24-b8a5-6ab179e84a24"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#  Split Mutations data (based on patient split) and \n",
    "#  write out data files\n",
    "#\n",
    "def split_and_save_mutation_data(split):   \n",
    "    train_patients = split['train_patients']\n",
    "    test_patients  = split['test_patients']\n",
    "\n",
    "    train_mutations = mutations[mutations.patient_barcode.isin(train_patients)]\n",
    "    test_mutations  = mutations[mutations.patient_barcode.isin(test_patients)]\n",
    "    print(\"\\ntraining data:      \", train_mutations.shape[0])\n",
    "    print(\"test data:          \", test_mutations.shape[0])\n",
    "    print(\"\\nall data:           \", test_mutations.shape[0])\n",
    "    print(\"train + test:       \", test_mutations.shape[0] + test_mutations.shape[0])\n",
    "    \n",
    "    # Write out mutations training data as csv file\n",
    "    print(\"\\nWriting training set ...\")\n",
    "    train_mutations.to_csv(\"./data/somatic_mutations_train.csv\")\n",
    "    print(\"done.\")\n",
    "\n",
    "    # Write out mutations test data as csv file\n",
    "    print(\"\\nWriting test set ...\")\n",
    "    test_mutations.to_csv(\"./data/somatic_mutations_test.csv\")\n",
    "    print(\"done.\")\n",
    "\n",
    "split = split_patient_data(mutations)   \n",
    "split_and_save_mutation_data(split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3mPJcoSFby5-"
   },
   "source": [
    "# EDA and Feature Selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_BIML2_wby6G"
   },
   "source": [
    "Here, we open the data we put together in the previous notebook. For the initial analysis, we look at $cancer\\_type$, $patient\\_barcode$, $gene$ and $gene\\_type$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZPZLk5W3MZXp"
   },
   "source": [
    "### Load the mutations train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "QzRDob5dby6I",
    "outputId": "c048774a-c487-435c-decc-37ccd9ea40b6"
   },
   "outputs": [],
   "source": [
    "print('Loading data ...')\n",
    "mutations = {}\n",
    "mutations['train'] = pd.read_csv(\"./data/somatic_mutations_train.csv\", \n",
    "                             usecols=['cancer_type', 'patient_barcode', 'gene', 'gene_type'])\n",
    "mutations['test']  = pd.read_csv(\"./data/somatic_mutations_test.csv\", \n",
    "                             usecols=['cancer_type', 'patient_barcode', 'gene', 'gene_type'])\n",
    "print(\"done.\")\n",
    "print(\"Mutations training data count:\", mutations['train']['patient_barcode'].count())\n",
    "print(\"Mutations test data count:    \", mutations['test']['patient_barcode'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s46QHIn-by6O"
   },
   "source": [
    "### Show distribution of genes across patient tumors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "s6V9M_2xby6P",
    "outputId": "06fdce1a-7dc9-4e21-8715-3ca5a190db53"
   },
   "outputs": [],
   "source": [
    "print(\"Number of genes across all patient tumors:\", mutations['train'].gene.nunique())\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "#\n",
    "# Show how many genes are mutation in a patient tumor\n",
    "#\n",
    "group1         = mutations['train'].groupby(['patient_barcode'])['gene'].nunique().reset_index(name='count')\n",
    "group1.columns = ['patient', 'gene_count']\n",
    "ax = group1['gene_count'].hist(bins=200, figsize=(12,4))\n",
    "_ = ax.set_xlabel(\"Number of Genes\")\n",
    "_ = ax.set_ylabel(\"Patient Tumor Frequency\")\n",
    "_ = ax.set_title(\"Distribution of Genes for a Patient Tumor\", fontsize=20)\n",
    "plt.show()\n",
    "print('Number of genes per patient tumor')\n",
    "print(\"  min, max:\", int(group1['gene_count'].min()), ',', int(group1['gene_count'].max()))\n",
    "print(\"  mean    :\", int(group1['gene_count'].mean()))\n",
    "print(\"  median  :\", int(group1['gene_count'].median()))\n",
    "print(\"\\n\")\n",
    "\n",
    "#\n",
    "# Show now many tumors contain the same gene\n",
    "#\n",
    "group2         = mutations['train'].groupby(['gene'])['patient_barcode'].nunique().reset_index(name='count')\n",
    "group2.columns = ['gene', 'patient_count']\n",
    "ax = group2['patient_count'].hist(bins=50, figsize=(12,4))\n",
    "_ = ax.set_xlabel(\"Number of Patient Tumors\")\n",
    "_ = ax.set_ylabel(\"Gene Frequency\")\n",
    "_ = ax.set_title(\"Distribution of Patients for a Gene\", fontsize=20)\n",
    "plt.show()\n",
    "print('Number of patient tumors with same mutated gene')\n",
    "print(\"  min, max:\", int(group2['patient_count'].min()), ',', int(group2['patient_count'].max()))\n",
    "print(\"  mean    :\", int(group2['patient_count'].mean()))\n",
    "print(\"  median  :\", int(group2['patient_count'].median()))\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "#\n",
    "# Show now many cancer types contain the same gene\n",
    "#\n",
    "gene_cc_count         = mutations['train'].groupby(['gene'])['cancer_type'].nunique().reset_index(name='count')\n",
    "gene_cc_count.columns = ['gene', 'cancer_type_count']\n",
    "gene_cc_count         = gene_cc_count.sort_values(['cancer_type_count', 'gene'], ascending=[0,1])\n",
    "ax = gene_cc_count['cancer_type_count'].hist(bins=40, figsize=(12,4))\n",
    "_ = ax.set_xlabel(\"Number of Cancer Types\")\n",
    "_ = ax.set_ylabel(\"Gene Frequency\")\n",
    "_ = ax.set_title(\"Genes in common across many cancer types\", fontsize=20)\n",
    "plt.show()\n",
    "print('\\nNumber of cancer types with same mutated gene')\n",
    "print(\"  min, max: \", int(gene_cc_count['cancer_type_count'].min()), ',', int(gene_cc_count['cancer_type_count'].max()))\n",
    "print(\"  mean    :\", int(gene_cc_count['cancer_type_count'].mean()))\n",
    "print(\"  median  :\", int(gene_cc_count['cancer_type_count'].median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F792XmEdby6S"
   },
   "source": [
    "From the histogram above, it is clear that even through we have a large number of genes, only a small number of them are turned on in the patient tumor data that we have. This is the classic problem of a large feature space with a much smaller number of samples. Hence we will need to perform a dimensionality reduction technique such as PCA here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "colab_type": "code",
    "id": "oAGvg71Mby6T",
    "outputId": "d75db9fe-c877-47e2-bacc-7849cb461c32"
   },
   "outputs": [],
   "source": [
    "# Print out the number of cancer types that are present in the \n",
    "# mutations dataset\n",
    "cancer_types = mutations['train'].cancer_type.unique()\n",
    "print(\"\\nNumber of cancer types:\", len(cancer_types))\n",
    "\n",
    "# Get number of cases per cancer type\n",
    "group_patients_by_cancer = mutations['train'].groupby(['cancer_type'])['patient_barcode'].nunique()\n",
    "print(\"Number of patients    :\", group_patients_by_cancer.sum())\n",
    "print(\"\\n\")\n",
    "ax = group_patients_by_cancer.plot.bar(figsize=(12,4))\n",
    "_ = ax.set_title(\"Number of patient tumors for each cancer type\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MVQDdYSEby6Y"
   },
   "source": [
    "The above chart shows that there are some cancers, such as BRCA and LUAD that have a large representation in our dataset, but other such as DBLC and UCS that are present in much smaller numbers. This will present a challenge for our classifier. Specifically, we want our classifier to be able to classify each of the 32 types of cancers with high precision, but the model should also be able to identify the cancers that don't have a proportionate representation in our data set. It could be that these are cancers are rare, or perhaps they are simply rare in our dataset. **Note:** add more details about the cancers that are abundant as well as rare in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "5ZdmTtEcby6a",
    "outputId": "94886669-b771-4012-9dda-78c0f6b29c36"
   },
   "outputs": [],
   "source": [
    "# Get the unique genes per cancer type\n",
    "group_genes_by_cancer = mutations['train'].groupby(['cancer_type'])['gene'].nunique();\n",
    "\n",
    "print(\"Number of genes in each cancer type\")\n",
    "print(\"  min, max:\", int(np.round(group_genes_by_cancer.min())), ',', int(np.round(group_genes_by_cancer.max())))\n",
    "print(\"  mean    :\", int(np.round(group_genes_by_cancer.mean())))\n",
    "print(\"  median  :\", int(np.round(group_genes_by_cancer.median())))\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "ax = group_genes_by_cancer.plot.bar(figsize=(12,4))\n",
    "_ = ax.set_title(\"Number of genes for each cancer type\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2IXUjEdQby6d"
   },
   "source": [
    "The above bar chart gives us an idea of how many genes (features for us) are _on_ for each of the cancer types. Cross referencing this chart with the previous one, we see that for some cancers such as DLBC and UCS we have a fair number of active features, even though the number of cases of such cancers are low. We should be able to person isolated (one-vs-rest) analysis for these cases. However, for other cancers, such as KICH (Kidney Chromophobe) and UVM (Uveal Melanoma) we have both a low occurance rate, and a low number of active features. This second category of cancers will need to be handled with care."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9jFCSDGTby65"
   },
   "source": [
    "## Create different feature sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From an initial analysis of our data, we can see that we have a large number of features (binary encoded gene mutations), and the number of features is greater than the number of samples that we have. Even before we try any dimentionality reduction technique such as PCA, we can use other tools to reduce the number of features. One such method is the scikit utility **SelectKBest**. This utility routine can apply the **Chi-Square** test to select the specified number of best features. Another method is to use a LogisticRegression Classifier with L1 regularization and an appropriate C value. This will drive down the coefficients of non-important features to 0, which can then be removed. We try multiple such methods below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "34Y8A5wuby6e"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Create feature matrix each row is a patient tumor; each column is a gene\n",
    "#\n",
    "def create_patient_x_gene_matrix(mutations, feature_genes, description, save=True):\n",
    "    cases = list()\n",
    "    grouped = mutations.groupby('patient_barcode')\n",
    "    i = int(0)\n",
    "\n",
    "    cols = ['case_id', 'cancer_type']\n",
    "    for gene in feature_genes:\n",
    "        cols.append(gene)\n",
    "\n",
    "    for name, group in grouped:\n",
    "        case = list()\n",
    "        case.append(name)\n",
    "        for cc in group.cancer_type.head(1):\n",
    "            case.append(cc)\n",
    "\n",
    "        for gene_flag in feature_genes.isin(group.gene.unique()):\n",
    "            switch = 0\n",
    "            if gene_flag == True:\n",
    "                switch = 1\n",
    "            case.append(switch)\n",
    "        cases.append(case)\n",
    "\n",
    "    cases_df = pd.DataFrame(cases)\n",
    "    cases_df.columns = cols\n",
    "    print(\"  \", cases_df.shape)\n",
    "    \n",
    "    # Write out transformed data to csv\n",
    "    if save:\n",
    "        fileName = \"./data/\" + description + \".csv\"\n",
    "        print(\"  writing\", fileName, \"...\")\n",
    "        cases_df.to_csv(fileName)\n",
    "        print(\"  done.\")\n",
    "    \n",
    "    return cases_df\n",
    "\n",
    "#\n",
    "# Create a feature matrix based on most frequent genes in each cancer type\n",
    "#\n",
    "def create_feature_matrix(mutations_train, mutations_test, top_n_gene_count, save, description):\n",
    "    print(\"Formatting gene matrix with top \", top_n_gene_count, \"genes from each cancer type\")\n",
    "    \n",
    "    # Now try to find the most common genes per cancer type and\n",
    "    # merge these together to come up with a master list\n",
    "    cancer_gene_count = mutations_train.groupby(['cancer_type', 'gene'])['patient_barcode'].nunique().reset_index(name='count')\n",
    "    cancer_gene_count.columns = ['cancer_type', 'gene', 'patient_count']\n",
    "\n",
    "    # Now create a large matrix, row is the gene, column for each cancer type\n",
    "    df = pd.DataFrame(cancer_gene_count, columns=['cancer_type', 'gene', 'patient_count'])\n",
    "    gene_cancer_matrix = pd.pivot_table(df, values='patient_count', index=['gene'],\n",
    "                         columns=['cancer_type'], aggfunc=np.sum, fill_value=0)\n",
    "\n",
    "    # Now find the top n genes for each cancer type\n",
    "    top_genes = []\n",
    "    idx = 0\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "    for cancer_type in gene_cancer_matrix.columns:\n",
    "        sorted_genes = gene_cancer_matrix[cancer_type].sort_values(ascending=False)\n",
    "        top_rows = sorted_genes[sorted_genes > 0].head(top_n_gene_count)\n",
    "        for gene, patient_count in top_rows.items():\n",
    "            top_genes.append(list([cancer_type, gene, patient_count]))\n",
    "\n",
    "    # Turn this back into a matrix, row is gene, column for each cancer type\n",
    "    top_df = pd.DataFrame(top_genes, columns=['cancer_type', 'gene', 'patient_count'])\n",
    "    top_gene_cancer_matrix = pd.pivot_table(top_df, values='patient_count', index=['gene'],\n",
    "                         columns=['cancer_type'], aggfunc=np.sum, fill_value=0)\n",
    "    print(\"  number of genes:\", top_gene_cancer_matrix.shape[0])\n",
    "   \n",
    "    feature_genes = top_gene_cancer_matrix.index\n",
    "    create_patient_x_gene_matrix(mutations_train, feature_genes, description + \".train\", save)\n",
    "    create_patient_x_gene_matrix(mutations_test,  feature_genes, description + \".test\", save)\n",
    "    \n",
    "#\n",
    "# Create a feature matrix for all genes in tumor mutations\n",
    "#\n",
    "def create_all_feature_matrix(mutations_train, mutations_test, save, description):\n",
    "    print(\"Formatting gene matrix with for all features\")\n",
    "    #\n",
    "    # Create feature matrix, each row is patient, columns are genes\n",
    "    #\n",
    "    feature_genes = pd.Series(mutations_train.gene.unique())\n",
    "    feature_matrix_train = create_patient_x_gene_matrix(mutations_train, feature_genes, description + \".train\", save)\n",
    "    feature_matrix_test  = create_patient_x_gene_matrix(mutations_test,  feature_genes, description + \".test\", save)\n",
    "    return feature_matrix_train, feature_matrix_test\n",
    "  \n",
    "#\n",
    "# Run KBestFit to determine most discriminatory genes\n",
    "#\n",
    "def get_best_fit_features(feature_matrix, n_features):\n",
    "    #apply SelectKBest class to extract top n best features\n",
    "    bestfeatures = SelectKBest(score_func=chi2, k=n_features)\n",
    "    \n",
    "    data = feature_matrix.loc[:, (feature_matrix.columns != 'cancer_type') & (feature_matrix.columns != 'case_id')]\n",
    "    labels_string = feature_matrix['cancer_type']\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    labels = le.fit_transform(labels_string)\n",
    "    \n",
    "    fit = bestfeatures.fit(data,labels)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(data.columns)\n",
    "    \n",
    "    #concat two dataframes for better visualization \n",
    "    scores_df = pd.concat([dfcolumns,dfscores], axis=1)\n",
    "    scores_df.columns = ['gene', 'score']\n",
    "    sorted_scores = scores_df.sort_values(by=['score', 'gene'], ascending=[0,1])\n",
    "    return sorted_scores.gene.values\n",
    " \n",
    "#\n",
    "# Create a feature matrix based on genes ranked highest using KBestFit\n",
    "#\n",
    "def create_best_fit_feature_matrix(feature_matrix_train, feature_matrix_test,  \n",
    "                               save, description):\n",
    "    #\n",
    "    #  Try BestFit (chi squared test) to find most\n",
    "    #  important genes\n",
    "    #\n",
    "    k_best_fits = [100, 700, 1000, 5000, 8000]\n",
    "    print(\"Running KBestFit\")\n",
    "    best_genes_ranked  = get_best_fit_features(feature_matrix_train, 8000)\n",
    "    \n",
    "    print(\"  done.\")\n",
    "\n",
    "    for k_best in k_best_fits:\n",
    "        print(\"Creating gene matrix with best fit for\", k_best, \"features\")\n",
    "        best_genes = best_genes_ranked[:k_best]\n",
    "        print(len(best_genes))\n",
    "      \n",
    "        cancer_type = feature_matrix_train['cancer_type']\n",
    "        case_id     = feature_matrix_train['case_id']\n",
    "        data_train  = feature_matrix_train.loc[:, feature_matrix_train.columns.isin(best_genes)]\n",
    "        final_feature_matrix_train = pd.concat([case_id, cancer_type, data_train], axis=1)\n",
    "\n",
    "        cancer_type = feature_matrix_test['cancer_type']\n",
    "        case_id     = feature_matrix_test['case_id']\n",
    "        data_test   = feature_matrix_test.loc[:, feature_matrix_test.columns.isin(best_genes)]\n",
    "        final_feature_matrix_test = pd.concat([case_id, cancer_type, data_test], axis=1)\n",
    "\n",
    "        if save:\n",
    "            fileName = \"./data/\" + description  + \"_\" + str(k_best) + \".train.csv\"\n",
    "            print(\"  writing\", fileName, \"...\")\n",
    "            print(\" \", final_feature_matrix_train.shape)\n",
    "            final_feature_matrix_train.to_csv(fileName)\n",
    "            print(\"  done.\")        \n",
    "\n",
    "            fileName = \"./data/\" + description  + \"_\" + str(k_best) + \".test.csv\"\n",
    "            print(\"  writing\", fileName, \"...\")\n",
    "            print(\" \", final_feature_matrix_test.shape)\n",
    "            final_feature_matrix_test.to_csv(fileName)\n",
    "            print(\"  done.\") \n",
    "\n",
    "#\n",
    "# Create a different feature matrix based on changing L1 regularization strength\n",
    "#\n",
    "def create_l1_feature_matrix(train_features, test_features, label_encoder, description, save):\n",
    "    \n",
    "    train_first_cols    = train_features[train_features.columns[:2]]\n",
    "    train_data          = train_features[train_features.columns[3:]]\n",
    "    train_labels        = label_encoder.fit_transform(train_features.cancer_type)\n",
    "\n",
    "    test_first_cols    = test_features[test_features.columns[:2]]\n",
    "    test_data          = test_features[test_features.columns[3:]]\n",
    "    test_labels        = label_encoder.fit_transform(test_features.cancer_type)\n",
    "\n",
    "    params = {'C':  [100, 10, 1, .5, .25, .1, .05, .025 ]}\n",
    "    \n",
    "    for c_param in reversed(params['C']):\n",
    "        # Keep this random seed here to make comparison easier.\n",
    "        np.random.seed(0)\n",
    "\n",
    "        #\n",
    "        # Perform Logistic Regression on different C values\n",
    "        # using L1 regularization\n",
    "        #\n",
    "        l1 = LogisticRegression(penalty='l1', tol=.01, \n",
    "                            solver=\"liblinear\", multi_class=\"ovr\",\n",
    "                            max_iter=500, C=c_param)\n",
    "        # Fit model\n",
    "        l1.fit(train_data, train_labels) \n",
    "\n",
    "\n",
    "        # Get the features with non-zero coefficients.  We will use\n",
    "        # this list to reduce the features \n",
    "        non_zero_sums = np.where(np.sum(l1.coef_, axis=0) != 0)\n",
    "        names = np.array(list(train_data.columns))\n",
    "        non_zero_genes = names[non_zero_sums] \n",
    "\n",
    "\n",
    "        #\n",
    "        # Reduce feature size, only keeping features with non-zero weights \n",
    "        # found using l1 regularization\n",
    "        #\n",
    "        trimmed_train_data = train_data[non_zero_genes]\n",
    "        trimmed_test_data  = test_data[non_zero_genes]\n",
    "        \n",
    "        final_features_train = pd.concat([train_first_cols, trimmed_train_data], axis=1)\n",
    "        final_features_test =  pd.concat([test_first_cols, trimmed_test_data], axis=1)\n",
    "        \n",
    "        if save:\n",
    "            fileName = \"./data/\" + description + \"_c\" + str(c_param) + \".train.csv\"\n",
    "            print(\"  writing\", fileName, \"...\")\n",
    "            print(\" \", final_features_train.shape)\n",
    "            final_features_train.to_csv(fileName)\n",
    "            print(\"  done.\")        \n",
    "\n",
    "            fileName = \"./data/\" + description + \"_c\" + str(c_param) + \".test.csv\"\n",
    "            print(\"  writing\", fileName, \"...\")\n",
    "            print(\" \", final_features_test.shape)\n",
    "            final_features_test.to_csv(fileName)\n",
    "            print(\"  done.\")        \n",
    "            \n",
    "#\n",
    "# Create a feature matrix using recursive feature elimination\n",
    "#\n",
    "def create_rfe_feature_matrix(train_features, test_features, label_encoder, \n",
    "                              classifier, n_features, n_step,\n",
    "                              description, save):\n",
    "\n",
    "    \n",
    "    train_first_cols    = train_features[train_features.columns[:2]]\n",
    "    train_data          = train_features[train_features.columns[3:]]\n",
    "    train_labels        = label_encoder.fit_transform(train_features.cancer_type)\n",
    "\n",
    "    test_first_cols    = test_features[test_features.columns[:2]]\n",
    "    test_data          = test_features[test_features.columns[3:]]\n",
    "    test_labels        = label_encoder.fit_transform(test_features.cancer_type)\n",
    "    \n",
    "\n",
    "    rfe = RFE(estimator=classifier, n_features_to_select=n_features, step=n_step, verbose=3)\n",
    "    rfe.fit(train_data, train_labels)\n",
    "    \n",
    "    trimmed_train_data = train_data[train_data.columns[rfe.support_]]\n",
    "    trimmed_test_data  = test_data[test_data.columns[rfe.support_]]\n",
    "    \n",
    "    final_features_train = pd.concat([train_first_cols, trimmed_train_data], axis=1)\n",
    "    final_features_test =  pd.concat([test_first_cols, trimmed_test_data], axis=1)\n",
    "    \n",
    "\n",
    "    if save:\n",
    "        fileName = \"./data/\" + description +  \".train.csv\"\n",
    "        print(\"  writing\", fileName, \"...\")\n",
    "        print(\" \", final_features_train.shape)\n",
    "        final_features_train.to_csv(fileName)\n",
    "        print(\"  done.\")        \n",
    "\n",
    "        fileName = \"./data/\"+ description + \".test.csv\"\n",
    "        print(\"  writing\", fileName, \"...\")\n",
    "        print(\" \", final_features_test.shape)\n",
    "        final_features_test.to_csv(fileName)\n",
    "        print(\"  done.\")        \n",
    "    \n",
    "    return final_features_train, final_features_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6eBT5ZZ1by7K"
   },
   "source": [
    "### All genes\n",
    "\n",
    "Create a feature matrix,  Feature matrix will have one row per patient tumor, \n",
    "column for every gene encountered in training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "ZNTgFiHnby7O",
    "outputId": "cc4c915f-9549-4e8d-cd97-502973cf70aa"
   },
   "outputs": [],
   "source": [
    "all_train_file = './data/features_all.train.csv'\n",
    "all_test_file = './data/features_all.test.csv'\n",
    "if os.path.isfile(all_train_file) and os.path.isfile(all_test_file):\n",
    "    print(\"Skipping generation, files %s and %s are present.\" %(all_train_file, all_test_file))\n",
    "else:\n",
    "    feature_matrix_train, feature_matrix_test = create_all_feature_matrix(mutations['train'], \n",
    "                                                    mutations['test'], True, 'features_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4WySygLLby65"
   },
   "source": [
    "### Top n genes most frequent in each cancer type\n",
    "\n",
    "Create a feature matrix, getting the top n genes that are most frequent\n",
    "per label (cancer type).  Merge these genes and create a feature matrix,\n",
    "one row per patient tumor, column for each merged gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "24tjauFJby66",
    "outputId": "61a005db-e034-4202-d87a-a38c49f5c6ad"
   },
   "outputs": [],
   "source": [
    "create_feature_matrix(mutations['train'], mutations['test'], 100, True, 'features_top_100_genes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bILSAw6aby68"
   },
   "source": [
    "### KBestFit \n",
    "\n",
    "Create a feature matrix, using sklearn BestFit to find top 100, 700, 1000, 5000, 8000 genes. Feature matrix will have one row per patient tumor, column for each 'bestfit' gene\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 773
    },
    "colab_type": "code",
    "id": "4vRFtl74Kj3Y",
    "outputId": "02c70051-93e0-4540-d6e7-2bcaf9456b60"
   },
   "outputs": [],
   "source": [
    "create_best_fit_feature_matrix(feature_matrix_train, feature_matrix_test, True, \n",
    "                          'features_bestfit')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TkrfXbf5by7a"
   },
   "source": [
    "### Logistic Regression (L1)\n",
    "\n",
    "Trim the features using Logistic Regression, L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 881
    },
    "colab_type": "code",
    "id": "tTXcr330by7b",
    "outputId": "cfaa8f96-4f4d-4031-fce9-e3c3b32e5219"
   },
   "outputs": [],
   "source": [
    "label_encoder            = preprocessing.LabelEncoder()\n",
    "create_l1_feature_matrix(feature_matrix_train, feature_matrix_test, label_encoder,\n",
    "           'features_l1reg', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w8-4ZwG8CLSj"
   },
   "source": [
    "### RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "s3HqHCQ778r5",
    "outputId": "49a51877-c447-4781-8aa5-753354aae906"
   },
   "outputs": [],
   "source": [
    "label_encoder            = preprocessing.LabelEncoder()\n",
    "\n",
    "svm = LinearSVC(penalty='l2', C=0.1)\n",
    "lr = LogisticRegression(penalty='l1', C=0.1)\n",
    "\n",
    "n_features = [100, 800, 4000, 8000]\n",
    "n_step = .05\n",
    "\n",
    "label_encoder            = preprocessing.LabelEncoder()\n",
    "\n",
    "for n_feature in n_features:\n",
    "    \n",
    "  _,_ = create_rfe_feature_matrix(feature_matrix_train, \n",
    "                           feature_matrix_test,\n",
    "                           label_encoder,\n",
    "                           svm, n_feature, n_step,\n",
    "                           'features_rfe_svm_'  + str(n_feature),\n",
    "                           True)\n",
    "  _,_ = create_rfe_feature_matrix(feature_matrix_train, \n",
    "                         feature_matrix_test,\n",
    "                         label_encoder,\n",
    "                         lr, n_feature, n_step,\n",
    "                         'features_rfe_lr_'  + str(n_feature),\n",
    "                         True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B0D7XgAQby7d"
   },
   "source": [
    "### PCA for dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "u2kdSZhsby7e",
    "outputId": "9e68db39-31e2-4480-e7a4-77d2df12a043"
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "all_features_train = feature_matrix_train.drop(columns=['case_id', 'cancer_type'])\n",
    "pca.fit(all_features_train)\n",
    "ev = np.cumsum(pca.explained_variance_ratio_)\n",
    "evcount = len(ev[ev<99.0])\n",
    "print(\"Number of features that explain 99% of the variance: \", evcount)\n",
    "pca = PCA(n_components=evcount)\n",
    "pca.fit(all_features_train)\n",
    "train_PCA = pca.transform(all_features_train)\n",
    "all_features_test = feature_matrix_test.drop(columns=['case_id', 'cancer_type'])\n",
    "test_PCA = pca.transform(all_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-yECeVhby7j"
   },
   "outputs": [],
   "source": [
    "train_PCA_df = pd.DataFrame(train_PCA)\n",
    "train_PCA_df['case_id'] = feature_matrix_train['case_id']\n",
    "train_PCA_df['cancer_type'] = feature_matrix_train['cancer_type']\n",
    "\n",
    "test_PCA_df = pd.DataFrame(test_PCA)\n",
    "test_PCA_df['case_id'] = feature_matrix_test['case_id']\n",
    "test_PCA_df['cancer_type'] = feature_matrix_test['cancer_type']\n",
    "\n",
    "#reorder columns and write out\n",
    "for df, f_name in zip( (train_PCA_df, test_PCA_df), \n",
    "                      ('./data/features_after_pca.train.csv', './data/features_after_pca.test.csv') ):\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-2:] + cols[:-2]\n",
    "    df = df[cols]\n",
    "    df.to_csv(f_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1jJefDaHby7m"
   },
   "source": [
    "# Run the Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k8UQU7csby7n"
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zK-UScuMa25r"
   },
   "source": [
    "### The data dictionary\n",
    "All data source files are downloaded above.  This dataset, is a data dictionary\n",
    "that will allow us to translate cancer type codes to cancer type names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yf_agA3Ba88f"
   },
   "outputs": [],
   "source": [
    "# This loads the data dictionary to will convert\n",
    "# the tumor_sample_barcode into a cancer_type\n",
    "# and provide full names for the cancer types\n",
    "tcga_dict = open(\"./raw/tcga_dictionaries.txt\",\"r\")\n",
    "dict_name_index = 0 #Set dictionary index counter to 0\n",
    "for line in tcga_dict:\n",
    "    if line.startswith(\"#\"): #If line starts with #, the next line will be a known dictionary\n",
    "        dict_name_index += 1\n",
    "    elif dict_name_index == 4:\n",
    "        tissue_source_site = eval(line)            \n",
    "    elif dict_name_index == 5:\n",
    "        code_to_disease = eval(line)\n",
    "    elif dict_name_index == 6:\n",
    "        disease_to_code = eval(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tvpezaGsby7o"
   },
   "outputs": [],
   "source": [
    "def getDataAndLabels(name, features, label_encoder):\n",
    "    labels_string = features.cancer_type\n",
    "   \n",
    "    labels        = label_encoder.fit_transform(labels_string)\n",
    "\n",
    "    # Get rid of the cancer type and patient_barcode columns \n",
    "    data = features[features.columns[3:]]\n",
    "\n",
    "    return {'name': name, 'feature_size': data.shape[1],\n",
    "            'data': data, 'labels': labels , 'label_encoder': label_encoder }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "u2kc_vGOby7r",
    "outputId": "8fa86854-348d-463d-97e7-e4fed4ae3811"
   },
   "outputs": [],
   "source": [
    "print('Loading training data ...')\n",
    "\n",
    "filepath = \"./data/features_l1reg*\"\n",
    "\n",
    "# label encoder\n",
    "label_encoder   = preprocessing.LabelEncoder()\n",
    "\n",
    "# get all file names for the feature datasets\n",
    "train_files = glob.glob(filepath + \".train.csv\")\n",
    "all_train_data = {}\n",
    "\n",
    "# load all of the files\n",
    "for filename in train_files:\n",
    "    \n",
    "    name = filename[16:-10]\n",
    "    print(\" \", name)\n",
    "    train_features = pd.read_csv(filename)\n",
    "    all_train_data[name] = getDataAndLabels(name, train_features, label_encoder)\n",
    "\n",
    "print(\"done.\")\n",
    "\n",
    "\n",
    "print('Loading test data ...')\n",
    "\n",
    "test_files = glob.glob(filepath + \".test.csv\")\n",
    "all_test_data = {}\n",
    "for filename in test_files:\n",
    "    \n",
    "    name = filename[16:-9]\n",
    "    print(\" \", name)\n",
    "    test_features = pd.read_csv(filename)\n",
    "    all_test_data[name] = getDataAndLabels(name, test_features, label_encoder)\n",
    "\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y_50vHGONZwI"
   },
   "source": [
    "## Functions for tracking metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KZsxQONYby8K"
   },
   "outputs": [],
   "source": [
    "def get_saved_metrics():\n",
    "    metrics_filename = \"./metrics/metrics.csv\"\n",
    "    if os.path.isfile(metrics_filename):\n",
    "        metrics_df = pd.read_csv(metrics_filename)\n",
    "        metrics =  [row for row in metrics_df.T.to_dict().values()]\n",
    "        return metrics\n",
    "    else:\n",
    "        return []\n",
    "      \n",
    "def get_saved_metrics_dataframe():\n",
    "    metrics_filename = \"./metrics/metrics.csv\"\n",
    "    if os.path.isfile(metrics_filename):\n",
    "        metrics_df = pd.read_csv(metrics_filename)\n",
    "        return metrics_df\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def save_metrics(name, classifier, metrics, prf_by_label, confusion_mx):\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics, columns=['name', 'classifier', 'feature_size', \n",
    "                                                'accuracy', 'precision', 'recall', 'f1', \n",
    "                                                'time'])\n",
    "    \n",
    "    # Write out scores as csv files\n",
    "    metrics_df.to_csv(\"./metrics/metrics.csv\")\n",
    "    \n",
    "    # Write out confusion matrix to csv file    \n",
    "    confusion_mx_df = pd.DataFrame.from_dict(confusion_mx)\n",
    "    filename = \"./metrics/confusion_\" + name + \"_\" + classifier + \".csv\"\n",
    "    confusion_mx_df.to_csv(filename)\n",
    "    \n",
    "    # Write out precision, recall, f1 by class to csv file\n",
    "    prf_by_label_df = pd.DataFrame(prf_by_label)\n",
    "    filename = \"./metrics/prf_by_class_\" + name + \"_\" + classifier + \".csv\"\n",
    "    prf_by_label_df.to_csv(filename)\n",
    "    \n",
    "def get_prf_by_label(name, classifier):\n",
    "    filename = \"./metrics/prf_by_class_\" + name + \"_\" + classifier + \".csv\"\n",
    "    if os.path.isfile(filename):\n",
    "        prf_by_label_df = pd.read_csv(filename)\n",
    "        return prf_by_label_df[prf_by_label_df.columns[1:]]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_confusion_matrix(name, classifier):\n",
    "    filename = \"./metrics/confusion_\" + name + \"_\" + classifier + \".csv\"\n",
    "    if os.path.isfile(filename):\n",
    "        confusion_df = pd.read_csv(filename)\n",
    "        return confusion_df[confusion_df.columns[1:]]\n",
    "    else:\n",
    "        return None\n",
    "      \n",
    "def calculate_metrics(name, classifier, feature_size, predict, test_labels, \n",
    "                      elapsed_time, metrics):\n",
    "    # Get precision, recall, f1 scores\n",
    "    prf_scores          = precision_recall_fscore_support(test_labels, predict, \n",
    "                                                          average='weighted')\n",
    "    acc_score           = accuracy_score(test_labels, predict)\n",
    "    prf_by_label        = precision_recall_fscore_support(test_labels, predict, \n",
    "                                                          average=None)\n",
    "    classification_rpt  = classification_report(test_labels, predict)\n",
    "\n",
    "    # Get confusion matrix\n",
    "    conf_mx             = confusion_matrix(test_labels, predict)\n",
    "\n",
    "    metrics.append({\n",
    "     'name':               name,\n",
    "     'classifier':         classifier,\n",
    "     'feature_size':       feature_size,\n",
    "     'accuracy':           acc_score,\n",
    "     'precision':          prf_scores[0],\n",
    "     'recall':             prf_scores[1],\n",
    "     'f1':                 prf_scores[2],\n",
    "     'time':               elapsed_time \n",
    "    })\n",
    "    save_metrics(name, classifier, metrics, prf_by_label, conf_mx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BcMd3vhdby7z"
   },
   "source": [
    "## Functions for running different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gOquprmrby75"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Logistic regression\n",
    "# \n",
    "def getBestParamsLogit(train_data, train_labels):\n",
    "    #\n",
    "    # Logistic Regression\n",
    "    #\n",
    "    lr = LogisticRegression(penalty='l2', multi_class = 'ovr', solver='liblinear', max_iter=150)\n",
    "    params = {'C': [0.1, 0.25,  0.5]}\n",
    "    logit = GridSearchCV(lr, params, cv=5,\n",
    "                         scoring='accuracy', return_train_score=True)\n",
    "\n",
    "    # Fit  training data\n",
    "    logit.fit(train_data, train_labels)  \n",
    "    # Show the best C parameter to use and the expected accuracy\n",
    "    print(' Best param:', logit.best_params_)\n",
    "    print(' Accuracy:  ', np.round(logit.best_score_, 4) )\n",
    "    \n",
    "    return logit.best_params_\n",
    "\n",
    "def run_logistic_regression(train_data, train_labels, test_data, test_labels, \n",
    "                            name, hyper_params, metrics, forcerun=False):\n",
    "  \n",
    "    existing = [record for record in metrics if record['name'] == name and record['classifier'] == 'lr']\n",
    "    if (not(forcerun) and len(existing) > 0):\n",
    "      print(\"\\nLogistic Regression (skipping)\")\n",
    "      return\n",
    "    \n",
    "    print(\"\\nLogistic Regression\", name)\n",
    "\n",
    "    start = time.process_time()\n",
    "    if name in hyper_params and 'lr' in hyper_params[name]:\n",
    "        best_params_logit = hyper_params[name]['lr']\n",
    "    else:\n",
    "        print(\"Running grid search on Logistic Regression...\")\n",
    "        best_params_logit = getBestParamsLogit(train_data, train_labels)\n",
    "\n",
    "    # Run logistic regression with L2 regularization on reduced\n",
    "    # feature set\n",
    "    lr = LogisticRegression(penalty='l2', tol=.01, max_iter=150, \n",
    "                          C=best_params_logit['C'], \n",
    "                          solver=\"liblinear\", multi_class=\"ovr\")\n",
    "    lr.fit(train_data, train_labels) \n",
    "    predict = lr.predict(test_data)\n",
    "    elapsed_time = time.process_time() - start\n",
    "\n",
    "\n",
    "    calculate_metrics(name, 'lr', train_data.shape[1], predict, test_labels, \n",
    "                      elapsed_time, metrics)\n",
    "\n",
    "    print(\" done.\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KHfO2X_Vby77"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Linear SVM\n",
    "#\n",
    "\n",
    "def getBestParamsSVM(train_data, train_labels):\n",
    "    #\n",
    "    # SVM\n",
    "    #\n",
    "    classifier = LinearSVC(penalty='l2')\n",
    "\n",
    "    params = {'C': [0.01, 0.1, 0.5]}\n",
    "    svm = GridSearchCV(classifier, params, cv=4, \n",
    "                       scoring='accuracy', return_train_score=True)\n",
    "\n",
    "    # Fit  training data\n",
    "    svm.fit(train_data, train_labels)  \n",
    "    # Show the best C parameter to use and the expected accuracy\n",
    "    print(' Best param:', svm.best_params_)\n",
    "    print(' Accuracy:  ', np.round(svm.best_score_, 4) )\n",
    "    \n",
    "    return svm.best_params_\n",
    "  \n",
    "def run_linear_svm(train_data, train_labels, test_data, test_labels, \n",
    "                   name, hyper_params, metrics, forcerun=False):\n",
    "    \n",
    "    existing = [record for record in metrics if record['name'] == name and record['classifier'] == 'svm']\n",
    "    if (not(forcerun) and len(existing) > 0):\n",
    "      print(\"\\nLinear SVM (skipping)\")\n",
    "      return\n",
    "    \n",
    "    print(\"\\nLinear SVM\", name)\n",
    "    start = time.process_time()\n",
    "    if name in hyper_params and 'svm' in hyper_params[name]:\n",
    "        best_params_svm = hyper_params[name]['svm']\n",
    "    else:\n",
    "        print(\"Running grid search on Linear SVM...\")\n",
    "        best_params_svm = getBestParamsSVM(train_data, train_labels)\n",
    "\n",
    "    svm = LinearSVC(penalty='l2', C=best_params_svm['C'])\n",
    "\n",
    "    svm.fit(train_data, train_labels,) \n",
    "    predict = svm.predict(test_data)\n",
    "    elapsed_time = time.process_time() - start\n",
    "\n",
    "    calculate_metrics(name, 'svm', train_data.shape[1], predict, test_labels, \n",
    "                      elapsed_time, metrics)\n",
    "    \n",
    "    print(\" done.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "muZmidvcby8A"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Decision tree\n",
    "#\n",
    "def run_decision_tree(train_data, train_labels, test_data, test_labels, name, hyper_params, metrics):\n",
    "\n",
    "    existing = [record for record in metrics if record['name'] == name and record['classifier'] == 'dt']\n",
    "    if (len(existing) > 0):\n",
    "      print(\"\\nDecision Tree (skipping)\")\n",
    "      return\n",
    "    \n",
    "    print(\"\\nDecision Tree\", name)\n",
    "    start = time.process_time()\n",
    "    dt = DecisionTreeClassifier()\n",
    "    \n",
    "    dt.fit(train_data, train_labels,) \n",
    "    predict = dt.predict(test_data)\n",
    "    elapsed_time = time.process_time() - start\n",
    "\n",
    "\n",
    "    calculate_metrics(name, 'dt', train_data.shape[1], predict, test_labels, \n",
    "                      elapsed_time, metrics)\n",
    "    \n",
    "    print(\" done.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aK-uq9g0by8C"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Random forest\n",
    "#\n",
    "def run_random_forest(train_data, train_labels, test_data, test_labels, name, hyper_params, metrics):\n",
    "  \n",
    "    existing = [record for record in metrics if record['name'] == name and record['classifier'] == 'rf']\n",
    "    if (len(existing) > 0):\n",
    "      print(\"\\nRandom Forest (skipping)\")\n",
    "      return\n",
    "    \n",
    "    print(\"\\nRandom Forest\", name)\n",
    "    start = time.process_time()\n",
    "    rf = RandomForestClassifier(n_estimators=500)\n",
    "    \n",
    "    rf.fit(train_data, train_labels,) \n",
    "    predict = rf.predict(test_data)\n",
    "    elapsed_time = time.process_time() - start\n",
    "\n",
    "    calculate_metrics(name, 'rf', train_data.shape[1], predict, test_labels, \n",
    "                      elapsed_time, metrics)\n",
    "    \n",
    "    print(\" done.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W7u0wd8oby8F"
   },
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "# Neural Net\n",
    "#\n",
    "def run_neural_net(train_data, train_labels, test_data, test_labels, name, hyper_params, metrics):\n",
    "    existing = [record for record in metrics if record['name'] == name and record['classifier'] == 'nn']\n",
    "    if (len(existing) > 0):\n",
    "      print(\"\\nNeural Net (skipping)\")\n",
    "      return\n",
    "    \n",
    "    print(\"\\nNeural Net\", name)\n",
    "    tr_lab = to_categorical(train_labels)\n",
    "    test_lab = to_categorical(test_labels)\n",
    "    \n",
    "    number_of_classes = len(tr_lab[0])\n",
    "    \n",
    "    start = time.process_time()\n",
    "    model = K.Sequential()\n",
    "    model.add(Dense(2000, input_dim=train_data.shape[1], activation='relu', \n",
    "                    kernel_regularizer=regularizers.l1_l2(l2=0.01,l1=0.01)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(400, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(number_of_classes, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = [\"accuracy\"])\n",
    "    \n",
    "    \n",
    "    #model.fit(train_data, tr_lab, epochs=200, batch_size=100)\n",
    "    if name == 'after_pca':\n",
    "      n_epochs = 10\n",
    "    else:\n",
    "      n_epochs = 140\n",
    "    hist = model.fit(train_data, tr_lab, epochs=n_epochs, batch_size=100,\n",
    "                     validation_data=(test_data, test_lab))\n",
    "    \n",
    "    \n",
    "    evaluate = model.evaluate(x = test_data, y = test_lab)\n",
    "    predict = model.predict(test_data)    \n",
    "    \n",
    "    elapsed_time = time.process_time() - start\n",
    "\n",
    "    calculate_metrics(name, 'nn', train_data.shape[1],\n",
    "                      np.argmax(predict,1), test_labels, elapsed_time, metrics)\n",
    "\n",
    "    print(\" done.\")\n",
    "    \n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dwdypavvby8K"
   },
   "source": [
    "## Run the different classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MPlio9KCby8R",
    "outputId": "1ffef275-ec68-42ea-bdc5-0679fb395165"
   },
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    'l1reg_c0.025':         {'lr': {'C': 0.25}, 'svm': {'C': 0.01}}, \n",
    "    'l1reg_c0.05':          {'lr': {'C': 0.25}, 'svm': {'C': 0.01}}, \n",
    "    'l1reg_c0.1':           {'lr': {'C': 0.25}, 'svm': {'C': 0.01}}, \n",
    "    'l1reg_c0.25':           {'lr': {'C': 0.25}, 'svm': {'C': 0.01}}, \n",
    "    'l1reg_c0.5':           {'lr': {'C': 0.25}, 'svm': {'C': 0.01}},\n",
    "    'l1reg_c1':             {'lr': {'C': 0.25}, 'svm': {'C': 0.01}},\n",
    "    'l1reg_c10':            {'lr': {'C': 0.1},  'svm': {'C': 0.01}},\n",
    "    'l1reg_c100':           {'lr': {'C': 0.25}, 'svm': {'C': 0.01}},\n",
    "    \n",
    "    'top_100_genes':        {'lr': {'C': 0.1},  'svm': {'C': 0.01}},\n",
    "\n",
    "    'bestfit_med':          {'lr': {'C': 0.1 }, 'svm': {'C': 0.01}},\n",
    "    'bestfit_large':        {'lr': {'C': 0.1 }, 'svm': {'C': 0.01}},\n",
    "    \n",
    "    'all':                  {'lr': {'C': 0.25}, 'svm': {'C': 0.01}},\n",
    "    'after_pca':            {'lr': {'C': 0.5 }, 'svm': {'C': 0.01}},\n",
    "    \n",
    "    'rfe_svm_100':          {'lr': {'C': 0.5},  'svm': {'C': 0.1}}, \n",
    "    'rfe_lr_100':           {'lr': {'C': 0.5},  'svm': {'C': 0.1}}, \n",
    "\n",
    "    'rfe_svm_800':          {'lr': {'C': 0.5},  'svm': {'C': 0.1}}, \n",
    "    'rfe_lr_800':           {'lr': {'C': 0.1},  'svm': {'C': 0.01}}, \n",
    "    \n",
    "    'rfe_svm_4000':         {'lr': {'C': 0.5},  'svm': {'C': 0.01}}, \n",
    "    'rfe_lr_4000':          {'lr': {'C': 0.1},  'svm': {'C': 0.01}}, \n",
    "    \n",
    "    'rfe_svm_8000':         {'lr': {'C': 0.25}, 'svm': {'C': 0.01}}, \n",
    "    'rfe_lr_8000':          {'lr': {'C': 0.1},  'svm': {'C': 0.01}} \n",
    "}\n",
    "\n",
    "metrics = get_saved_metrics()\n",
    "\n",
    "\n",
    "for name in all_train_data.keys():\n",
    "    print(\"************************\")\n",
    "    print(name)\n",
    "    print(\"************************\")\n",
    "\n",
    "    train      = all_train_data[name]\n",
    "    test       = all_test_data[name]\n",
    "    \n",
    "    \n",
    "\n",
    "    run_logistic_regression(train['data'], train['labels'], test['data'], test['labels'], \n",
    "                            name, hyper_params, metrics, forcerun=False)\n",
    "    \n",
    "    run_linear_svm(train['data'], train['labels'], test['data'], test['labels'], \n",
    "                   name, hyper_params, metrics, forcerun=False)\n",
    "\n",
    "    run_decision_tree(train['data'], train['labels'], test['data'], test['labels'], \n",
    "                   name, hyper_params, metrics)\n",
    "    \n",
    "    run_random_forest(train['data'], train['labels'], test['data'], test['labels'], \n",
    "                   name, hyper_params, metrics)\n",
    "    \n",
    "    run_neural_net(train['data'], train['labels'], test['data'], test['labels'], \n",
    "                   name, hyper_params, metrics)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uVrkAG7Cby8X"
   },
   "source": [
    "# Visualize Performance across different feature sets, different classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PWMrpYFIFvEL"
   },
   "source": [
    "### Load the metrics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0v60WuOBby8X"
   },
   "outputs": [],
   "source": [
    "metrics_df = get_saved_metrics_dataframe()\n",
    "metrics_df = metrics_df.sort_values(by=['feature_size', 'name', 'classifier'], ascending=[1,1,1])\n",
    "metrics_df = metrics_df[metrics_df.columns[1:]]\n",
    "\n",
    "metrics_df = metrics_df.sort_values(by=['classifier', 'feature_size', 'name'], ascending=[1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tIBzDQt3by8a"
   },
   "outputs": [],
   "source": [
    "colors = {'lr': 'olivedrab', 'svm': 'slateblue', \n",
    "          'dt': 'mediumseagreen', 'rf': 'goldenrod',\n",
    "          'xgb': 'coral', 'nn': 'crimson'}\n",
    "\n",
    "def plot_classifier_metrics(metrics_df, label_encoder, description):\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (20,14)\n",
    "\n",
    "    labels = []\n",
    "    for key, group in metrics_df.groupby(['feature_size', 'name']):\n",
    "        labels.append(str(key[0]) + '\\n' + key[1])\n",
    "    \n",
    "\n",
    "    sorted_df_report = metrics_df.sort_values(by=['classifier', 'feature_size', 'name'], ascending=[1,1,1])\n",
    "\n",
    "\n",
    "        \n",
    "    for classifier, group in sorted_df_report.groupby(['classifier']):\n",
    "\n",
    "        plt.plot(labels, group.precision.values, color=colors[classifier], \n",
    "                 linewidth=2, label=classifier + \" precision\", marker='o' )\n",
    "        plt.plot(labels, group.recall.values, color=colors[classifier], linestyle=\"dashed\",\n",
    "                 linewidth=2, label=classifier + \" recall\", marker='o' )\n",
    "    \n",
    "\n",
    "    plt.yticks(np.arange(0, .70, .01))\n",
    "    plt.title(description, fontsize=20)\n",
    "    plt.ylabel('Precision, Recall', fontsize=14)\n",
    "    plt.xlabel('Feature Sets', fontsize=14, labelpad=14)\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    for classifier, group in sorted_df_report.groupby(['classifier']):\n",
    "\n",
    "        plt.plot(labels, group.accuracy.values, color=colors[classifier], \n",
    "                 linewidth=2, label=classifier + \" accuracy\", marker='o' )\n",
    "    \n",
    "\n",
    "    plt.yticks(np.arange(0, .70, .01))\n",
    "    plt.ylabel('Accuracy', fontsize=14)\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.xlabel('Features and Classifiers', fontsize=14, labelpad=20)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_classifier_times(metrics_df, label_encoder, description):\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (20,6)\n",
    "\n",
    "    labels = []\n",
    "    for key, group in metrics_df.groupby(['feature_size', 'name']):\n",
    "        labels.append(str(key[0]) + '\\n' + key[1])\n",
    "        \n",
    "    sorted_df_report = metrics_df.sort_values(by=['classifier', 'feature_size', 'name'], ascending=[1,1,1])\n",
    "\n",
    "\n",
    "        \n",
    "    for classifier, group in sorted_df_report.groupby(['classifier']):\n",
    "\n",
    "        plt.plot(labels, group.time.values, color=colors[classifier], \n",
    "                 linewidth=2, label=classifier + \" precision\", marker='o' )\n",
    "        \n",
    "    \n",
    "\n",
    "    plt.ylabel('Time to train and predict', fontsize=14)\n",
    "    plt.xlabel('Feature Sets', fontsize=14, labelpad=14)\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "def coords_of_max(theArray, n):\n",
    "    # Flatten the 2D array\n",
    "    flat = theArray.flatten()\n",
    "    # Partition so that the we know the sort order for\n",
    "    # the cells with the highest values.  We just\n",
    "    # care about the top n highest values.  So for example,\n",
    "    # if n = 3, get return 3 indices.  \n",
    "    indices = np.argpartition(flat, -n)[-n:]\n",
    "    # Reverse so that we show index of highest value first\n",
    "    # (descending)\n",
    "    indices = indices[np.argsort(-flat[indices])]\n",
    "    # Now return the coordinates for these indices\n",
    "    # for a 2D array.  This will return 2 arrays,\n",
    "    # the first for the row index, the second for the\n",
    "    # column index.  The row index represents the\n",
    "    # actual digit, the column index represents\n",
    "    # the confused digit\n",
    "    return np.unravel_index(indices, theArray.shape)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_MYKrX8Dby8o"
   },
   "source": [
    "### Plot precision metrics across different classifiers and feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "GJSJhTWgby8p",
    "outputId": "18f89378-af4d-404f-d1b6-f9726189afb1"
   },
   "outputs": [],
   "source": [
    "label_encoder   = preprocessing.LabelEncoder()\n",
    "\n",
    "metrics_df = metrics_df[~metrics_df.name.isin(['cna_alone'])]\n",
    "                        \n",
    "somatic_metrics = metrics_df[~metrics_df.name.isin([\n",
    "                                                    'cna_l1reg_c0.025', \n",
    "                                                    'cna_l1reg_c0.01', \n",
    "                                                    'cna_binary_l1reg_c0.025',\n",
    "                                                    'cna_binary_l1reg_c0.01'])]\n",
    "cna_metrics     = metrics_df[metrics_df.name.isin( ['cna_l1reg_c0.025', \n",
    "                                                    'cna_l1reg_c0.01', \n",
    "                                                    'cna_binary_l1reg_c0.025',\n",
    "                                                    'cna_binary_l1reg_c0.01'])]\n",
    "# Plot precision, recall, accuracy across different classifiers\n",
    "# for somatic mutations\n",
    "plot_classifier_metrics(somatic_metrics, label_encoder, 'Somatic mutations')\n",
    "\n",
    "# Plot time across different classifiers\n",
    "# for somatic mutations\n",
    "plot_classifier_times(somatic_metrics, label_encoder, 'Somatic mutations')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7129vqRQby8q"
   },
   "source": [
    "### Report the precision, recall, and f1 score across different classifiers and feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6Jc7L3Ffby8r",
    "outputId": "f0a66ba3-ce0d-4f5a-ebef-fc7f4519fa70"
   },
   "outputs": [],
   "source": [
    "def show_precision_recall_by_label(prf_by_label_df, name, classifier, label_encoder):\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (16,14)\n",
    "    \n",
    "    labels = []\n",
    "    for i in range(prf_by_label_df.shape[1]):\n",
    "        label = label_encoder.inverse_transform([i])[0]\n",
    "        labels.append(label)\n",
    "    \n",
    "    \n",
    "    y_pos = np.arange(len(labels))    \n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=False)\n",
    "\n",
    "    ax1.invert_xaxis()\n",
    "    ax1.invert_yaxis()\n",
    "    ax1.yaxis.tick_right()\n",
    "    \n",
    "    ax1.set_yticks(y_pos)\n",
    "    ax1.set_yticklabels(labels)\n",
    "    \n",
    "    ax2.invert_yaxis()\n",
    "    ax2.set_yticks(y_pos)\n",
    "    ax2.set_yticklabels(labels)\n",
    "        \n",
    "    ax1.barh(y_pos, prf_by_label_df.iloc[0].values, color=label_colors , label=\"precision\")\n",
    "    ax2.barh(y_pos, prf_by_label_df.iloc[1].values, color=label_colors,  label='recall')\n",
    "\n",
    "    ax1.set_title('Precision( ' + classifier + ')')\n",
    "    ax2.set_title('Recall (' + classifier + ')')\n",
    "    ax1.grid()\n",
    "    ax2.grid()\n",
    "    \n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# best precision\n",
    "sorted_df = somatic_metrics.sort_values(by='precision', ascending=0)\n",
    "best_precision = sorted_df.head(1)\n",
    "\n",
    "# best recall\n",
    "sorted_df = somatic_metrics.sort_values(by='recall', ascending=0)\n",
    "best_recall = sorted_df.head(1)\n",
    "\n",
    "# best f1\n",
    "sorted_df = somatic_metrics.sort_values(by='f1', ascending=0)\n",
    "best_f1 = sorted_df.head(1)\n",
    "\n",
    "# best accuracy\n",
    "sorted_df = somatic_metrics.sort_values(by='accuracy', ascending=0)\n",
    "best_accuracy = sorted_df.head(1)\n",
    "\n",
    "\n",
    "# Show the feature set and classifier with the best \n",
    "# precision, recall, and f1 scores\n",
    "print(\"\\n\\nBest precision\")\n",
    "display(best_precision)\n",
    "print(\"\\n\\nBest recall\")\n",
    "display(best_recall)\n",
    "print(\"\\n\\nBest f1\")\n",
    "display(best_f1)\n",
    "print(\"\\n\\nBest accuracy\")\n",
    "display(best_accuracy)\n",
    "\n",
    "# get the scores by label and confusion matrix\n",
    "# for the best prediction\n",
    "best_prediction = best_precision\n",
    "best_name       = best_prediction.name.values[0]\n",
    "best_classifier = best_prediction.classifier.values[0]\n",
    "\n",
    "\n",
    "best_prf_by_label_df = get_prf_by_label(best_name, best_classifier)\n",
    "best_confusion_mx_df = get_confusion_matrix(best_name, best_classifier)\n",
    "\n",
    "feature_matrix = pd.read_csv(\"./data/features_\" + best_name + \".train.csv\")\n",
    "label_encoder.fit(feature_matrix.cancer_type.unique())\n",
    "\n",
    "# show a side-by-side barchart of precision and recall for each label\n",
    "print(\"\\n\\nPrecision and Recall by Label with Best F1 score \")\n",
    "print(\"Classifier:\", best_classifier, \"Feature set:\", best_name)\n",
    "show_precision_recall_by_label(best_prf_by_label_df,\n",
    "                               best_name, best_classifier, label_encoder)\n",
    "                                                      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-t7BzkrmImi"
   },
   "source": [
    "## Visualizations for Diagnosing Poor Performing Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KPOgeimaBmYR"
   },
   "source": [
    "### How many genes are in common for a cancer type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pCGcizYvmNeJ",
    "outputId": "27f3b031-6b17-4578-f85c-02bb3c306f16"
   },
   "outputs": [],
   "source": [
    "features       = feature_matrix[feature_matrix.columns[1:]]\n",
    "cancer_types   = sorted(features.cancer_type.unique())\n",
    "best_precision = np.round(best_prf_by_label_df.loc[0:0].values[0], 2)  \n",
    "best_recall    = np.round(best_prf_by_label_df.loc[0:1].values[0], 2)  \n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "fig = plt.figure()\n",
    "suptitle = fig.suptitle(\"Number of Genes in Common for Samples of a Cancer Type\", fontsize=20)\n",
    "ax = fig.subplots(7, 5, sharex=False, sharey=False, squeeze=True)\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "ax = ax.flatten()\n",
    "_ = ax[33].axis('off')\n",
    "_ = ax[34].axis('off')\n",
    "\n",
    "\n",
    "num_samples_per_cancer_type = []\n",
    "num_genes_per_cancer_type   = []\n",
    "num_multisample_genes_per_cancer_type = []\n",
    "pct_multisample_genes_per_cancer_type = []\n",
    "avg_num_samples_sharing_genes = []\n",
    "\n",
    "\n",
    "for idx, cancer_type in enumerate(cancer_types, start=0):\n",
    "  features_ct = features.loc[features.cancer_type == cancer_type]\n",
    "  features_ct = features_ct[features_ct.columns[2:]]\n",
    "\n",
    "  print(\".\", end='')\n",
    "\n",
    "  \n",
    "  gene_sums_all = features_ct.sum(axis=0) \n",
    "  gene_sums_all = gene_sums_all[gene_sums_all > 0]\n",
    "  gene_sums = gene_sums_all[gene_sums_all > 1]\n",
    "  gene_sums.columns = ['gene_count']\n",
    "\n",
    "  \n",
    "  num_samples_per_cancer_type.append(features_ct.shape[0])\n",
    "  num_genes_per_cancer_type.append(gene_sums_all.shape[0])\n",
    "  num_multisample_genes_per_cancer_type.append(gene_sums.shape[0])\n",
    "  pct_multisample_genes_per_cancer_type.append((gene_sums.shape[0] / gene_sums_all.shape[0]) * 100)\n",
    "  avg_num_samples_sharing_genes.append(gene_sums.mean(axis=0))\n",
    "  \n",
    "  bins = np.arange(31) - 0.5\n",
    "  _ = gene_sums.hist(ax=ax[idx], bins=bins, density=True, range=[0,31], color=label_colors[idx] )\n",
    "  _ = ax[idx].set_title(cancer_type + \"\\n\" \n",
    "                        + str(best_precision[idx]) + \" prec, \" + str(best_recall[idx]) + \" recall \\n\"\n",
    "                        + str(gene_sums_all.shape[0]) + \" genes, \" + str(features_ct.shape[0]) + \" samples\\n\" \n",
    "                        + str(int(np.round(gene_sums.shape[0] / gene_sums_all.shape[0], 2) * 100)) + \"% genes in mult. samples \")\n",
    "  \n",
    "  _ = ax[idx].axvline(gene_sums.mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "  _ = ax[idx].set_xlabel(\"Number of samples with genes in common\")\n",
    "  _ = ax[idx].set_ylim((0,1))\n",
    "  _ = ax[idx].set_xticks(np.arange(0, 30, 3))\n",
    "  _ = ax[idx].set_ylabel(\"Number of genes in common\")\n",
    "\n",
    "_ = fig.tight_layout()\n",
    "_ = suptitle.set_y(1.05)\n",
    "_ = fig.subplots_adjust(top=.95)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Csdqf5Q2B5e8"
   },
   "source": [
    "### How many genes are common across all cancer types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "qILJEym3BP74",
    "outputId": "715f7442-4ec1-4e87-c126-8692619f6cc6"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "fig = plt.figure()\n",
    "suptitle = fig.suptitle(\"Number of Genes for a Cancer Type that are common across other Cancer Types\", fontsize=20)\n",
    "ax = fig.subplots(7, 5, sharex=False, sharey=False, squeeze=True)\n",
    "_ = plt.subplots_adjust(hspace=0.4)\n",
    "ax = ax.flatten()\n",
    "_ = ax[33].axis('off')\n",
    "_ = ax[34].axis('off')\n",
    "\n",
    "mean_common_cancer_types = []\n",
    "\n",
    "features_by_cc = features[features.columns[1:]].groupby(['cancer_type']).sum()\n",
    "for col in features_by_cc.columns:\n",
    "  features_by_cc[col] = features_by_cc[col].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "\n",
    "diff_pairings = []\n",
    "\n",
    "for idx, cancer_type in enumerate(cancer_types, start=0):\n",
    "  print(\".\", end='')\n",
    "  features_ct = features_by_cc.loc[[cancer_type]]\n",
    "  \n",
    "  gene_counts_ct = features_ct.T\n",
    "  non_zero_genes = list(gene_counts_ct[gene_counts_ct[cancer_type] > 0].index)\n",
    "  \n",
    "  other_cancer_types = [c for c in cancer_types if c != cancer_type]\n",
    "  features_other = features_by_cc.loc[other_cancer_types, non_zero_genes]\n",
    "  \n",
    "  gene_sums_ct = features_ct.sum(axis=0) \n",
    "  gene_sums_ct = gene_sums_ct[gene_sums_ct > 0]\n",
    "  gene_sums_ct.columns = ['gene_count']\n",
    "  \n",
    "  gene_sums_other = features_other.sum(axis=0) \n",
    "  gene_sums_other = gene_sums_other[gene_sums_ct > 0]\n",
    "  gene_sums_other.columns = ['gene_count']\n",
    "  \n",
    "  sums_other     = features_other.sum(axis=0)\n",
    "  \n",
    "  mean_common_cancer_types.append(sums_other.mean())\n",
    "  \n",
    "  \n",
    "  diff_pairing       = []\n",
    "  diff_pairing_norm  = []\n",
    "  for x, cancer_type_pairing in enumerate(cancer_types, start=0):\n",
    "    features_pairing    = features_by_cc.loc[[cancer_type_pairing]]\n",
    "    gene_counts_pairing = features_pairing.T\n",
    "    non_zero_target     = set(non_zero_genes)\n",
    "    non_zero_other      = list(gene_counts_pairing[gene_counts_pairing[cancer_type_pairing] > 0].index)\n",
    "    non_zero_other      = set(non_zero_other)\n",
    "  \n",
    "    diff = non_zero_target - non_zero_other\n",
    "    \n",
    "    diff_pairing.append(len(diff))\n",
    "    \n",
    "  diff_pairings.append(diff_pairing)\n",
    "  diff_pairings_norm.append(diff_pairing_norm)\n",
    "  \n",
    "  bins = np.arange(32) - 0.5\n",
    "  _ = sums_other.hist(ax=ax[idx], bins=bins, range=[0,33], color=label_colors[idx])\n",
    "  _ = ax[idx].set_ylim((0,1500))\n",
    "  _ = ax[idx].axvline(sums_other.mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "  _ = ax[idx].set_title(cancer_type + \" (\" + str(gene_sums_ct.shape[0]) + \" genes, \"\n",
    "                       + \"prec=\" + str(best_precision[idx]) + \")\")\n",
    "  \n",
    "  _ = ax[idx].set_title(cancer_type + \"\\n\" \n",
    "                        + str(best_precision[idx]) + \" prec, \" + str(best_recall[idx]) + \" recall \\n\"\n",
    "                        + str(gene_sums_ct.shape[0]) + \" genes, \" + str(num_samples_per_cancer_type[idx]) + \" samples\")\n",
    "  \n",
    "  _ = ax[idx].set_xlabel(\"Number of Cancer types\")\n",
    "  _ = ax[idx].set_ylabel(\"Number of Shared genes\")\n",
    "\n",
    "  \n",
    "fig.tight_layout()\n",
    "suptitle.set_y(1)\n",
    "fig.subplots_adjust(top=.95)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 902
    },
    "colab_type": "code",
    "id": "c7qQL6vKGRQd",
    "outputId": "d86a8659-0d64-4130-e205-003244e13f6f"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (8,4)\n",
    "fig = plt.figure()\n",
    "suptitle = fig.suptitle(\"Is Cancer Type Precision Affected by Number of Samples or Number of Genes?\", \n",
    "                        fontsize=16)\n",
    "ax = fig.subplots(1, 2, sharex=False, sharey=False, squeeze=True)\n",
    "\n",
    "_ = ax[0].scatter(num_samples_per_cancer_type, best_precision, color=label_colors)\n",
    "_ = ax[0].set_ylabel(\"Precision\")\n",
    "_ = ax[0].set_xlabel(\"Number of Samples\")\n",
    "\n",
    "_ = ax[1].scatter(num_genes_per_cancer_type, best_precision, color=label_colors)\n",
    "_ = ax[1].set_ylabel(\"Precision\")\n",
    "_ = ax[1].set_xlabel(\"Number of Genes\")\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,4)\n",
    "fig = plt.figure()\n",
    "suptitle = fig.suptitle(\"Is Cancer Type Precision Affected by How Many Samples Share the same Genes?\",\n",
    "                        fontsize=16)\n",
    "ax = fig.subplots(1, 3, sharex=False, sharey=False, squeeze=True)\n",
    "\n",
    "_ = ax[0].scatter(num_multisample_genes_per_cancer_type, best_precision, color=label_colors)\n",
    "_ = ax[0].set_ylabel(\"Precision\")\n",
    "_ = ax[0].set_xlabel(\"Number of Genes of Cancer Type\\nthat have Samples in Common\")\n",
    "\n",
    "\n",
    "_ = ax[1].scatter(pct_multisample_genes_per_cancer_type , best_precision, color=label_colors)\n",
    "_ = ax[1].set_ylabel(\"Precision\")\n",
    "_ = ax[1].set_xlabel(\"% of all Genes of Cancer Type\\nthat have Samples in Common\")\n",
    "\n",
    "\n",
    "_ = ax[2].scatter(avg_num_samples_sharing_genes, best_precision, color=label_colors)\n",
    "_ = ax[2].set_ylabel(\"Precision\")\n",
    "_ = ax[2].set_xlabel(\"Avg Number of Samples of Cancer Type\\nthat have Genes Common \")\n",
    "\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (5,4)\n",
    "fig = plt.figure()\n",
    "suptitle = fig.suptitle(\"Is Cancer Type Precision Affected by How Common Genes are Across different Cancers?\", \n",
    "                        fontsize=16)\n",
    "ax = fig.subplots(1, 1, sharex=False, sharey=False, squeeze=True)\n",
    "\n",
    "_ = ax.scatter(mean_common_cancer_types, best_precision, color=label_colors)\n",
    "_ = ax.set_ylabel(\"Precision\")\n",
    "_ = ax.set_xlabel(\"Number of Cancer Types sharing genes\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "10mUVouOCFBb"
   },
   "source": [
    "### Pairwise comparison of cancer types, how unique is the set of genes for each cancer type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "colab_type": "code",
    "id": "mCo7VgdZspur",
    "outputId": "cdd807d5-f5e7-4fa6-eb44-6ba097f402c3"
   },
   "outputs": [],
   "source": [
    "\n",
    "informative_labels = []\n",
    "for i in range(len(cancer_types)):\n",
    "  informative_labels.append(cancer_types[i] + \" (recall=\" + str(best_recall[i]))\n",
    "  \n",
    "def plot_pairwise_comparison(pairings, title):\n",
    "  \n",
    "  pairing_df = pd.DataFrame(pairings, columns=informative_labels, index=informative_labels)\n",
    "  pairing_df['recall'] = best_prec\n",
    "\n",
    "  plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "  fig = plt.figure()\n",
    "  ax = fig.add_subplot(111)\n",
    "  cax = ax.matshow(pairing_df)\n",
    "  the_title = plt.title(title, fontsize=20)\n",
    "  _ = fig.colorbar(cax)\n",
    "  _ = ax.set_xticks(np.arange(0, 33, 1.0))\n",
    "  _ = ax.set_yticks(np.arange(0, 33, 1.0))\n",
    "  _ = ax.set_xticklabels(informative_labels, rotation='vertical')\n",
    "  _ = ax.set_yticklabels(informative_labels)\n",
    "  _ = plt.xlabel('Compared to')\n",
    "  _ = plt.ylabel('Cancer Type')\n",
    "  _ = the_title.set_y(1.18)\n",
    "  _ = fig.subplots_adjust(top=.95)\n",
    "  plt.show()\n",
    "\n",
    "plot_pairwise_comparison(diff_pairings, \"Unique genes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FA9nG88nby8s"
   },
   "source": [
    "### Show the confusion matrix for the best performing classifier/feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RXNBflwyby8t",
    "outputId": "17de0f2d-0f4b-4be7-c680-700d6c5ed914"
   },
   "outputs": [],
   "source": [
    "def show_confusion_matrix(conf_mx, label_encoder):\n",
    "\n",
    "  \n",
    "    # Determine the error rates for each misclassification pair\n",
    "    row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "    norm_conf_mx = conf_mx / row_sums\n",
    "    # Set the error rates for correctly classified pairs (the diagonal) to zero\n",
    "    np.fill_diagonal(norm_conf_mx, 0)\n",
    "    \n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(norm_conf_mx)\n",
    "    _ = plt.title('Confusion matrix')\n",
    "    _ = fig.colorbar(cax)\n",
    "    _ = ax.set_xticks(np.arange(0, 33, 1.0))\n",
    "    _ = ax.set_yticks(np.arange(0, 33, 1.0))\n",
    "    _ = ax.set_xticklabels(cancer_types, rotation='vertical')\n",
    "    _ = ax.set_yticklabels(cancer_types)\n",
    "    _ = plt.xlabel('Predicted')\n",
    "    _ = plt.ylabel('True')\n",
    "    plt.show()\n",
    "    \n",
    "    max_coords = coords_of_max(norm_conf_mx, 50)\n",
    "    confusion_rows = []\n",
    "    for i in range(len(max_coords[0])):\n",
    "\n",
    "        # This is the actual label\n",
    "        actual_label_idx  = max_coords[0][i]\n",
    "        actual_label      = label_encoder.inverse_transform([actual_label_idx])[0]\n",
    "\n",
    "        # This is the predicted label\n",
    "        predicted_label_idx = max_coords[1][i]\n",
    "        predicted_label = label_encoder.inverse_transform([predicted_label_idx])[0]\n",
    "        \n",
    "        # This is the error rate\n",
    "        error_rate  = norm_conf_mx[max_coords[0][i], max_coords[1][i]]\n",
    "        error_count = conf_mx[max_coords[0][i], max_coords[1][i]]\n",
    "\n",
    "        row = list([ actual_label,                     \n",
    "                     predicted_label,\n",
    "                     code_to_disease[actual_label][0], \n",
    "                     code_to_disease[predicted_label][0], \n",
    "                     error_rate, \n",
    "                     error_count ])\n",
    "        confusion_rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(confusion_rows, columns=['actual', 'predicted',  'actual_name', 'predicted_name', 'error_rate', 'error_count'])\n",
    "    display(df)\n",
    "    \n",
    "\n",
    "cols = [c for c in best_confusion_mx_df.columns]\n",
    "best_confusion_mx = best_confusion_mx_df[cols].values\n",
    "show_confusion_matrix(best_confusion_mx, label_encoder)                                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KZ1t3OPZtSGY"
   },
   "source": [
    "### TSNE Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "t3wZ9Y03tVk1",
    "outputId": "62864444-667e-4db3-9c17-0a6020022f45"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib as mpl\n",
    "\n",
    "label_encoder   = preprocessing.LabelEncoder()\n",
    "\n",
    "labels  = list(feature_matrix.cancer_type.unique())\n",
    "labels.sort()\n",
    "X       = feature_matrix[feature_matrix.columns[3:]]\n",
    "label_encoder.fit(labels)\n",
    "\n",
    "print(\"Plot TSNE...\")\n",
    "N = len(labels)\n",
    "colors = mpl.cm.rainbow(np.linspace(0, 1, N))\n",
    "fig, axes = plt.subplots(nrows=11, ncols=3, figsize=(11, 33))\n",
    "_ = plt.tight_layout()\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if (i < len(labels)):\n",
    "      ax.title.set_text(\"cancer = {}\".format(labels[i]))\n",
    "      d = X[feature_matrix['cancer_type'] == labels[i]]\n",
    "      dd = TSNE(n_components=2).fit_transform(d)\n",
    "      _ = ax.scatter(dd[:,0], dd[:,1], color=label_colors[i])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "disera_nair_singh_fraenkel_final_project.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
